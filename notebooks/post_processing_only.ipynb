{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6072494a",
   "metadata": {},
   "source": [
    "# Post-Processing Only Notebook\n",
    "\n",
    "This notebook runs post-processing on already-tracked data without re-running tracking.\n",
    "It assumes **bidirectional (forward + backward) tracking** was enabled and the following files exist:\n",
    "\n",
    "- `*_forward.csv` - Raw forward tracking output\n",
    "- `*_backward.csv` - Raw backward tracking output\n",
    "\n",
    "The notebook will:\n",
    "1. Load forward and backward CSV files\n",
    "2. Apply post-processing (break trajectories at velocity/distance jumps)\n",
    "3. Merge forward and backward trajectories into consensus trajectories\n",
    "4. Apply interpolation\n",
    "5. Scale coordinates back to original video space\n",
    "6. Save the final merged output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e468fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import logging\n",
    "\n",
    "# Add the src directory to path if running from notebooks folder\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import post-processing functions\n",
    "from multi_tracker.core.post_processing import (\n",
    "    process_trajectories_from_csv,\n",
    "    resolve_trajectories,\n",
    "    interpolate_trajectories,\n",
    ")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úì Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b072b8b",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your file paths and parameters here. You need to provide:\n",
    "1. Path to the forward tracking CSV\n",
    "2. Path to the backward tracking CSV\n",
    "3. Path to the original video file (to get total frame count and verify resize factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "badb93ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward CSV:  emi_short_tracking_forward.csv\n",
      "Backward CSV: emi_short_tracking_backward.csv\n",
      "Output CSV:   emi_short_tracking_final.csv\n",
      "Video file:   emi_short.mp4\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# FILE PATHS - UPDATE THESE!\n",
    "# ===================================================================\n",
    "\n",
    "# Base path to your tracking output CSV (without _forward/_backward suffix)\n",
    "# Example: if your files are \"video_forward.csv\" and \"video_backward.csv\",\n",
    "# set this to \"video.csv\"\n",
    "BASE_CSV_PATH = \"emi_short_tracking.csv\"\n",
    "\n",
    "# Path to the original video file (used to get total frame count)\n",
    "VIDEO_PATH = \"emi_short.mp4\"\n",
    "\n",
    "# Output path for final merged trajectories\n",
    "OUTPUT_CSV_PATH = None  # Will auto-generate as *_final.csv if None\n",
    "\n",
    "# ===================================================================\n",
    "# DERIVED PATHS (auto-generated)\n",
    "# ===================================================================\n",
    "base, ext = os.path.splitext(BASE_CSV_PATH)\n",
    "FORWARD_CSV_PATH = f\"{base}_forward{ext}\"\n",
    "BACKWARD_CSV_PATH = f\"{base}_backward{ext}\"\n",
    "\n",
    "if OUTPUT_CSV_PATH is None:\n",
    "    OUTPUT_CSV_PATH = f\"{base}_final{ext}\"\n",
    "\n",
    "print(f\"Forward CSV:  {FORWARD_CSV_PATH}\")\n",
    "print(f\"Backward CSV: {BACKWARD_CSV_PATH}\")\n",
    "print(f\"Output CSV:   {OUTPUT_CSV_PATH}\")\n",
    "print(f\"Video file:   {VIDEO_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1a110d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters configured:\n",
      "  MIN_TRAJECTORY_LENGTH: 10\n",
      "  MAX_VELOCITY_BREAK: 57.75\n",
      "  MAX_OCCLUSION_GAP: 5\n",
      "  AGREEMENT_DISTANCE: 9.625\n",
      "  MIN_OVERLAP_FRAMES: 2\n",
      "\n",
      "Interpolation: spline (max_gap=5)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# POST-PROCESSING PARAMETERS\n",
    "# ===================================================================\n",
    "# These should match the values used during tracking, or adjust as needed\n",
    "\n",
    "# Resize factor used during tracking (1.0 = no resize)\n",
    "# This is needed to scale coordinates back to original video space\n",
    "RESIZE_FACTOR = 0.5\n",
    "\n",
    "# Reference body size in pixels (used for scaling thresholds)\n",
    "# This is the typical size of your tracked animal\n",
    "REFERENCE_BODY_SIZE = 77.0\n",
    "\n",
    "# Trajectory post-processing parameters\n",
    "params = {\n",
    "    # Minimum trajectory length (in frames) - shorter ones are removed\n",
    "    \"MIN_TRAJECTORY_LENGTH\": 10,\n",
    "    \n",
    "    # Maximum velocity before breaking trajectory (pixels/frame)\n",
    "    # Jumps faster than this indicate tracking errors\n",
    "    # Note: MAX_DISTANCE_BREAK is now computed dynamically as MAX_VELOCITY_BREAK * frame_diff\n",
    "    \"MAX_VELOCITY_BREAK\": 1.5 * REFERENCE_BODY_SIZE * RESIZE_FACTOR,\n",
    "    \n",
    "    # Maximum consecutive occluded frames before breaking trajectory\n",
    "    \"MAX_OCCLUSION_GAP\": 5,\n",
    "    \n",
    "    # Conservative merge parameters for forward/backward trajectory resolution\n",
    "    # AGREEMENT_DISTANCE: Max distance (px) for frames to be considered \"agreeing\"\n",
    "    # Frames within this distance are merged; frames outside create separate trajectories\n",
    "    \"AGREEMENT_DISTANCE\": REFERENCE_BODY_SIZE * RESIZE_FACTOR * 0.25,\n",
    "    \n",
    "    # MIN_OVERLAP_FRAMES: Minimum number of agreeing frames required to consider merging\n",
    "    \"MIN_OVERLAP_FRAMES\": 2,\n",
    "}\n",
    "\n",
    "# Interpolation settings\n",
    "INTERPOLATION_METHOD = \"spline\"  # Options: \"none\", \"linear\", \"cubic\", \"spline\"\n",
    "INTERPOLATION_MAX_GAP = 5  # Maximum gap size to interpolate (frames)\n",
    "\n",
    "print(\"Parameters configured:\")\n",
    "for k, v in params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nInterpolation: {INTERPOLATION_METHOD} (max_gap={INTERPOLATION_MAX_GAP})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db01bf19",
   "metadata": {},
   "source": [
    "## Validate Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a06a107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Forward CSV: emi_short_tracking_forward.csv\n",
      "‚úì Backward CSV: emi_short_tracking_backward.csv\n",
      "‚úì Video file: emi_short.mp4\n",
      "\n",
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "# Check that all required files exist\n",
    "files_to_check = [\n",
    "    (\"Forward CSV\", FORWARD_CSV_PATH),\n",
    "    (\"Backward CSV\", BACKWARD_CSV_PATH),\n",
    "    (\"Video file\", VIDEO_PATH),\n",
    "]\n",
    "\n",
    "all_ok = True\n",
    "for name, path in files_to_check:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"‚úì {name}: {path}\")\n",
    "    else:\n",
    "        print(f\"‚úó {name} NOT FOUND: {path}\")\n",
    "        all_ok = False\n",
    "\n",
    "if not all_ok:\n",
    "    raise FileNotFoundError(\"One or more required files are missing. Please check the paths above.\")\n",
    "\n",
    "print(\"\\nAll files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b32aa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info:\n",
      "  Total frames: 750\n",
      "  FPS: 25.0\n",
      "  Resolution: 4512 x 4512\n",
      "  Duration: 30.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get total frame count from video\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Could not open video: {VIDEO_PATH}\")\n",
    "\n",
    "TOTAL_FRAMES = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "WIDTH = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "HEIGHT = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.release()\n",
    "\n",
    "print(f\"Video info:\")\n",
    "print(f\"  Total frames: {TOTAL_FRAMES}\")\n",
    "print(f\"  FPS: {FPS}\")\n",
    "print(f\"  Resolution: {WIDTH} x {HEIGHT}\")\n",
    "print(f\"  Duration: {TOTAL_FRAMES/FPS:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28826ca1",
   "metadata": {},
   "source": [
    "## Step 1: Load and Process Forward Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54bdc6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward raw trajectories:\n",
      "  Rows: 18750\n",
      "  Unique trajectories: 68\n",
      "  Columns: ['TrackID', 'TrajectoryID', 'Index', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "  Frame range: 1 - 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrackID</th>\n",
       "      <th>TrajectoryID</th>\n",
       "      <th>Index</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Theta</th>\n",
       "      <th>FrameID</th>\n",
       "      <th>State</th>\n",
       "      <th>DetectionConfidence</th>\n",
       "      <th>AssignmentConfidence</th>\n",
       "      <th>PositionUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrackID  TrajectoryID  Index   X   Y  Theta  FrameID     State  \\\n",
       "0        0             0      0 NaN NaN    NaN        1  occluded   \n",
       "1        1             1      0 NaN NaN    NaN        1  occluded   \n",
       "2        2             2      0 NaN NaN    NaN        1  occluded   \n",
       "3        3             3      0 NaN NaN    NaN        1  occluded   \n",
       "4        4             4      0 NaN NaN    NaN        1  occluded   \n",
       "\n",
       "   DetectionConfidence  AssignmentConfidence  PositionUncertainty  \n",
       "0                  0.0                   0.0            20.109999  \n",
       "1                  0.0                   0.0            20.109999  \n",
       "2                  0.0                   0.0            20.109999  \n",
       "3                  0.0                   0.0            20.109999  \n",
       "4                  0.0                   0.0            20.109999  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load forward CSV and preview\n",
    "forward_raw = pd.read_csv(FORWARD_CSV_PATH)\n",
    "print(f\"Forward raw trajectories:\")\n",
    "print(f\"  Rows: {len(forward_raw)}\")\n",
    "print(f\"  Unique trajectories: {forward_raw['TrajectoryID'].nunique()}\")\n",
    "print(f\"  Columns: {list(forward_raw.columns)}\")\n",
    "print(f\"  Frame range: {forward_raw['FrameID'].min()} - {forward_raw['FrameID'].max()}\")\n",
    "forward_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fabe1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:03:52,202 - multi_tracker.core.post_processing - INFO - Loaded 18750 rows from emi_short_tracking_forward.csv with columns: ['TrackID', 'TrajectoryID', 'Index', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "2026-02-03 10:03:52,203 - multi_tracker.core.post_processing - INFO - Dropped columns: []\n",
      "2026-02-03 10:03:52,204 - multi_tracker.core.post_processing - INFO - Setting X, Y, Theta to NaN for 4766 occluded/lost detections\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forward trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:03:52,414 - multi_tracker.core.post_processing - INFO - Post-processing stats: {'original_count': 68, 'removed_short': 0, 'broken_velocity': 9, 'broken_distance': 0, 'broken_occlusion': 132, 'final_count': 102}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forward processing stats:\n",
      "  original_count: 68\n",
      "  removed_short: 0\n",
      "  broken_velocity: 9\n",
      "  broken_distance: 0\n",
      "  broken_occlusion: 132\n",
      "  final_count: 102\n",
      "\n",
      "Processed forward trajectories: 102\n"
     ]
    }
   ],
   "source": [
    "# Process forward trajectories\n",
    "print(\"Processing forward trajectories...\")\n",
    "forward_processed, forward_stats = process_trajectories_from_csv(FORWARD_CSV_PATH, params)\n",
    "\n",
    "print(f\"\\nForward processing stats:\")\n",
    "for k, v in forward_stats.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "if forward_processed is not None and not forward_processed.empty:\n",
    "    print(f\"\\nProcessed forward trajectories: {forward_processed['TrajectoryID'].nunique()}\")\n",
    "else:\n",
    "    print(\"WARNING: No forward trajectories after processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08e38b",
   "metadata": {},
   "source": [
    "## Step 2: Load and Process Backward Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2915c1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward raw trajectories:\n",
      "  Rows: 18750\n",
      "  Unique trajectories: 97\n",
      "  Columns: ['TrackID', 'TrajectoryID', 'Index', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "  Frame range (before transform): 1 - 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrackID</th>\n",
       "      <th>TrajectoryID</th>\n",
       "      <th>Index</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Theta</th>\n",
       "      <th>FrameID</th>\n",
       "      <th>State</th>\n",
       "      <th>DetectionConfidence</th>\n",
       "      <th>AssignmentConfidence</th>\n",
       "      <th>PositionUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrackID  TrajectoryID  Index   X   Y  Theta  FrameID     State  \\\n",
       "0        0             0      0 NaN NaN    NaN        1  occluded   \n",
       "1        1             1      0 NaN NaN    NaN        1  occluded   \n",
       "2        2             2      0 NaN NaN    NaN        1  occluded   \n",
       "3        3             3      0 NaN NaN    NaN        1  occluded   \n",
       "4        4             4      0 NaN NaN    NaN        1  occluded   \n",
       "\n",
       "   DetectionConfidence  AssignmentConfidence  PositionUncertainty  \n",
       "0                  0.0                   0.0            20.109999  \n",
       "1                  0.0                   0.0            20.109999  \n",
       "2                  0.0                   0.0            20.109999  \n",
       "3                  0.0                   0.0            20.109999  \n",
       "4                  0.0                   0.0            20.109999  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load backward CSV and preview\n",
    "backward_raw = pd.read_csv(BACKWARD_CSV_PATH)\n",
    "print(f\"Backward raw trajectories:\")\n",
    "print(f\"  Rows: {len(backward_raw)}\")\n",
    "print(f\"  Unique trajectories: {backward_raw['TrajectoryID'].nunique()}\")\n",
    "print(f\"  Columns: {list(backward_raw.columns)}\")\n",
    "print(f\"  Frame range (before transform): {backward_raw['FrameID'].min()} - {backward_raw['FrameID'].max()}\")\n",
    "backward_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4120bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:03:57,135 - multi_tracker.core.post_processing - INFO - Loaded 18750 rows from emi_short_tracking_backward.csv with columns: ['TrackID', 'TrajectoryID', 'Index', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "2026-02-03 10:03:57,136 - multi_tracker.core.post_processing - INFO - Dropped columns: []\n",
      "2026-02-03 10:03:57,137 - multi_tracker.core.post_processing - INFO - Setting X, Y, Theta to NaN for 4853 occluded/lost detections\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing backward trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:03:57,406 - multi_tracker.core.post_processing - INFO - Post-processing stats: {'original_count': 97, 'removed_short': 2, 'broken_velocity': 4, 'broken_distance': 0, 'broken_occlusion': 146, 'final_count': 93}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backward processing stats:\n",
      "  original_count: 97\n",
      "  removed_short: 2\n",
      "  broken_velocity: 4\n",
      "  broken_distance: 0\n",
      "  broken_occlusion: 146\n",
      "  final_count: 93\n",
      "\n",
      "Processed backward trajectories: 93\n"
     ]
    }
   ],
   "source": [
    "# Process backward trajectories\n",
    "print(\"Processing backward trajectories...\")\n",
    "backward_processed, backward_stats = process_trajectories_from_csv(BACKWARD_CSV_PATH, params)\n",
    "\n",
    "print(f\"\\nBackward processing stats:\")\n",
    "for k, v in backward_stats.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "if backward_processed is not None and not backward_processed.empty:\n",
    "    print(f\"\\nProcessed backward trajectories: {backward_processed['TrajectoryID'].nunique()}\")\n",
    "else:\n",
    "    print(\"WARNING: No backward trajectories after processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7efb9",
   "metadata": {},
   "source": [
    "## Step 3: Merge Forward and Backward Trajectories (Conservative Strategy)\n",
    "\n",
    "This step resolves conflicts between forward and backward tracking using a **conservative consensus-based approach**:\n",
    "\n",
    "1. **Adjust backward data**: Frame numbers are flipped (they were stored in reverse), and theta is rotated by 180¬∞\n",
    "2. **Find merge candidates**: Pairs must have at least `MIN_OVERLAP_FRAMES` frames where positions agree (within `AGREEMENT_DISTANCE`)\n",
    "3. **Conservative merge**: \n",
    "   - **Agreeing frames** (both exist within threshold): Merge into average position\n",
    "   - **Disagreeing frames** (both exist but too far apart): Split into separate trajectory segments\n",
    "   - **Unique frames** (only one direction has data): Keep as-is\n",
    "\n",
    "This prioritizes **identity confidence** over trajectory completeness - you may get more trajectory fragments, but each fragment has higher confidence in identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "566462de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward trajectories ready for merge: 102\n",
      "Backward trajectories ready for merge: 93\n"
     ]
    }
   ],
   "source": [
    "# Helper function to convert DataFrame to list of DataFrames (one per trajectory)\n",
    "def prepare_trajs_for_merge(trajs_df):\n",
    "    \"\"\"Convert a single DataFrame to a list of DataFrames (one per trajectory).\"\"\"\n",
    "    if trajs_df is None or trajs_df.empty:\n",
    "        return []\n",
    "    return [group.copy() for _, group in trajs_df.groupby(\"TrajectoryID\")]\n",
    "\n",
    "# Prepare trajectories for merging\n",
    "forward_prepared = prepare_trajs_for_merge(forward_processed)\n",
    "backward_prepared = prepare_trajs_for_merge(backward_processed)\n",
    "\n",
    "print(f\"Forward trajectories ready for merge: {len(forward_prepared)}\")\n",
    "print(f\"Backward trajectories ready for merge: {len(backward_prepared)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d65d19e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:04:02,817 - multi_tracker.core.post_processing - INFO - Starting conservative trajectory resolution with 102 forward and 93 backward trajectories\n",
      "2026-02-03 10:04:02,817 - multi_tracker.core.post_processing - INFO - Parameters: AGREEMENT_DISTANCE=9.62px, MIN_OVERLAP_FRAMES=2, MIN_LENGTH=10\n",
      "2026-02-03 10:04:02,901 - multi_tracker.core.post_processing - INFO - After cleaning: 102 forward, 93 backward\n",
      "2026-02-03 10:04:02,958 - multi_tracker.core.post_processing - INFO - Found 265 merge candidates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving forward and backward trajectories...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:04:04,407 - multi_tracker.core.post_processing - INFO - Removed 73 spatially redundant trajectories\n",
      "2026-02-03 10:04:16,131 - multi_tracker.core.post_processing - INFO - Processed overlapping trajectories in 5 iterations\n",
      "2026-02-03 10:04:16,150 - multi_tracker.core.post_processing - INFO - Final result: 154 trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Resolution complete! Got 154 merged trajectories.\n"
     ]
    }
   ],
   "source": [
    "# Resolve (merge) forward and backward trajectories\n",
    "print(\"Resolving forward and backward trajectories...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "resolved_trajectories = resolve_trajectories(\n",
    "    forward_prepared,\n",
    "    backward_prepared,\n",
    "    video_length=TOTAL_FRAMES,\n",
    "    params=params,\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nResolution complete! Got {len(resolved_trajectories)} merged trajectories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4928fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "  Rows: 13607\n",
      "  Unique trajectories: 154\n",
      "  Frame range: 1 - 750\n"
     ]
    }
   ],
   "source": [
    "# Convert list of DataFrames back to single DataFrame\n",
    "if resolved_trajectories and isinstance(resolved_trajectories, list):\n",
    "    if isinstance(resolved_trajectories[0], pd.DataFrame):\n",
    "        # Reassign TrajectoryID to ensure unique IDs\n",
    "        for new_id, traj_df in enumerate(resolved_trajectories):\n",
    "            traj_df[\"TrajectoryID\"] = new_id\n",
    "        merged_df = pd.concat(resolved_trajectories, ignore_index=True)\n",
    "    else:\n",
    "        # Fallback for old tuple format\n",
    "        all_data = []\n",
    "        for traj_id, traj in enumerate(resolved_trajectories):\n",
    "            for x, y, theta, frame in traj:\n",
    "                all_data.append({\n",
    "                    \"TrajectoryID\": traj_id,\n",
    "                    \"X\": x,\n",
    "                    \"Y\": y,\n",
    "                    \"Theta\": theta,\n",
    "                    \"FrameID\": frame,\n",
    "                })\n",
    "        merged_df = pd.DataFrame(all_data) if all_data else pd.DataFrame()\n",
    "else:\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "print(f\"Merged DataFrame:\")\n",
    "print(f\"  Rows: {len(merged_df)}\")\n",
    "print(f\"  Unique trajectories: {merged_df['TrajectoryID'].nunique() if not merged_df.empty else 0}\")\n",
    "if not merged_df.empty:\n",
    "    print(f\"  Frame range: {merged_df['FrameID'].min()} - {merged_df['FrameID'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c35a2",
   "metadata": {},
   "source": [
    "## Step 4: Apply Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eab9f7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:04:21,930 - multi_tracker.core.post_processing - INFO - Interpolating trajectories using spline method (max_gap=5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying spline interpolation (max_gap=5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:04:22,289 - multi_tracker.core.post_processing - INFO - Interpolation complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation complete!\n",
      "  NaN values before: 1834\n",
      "  NaN values after: 0\n",
      "  Filled: 1834 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Apply interpolation if enabled\n",
    "if INTERPOLATION_METHOD.lower() != \"none\" and not merged_df.empty:\n",
    "    print(f\"Applying {INTERPOLATION_METHOD} interpolation (max_gap={INTERPOLATION_MAX_GAP})...\")\n",
    "    \n",
    "    # Count NaN values before\n",
    "    nan_before = merged_df[['X', 'Y']].isna().sum().sum()\n",
    "    \n",
    "    merged_df = interpolate_trajectories(\n",
    "        merged_df,\n",
    "        method=INTERPOLATION_METHOD,\n",
    "        max_gap=INTERPOLATION_MAX_GAP,\n",
    "    )\n",
    "    \n",
    "    # Count NaN values after\n",
    "    nan_after = merged_df[['X', 'Y']].isna().sum().sum()\n",
    "    \n",
    "    print(f\"Interpolation complete!\")\n",
    "    print(f\"  NaN values before: {nan_before}\")\n",
    "    print(f\"  NaN values after: {nan_after}\")\n",
    "    print(f\"  Filled: {nan_before - nan_after} ({100*(nan_before-nan_after)/max(nan_before,1):.1f}%)\")\n",
    "else:\n",
    "    print(\"Skipping interpolation (disabled or no data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb83947",
   "metadata": {},
   "source": [
    "## Step 5: Scale to Original Video Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b19ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling coordinates from resized space (factor=0.5) to original space...\n",
      "‚úì Coordinates scaled to original video space\n"
     ]
    }
   ],
   "source": [
    "# Scale coordinates back to original video space\n",
    "if RESIZE_FACTOR != 1.0 and not merged_df.empty:\n",
    "    print(f\"Scaling coordinates from resized space (factor={RESIZE_FACTOR}) to original space...\")\n",
    "    \n",
    "    merged_df[[\"X\", \"Y\"]] = merged_df[[\"X\", \"Y\"]] / RESIZE_FACTOR\n",
    "    \n",
    "    if \"Width\" in merged_df.columns:\n",
    "        merged_df[\"Width\"] /= RESIZE_FACTOR\n",
    "    if \"Height\" in merged_df.columns:\n",
    "        merged_df[\"Height\"] /= RESIZE_FACTOR\n",
    "        \n",
    "    print(\"‚úì Coordinates scaled to original video space\")\n",
    "else:\n",
    "    print(\"No scaling needed (resize_factor=1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eed287",
   "metadata": {},
   "source": [
    "## Step 6: Save Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a8758fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged trajectories:\n",
      "  Rows: 13964\n",
      "  Unique trajectories: 154\n",
      "  Columns: ['TrajectoryID', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "  Frame range: 1 - 750\n",
      "  X range: 456.0 - 4046.0\n",
      "  Y range: 328.0 - 3862.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrajectoryID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Theta</th>\n",
       "      <th>FrameID</th>\n",
       "      <th>State</th>\n",
       "      <th>DetectionConfidence</th>\n",
       "      <th>AssignmentConfidence</th>\n",
       "      <th>PositionUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1206.000000</td>\n",
       "      <td>1160.000000</td>\n",
       "      <td>0.675481</td>\n",
       "      <td>36</td>\n",
       "      <td>active</td>\n",
       "      <td>0.838827</td>\n",
       "      <td>0.948763</td>\n",
       "      <td>1.464978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1218.738423</td>\n",
       "      <td>1168.398764</td>\n",
       "      <td>6.265722</td>\n",
       "      <td>37</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1172.000000</td>\n",
       "      <td>0.567744</td>\n",
       "      <td>38</td>\n",
       "      <td>active</td>\n",
       "      <td>0.824358</td>\n",
       "      <td>0.948248</td>\n",
       "      <td>1.445745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1228.663387</td>\n",
       "      <td>1176.211403</td>\n",
       "      <td>6.279717</td>\n",
       "      <td>39</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1184.000000</td>\n",
       "      <td>0.747237</td>\n",
       "      <td>40</td>\n",
       "      <td>active</td>\n",
       "      <td>0.933830</td>\n",
       "      <td>0.960669</td>\n",
       "      <td>0.525624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1252.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>0.627755</td>\n",
       "      <td>41</td>\n",
       "      <td>active</td>\n",
       "      <td>0.931419</td>\n",
       "      <td>0.948831</td>\n",
       "      <td>0.525870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1272.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>0.667517</td>\n",
       "      <td>42</td>\n",
       "      <td>active</td>\n",
       "      <td>0.973645</td>\n",
       "      <td>0.772828</td>\n",
       "      <td>0.526734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1304.000000</td>\n",
       "      <td>1242.000000</td>\n",
       "      <td>0.660133</td>\n",
       "      <td>43</td>\n",
       "      <td>active</td>\n",
       "      <td>0.940105</td>\n",
       "      <td>0.787868</td>\n",
       "      <td>0.529522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1318.000000</td>\n",
       "      <td>1248.000000</td>\n",
       "      <td>0.596525</td>\n",
       "      <td>44</td>\n",
       "      <td>active</td>\n",
       "      <td>0.953296</td>\n",
       "      <td>0.889432</td>\n",
       "      <td>0.534240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1330.000000</td>\n",
       "      <td>1248.000000</td>\n",
       "      <td>0.541193</td>\n",
       "      <td>45</td>\n",
       "      <td>active</td>\n",
       "      <td>0.966093</td>\n",
       "      <td>0.956306</td>\n",
       "      <td>0.535654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrajectoryID            X            Y     Theta  FrameID     State  \\\n",
       "0             0  1206.000000  1160.000000  0.675481       36    active   \n",
       "1             0  1218.738423  1168.398764  6.265722       37  occluded   \n",
       "2             0  1226.000000  1172.000000  0.567744       38    active   \n",
       "3             0  1228.663387  1176.211403  6.279717       39  occluded   \n",
       "4             0  1232.000000  1184.000000  0.747237       40    active   \n",
       "5             0  1252.000000  1198.000000  0.627755       41    active   \n",
       "6             0  1272.000000  1212.000000  0.667517       42    active   \n",
       "7             0  1304.000000  1242.000000  0.660133       43    active   \n",
       "8             0  1318.000000  1248.000000  0.596525       44    active   \n",
       "9             0  1330.000000  1248.000000  0.541193       45    active   \n",
       "\n",
       "   DetectionConfidence  AssignmentConfidence  PositionUncertainty  \n",
       "0             0.838827              0.948763             1.464978  \n",
       "1             0.000000              0.000000             0.542961  \n",
       "2             0.824358              0.948248             1.445745  \n",
       "3             0.000000              0.000000             0.525485  \n",
       "4             0.933830              0.960669             0.525624  \n",
       "5             0.931419              0.948831             0.525870  \n",
       "6             0.973645              0.772828             0.526734  \n",
       "7             0.940105              0.787868             0.529522  \n",
       "8             0.953296              0.889432             0.534240  \n",
       "9             0.966093              0.956306             0.535654  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview final data\n",
    "print(\"Final merged trajectories:\")\n",
    "print(f\"  Rows: {len(merged_df)}\")\n",
    "print(f\"  Unique trajectories: {merged_df['TrajectoryID'].nunique()}\")\n",
    "print(f\"  Columns: {list(merged_df.columns)}\")\n",
    "\n",
    "if not merged_df.empty:\n",
    "    print(f\"  Frame range: {merged_df['FrameID'].min()} - {merged_df['FrameID'].max()}\")\n",
    "    print(f\"  X range: {merged_df['X'].min():.1f} - {merged_df['X'].max():.1f}\")\n",
    "    print(f\"  Y range: {merged_df['Y'].min():.1f} - {merged_df['Y'].max():.1f}\")\n",
    "\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "937eb301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Final trajectories saved to: emi_short_tracking_final.csv\n",
      "  File size: 1271.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "if not merged_df.empty:\n",
    "    merged_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "    print(f\"‚úì Final trajectories saved to: {OUTPUT_CSV_PATH}\")\n",
    "    print(f\"  File size: {os.path.getsize(OUTPUT_CSV_PATH) / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"WARNING: No data to save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc2f78",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "beb612de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "POST-PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "üìÅ Input files:\n",
      "   Forward:  68 trajectories\n",
      "   Backward: 97 trajectories\n",
      "\n",
      "üîß After individual post-processing:\n",
      "   Forward:  102 trajectories\n",
      "   Backward: 93 trajectories\n",
      "\n",
      "üîÄ After merging:\n",
      "   Final: 154 trajectories\n",
      "\n",
      "üíæ Output saved to:\n",
      "   emi_short_tracking_final.csv\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(\"=\"*60)\n",
    "print(\"POST-PROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìÅ Input files:\")\n",
    "print(f\"   Forward:  {forward_raw['TrajectoryID'].nunique()} trajectories\")\n",
    "print(f\"   Backward: {backward_raw['TrajectoryID'].nunique()} trajectories\")\n",
    "\n",
    "print(f\"\\nüîß After individual post-processing:\")\n",
    "print(f\"   Forward:  {forward_stats.get('final_count', 0)} trajectories\")\n",
    "print(f\"   Backward: {backward_stats.get('final_count', 0)} trajectories\")\n",
    "\n",
    "print(f\"\\nüîÄ After merging:\")\n",
    "print(f\"   Final: {merged_df['TrajectoryID'].nunique()} trajectories\")\n",
    "\n",
    "print(f\"\\nüíæ Output saved to:\")\n",
    "print(f\"   {OUTPUT_CSV_PATH}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4636ad",
   "metadata": {},
   "source": [
    "## Optional: Generate Annotated Video\n",
    "\n",
    "Generate a video with trajectory overlays similar to the main tracker output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "571d05b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video output: emi_short_annotated.mp4\n",
      "Options: labels=True, orientation=True, trails=True\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# VIDEO OUTPUT SETTINGS\n",
    "# ===================================================================\n",
    "\n",
    "# Generate video?\n",
    "GENERATE_VIDEO = True\n",
    "\n",
    "# Output video path (auto-generated if None)\n",
    "VIDEO_OUTPUT_PATH = None  # Will be *_annotated.mp4 if None\n",
    "\n",
    "# Visualization options\n",
    "SHOW_LABELS = True          # Show trajectory ID labels\n",
    "SHOW_ORIENTATION = True     # Show orientation arrows\n",
    "SHOW_TRAILS = True          # Show trajectory trails\n",
    "TRAIL_DURATION_SEC = 5.0    # Trail duration in seconds\n",
    "\n",
    "# Drawing parameters (relative to body size)\n",
    "MARKER_SIZE = 0.1           # Circle radius as fraction of body size\n",
    "ARROW_LENGTH = 0.25         # Arrow length as fraction of body size\n",
    "TEXT_SCALE = 3.0            # Text size scale factor\n",
    "\n",
    "# Auto-generate output path\n",
    "if VIDEO_OUTPUT_PATH is None:\n",
    "    base_video, ext_video = os.path.splitext(VIDEO_PATH)\n",
    "    VIDEO_OUTPUT_PATH = f\"{base_video}_annotated.mp4\"\n",
    "\n",
    "print(f\"Video output: {VIDEO_OUTPUT_PATH}\")\n",
    "print(f\"Options: labels={SHOW_LABELS}, orientation={SHOW_ORIENTATION}, trails={SHOW_TRAILS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09e4040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video generation function defined.\n"
     ]
    }
   ],
   "source": [
    "def generate_annotated_video(\n",
    "    video_path, \n",
    "    output_path, \n",
    "    trajectories_df,\n",
    "    reference_body_size=77.0,\n",
    "    show_labels=True,\n",
    "    show_orientation=True,\n",
    "    show_trails=True,\n",
    "    trail_duration_sec=2.0,\n",
    "    marker_size=0.1,\n",
    "    arrow_length=0.25,\n",
    "    text_scale=3.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate annotated video with trajectory overlays.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "        output_path: Path to output video\n",
    "        trajectories_df: DataFrame with columns TrajectoryID, FrameID, X, Y, Theta\n",
    "        reference_body_size: Reference body size in pixels for scaling\n",
    "        show_labels: Show trajectory ID labels\n",
    "        show_orientation: Show orientation arrows\n",
    "        show_trails: Show trajectory trails\n",
    "        trail_duration_sec: Duration of trails in seconds\n",
    "        marker_size: Circle radius as fraction of body size\n",
    "        arrow_length: Arrow length as fraction of body size\n",
    "        text_scale: Text size scale factor\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    from tqdm.notebook import tqdm\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video: {video_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"Input video: {frame_width}x{frame_height} @ {fps:.1f} FPS, {total_frames} frames\")\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    if not out.isOpened():\n",
    "        cap.release()\n",
    "        raise ValueError(f\"Could not create output video: {output_path}\")\n",
    "    \n",
    "    # Calculate trail duration in frames\n",
    "    trail_duration_frames = int(trail_duration_sec * fps)\n",
    "    \n",
    "    # Scale drawing parameters by body size\n",
    "    marker_radius = int(marker_size * reference_body_size)\n",
    "    arrow_len = int(arrow_length * reference_body_size)\n",
    "    text_size = 0.5 * text_scale\n",
    "    marker_thickness = max(2, int(0.15 * reference_body_size))\n",
    "    \n",
    "    # Default colors (BGR format for OpenCV)\n",
    "    default_colors = [\n",
    "        (0, 255, 0),    # Green\n",
    "        (255, 0, 0),    # Blue\n",
    "        (0, 0, 255),    # Red\n",
    "        (255, 255, 0),  # Cyan\n",
    "        (255, 0, 255),  # Magenta\n",
    "        (0, 255, 255),  # Yellow\n",
    "        (128, 0, 255),  # Orange\n",
    "        (255, 128, 0),  # Light blue\n",
    "        (0, 128, 255),  # Orange-red\n",
    "        (128, 255, 0),  # Lime\n",
    "    ]\n",
    "    \n",
    "    # Build lookup for trajectories by frame\n",
    "    print(\"Building trajectory lookup...\")\n",
    "    traj_by_frame = {}\n",
    "    traj_by_track = {}\n",
    "    \n",
    "    for _, row in trajectories_df.iterrows():\n",
    "        frame_num = int(row[\"FrameID\"])\n",
    "        track_id = int(row[\"TrajectoryID\"])\n",
    "        \n",
    "        if frame_num not in traj_by_frame:\n",
    "            traj_by_frame[frame_num] = []\n",
    "        traj_by_frame[frame_num].append(row)\n",
    "        \n",
    "        if track_id not in traj_by_track:\n",
    "            traj_by_track[track_id] = []\n",
    "        traj_by_track[track_id].append(row)\n",
    "    \n",
    "    # Process video frame by frame\n",
    "    print(f\"Generating video: {output_path}\")\n",
    "    \n",
    "    for frame_idx in tqdm(range(total_frames), desc=\"Processing frames\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Get trajectories for this frame\n",
    "        frame_trajs = traj_by_frame.get(frame_idx, [])\n",
    "        \n",
    "        # Draw trails first (underneath current positions)\n",
    "        if show_trails:\n",
    "            for traj in frame_trajs:\n",
    "                track_id = int(traj[\"TrajectoryID\"])\n",
    "                color = default_colors[track_id % len(default_colors)]\n",
    "                \n",
    "                # Get trail points (past N frames)\n",
    "                trail_points = []\n",
    "                if track_id in traj_by_track:\n",
    "                    for past_row in traj_by_track[track_id]:\n",
    "                        past_frame = int(past_row[\"FrameID\"])\n",
    "                        if frame_idx - trail_duration_frames <= past_frame < frame_idx:\n",
    "                            px, py = past_row[\"X\"], past_row[\"Y\"]\n",
    "                            if not pd.isna(px) and not pd.isna(py):\n",
    "                                trail_points.append((int(px), int(py), past_frame))\n",
    "                \n",
    "                # Draw trail as fading line segments\n",
    "                if len(trail_points) > 1:\n",
    "                    trail_points.sort(key=lambda p: p[2])\n",
    "                    for i in range(len(trail_points) - 1):\n",
    "                        pt1 = (trail_points[i][0], trail_points[i][1])\n",
    "                        pt2 = (trail_points[i + 1][0], trail_points[i + 1][1])\n",
    "                        \n",
    "                        # Calculate opacity based on age\n",
    "                        age = frame_idx - trail_points[i][2]\n",
    "                        alpha = 1.0 - (age / trail_duration_frames)\n",
    "                        faded_color = tuple(int(c * alpha) for c in color)\n",
    "                        \n",
    "                        cv2.line(frame, pt1, pt2, faded_color, max(1, marker_thickness // 2))\n",
    "        \n",
    "        # Draw current positions\n",
    "        for traj in frame_trajs:\n",
    "            track_id = int(traj[\"TrajectoryID\"])\n",
    "            cx, cy = traj[\"X\"], traj[\"Y\"]\n",
    "            \n",
    "            # Skip if NaN\n",
    "            if pd.isna(cx) or pd.isna(cy):\n",
    "                continue\n",
    "            \n",
    "            cx, cy = int(cx), int(cy)\n",
    "            color = default_colors[track_id % len(default_colors)]\n",
    "            \n",
    "            # Draw circle at position\n",
    "            cv2.circle(frame, (cx, cy), marker_radius, color, marker_thickness)\n",
    "            \n",
    "            # Draw label\n",
    "            if show_labels:\n",
    "                label = f\"ID{track_id}\"\n",
    "                label_offset = int(marker_radius + 5)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    label,\n",
    "                    (cx + label_offset, cy - label_offset),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    text_size,\n",
    "                    color,\n",
    "                    max(1, int(text_scale * 2)),\n",
    "                )\n",
    "            \n",
    "            # Draw orientation arrow\n",
    "            if show_orientation and \"Theta\" in traj.index and not pd.isna(traj[\"Theta\"]):\n",
    "                heading = traj[\"Theta\"]\n",
    "                end_x = int(cx + arrow_len * np.cos(heading))\n",
    "                end_y = int(cy + arrow_len * np.sin(heading))\n",
    "                cv2.arrowedLine(\n",
    "                    frame,\n",
    "                    (cx, cy),\n",
    "                    (end_x, end_y),\n",
    "                    color,\n",
    "                    marker_thickness,\n",
    "                    tipLength=0.3,\n",
    "                )\n",
    "        \n",
    "        # Write frame\n",
    "        out.write(frame)\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"‚úì Video saved to: {output_path}\")\n",
    "    print(f\"  File size: {os.path.getsize(output_path) / (1024*1024):.1f} MB\")\n",
    "\n",
    "print(\"Video generation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d8254ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input video: 4512x4512 @ 25.0 FPS, 750 frames\n",
      "Building trajectory lookup...\n",
      "Generating video: emi_short_annotated.mp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20607fbefc24442b91739a467817ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing frames:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Video saved to: emi_short_annotated.mp4\n",
      "  File size: 116.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Generate the annotated video\n",
    "if GENERATE_VIDEO and not merged_df.empty:\n",
    "    generate_annotated_video(\n",
    "        video_path=VIDEO_PATH,\n",
    "        output_path=VIDEO_OUTPUT_PATH,\n",
    "        trajectories_df=merged_df,\n",
    "        reference_body_size=REFERENCE_BODY_SIZE,  # Use original body size (coords already scaled)\n",
    "        show_labels=SHOW_LABELS,\n",
    "        show_orientation=SHOW_ORIENTATION,\n",
    "        show_trails=SHOW_TRAILS,\n",
    "        trail_duration_sec=TRAIL_DURATION_SEC,\n",
    "        marker_size=MARKER_SIZE,\n",
    "        arrow_length=ARROW_LENGTH,\n",
    "        text_scale=TEXT_SCALE,\n",
    "    )\n",
    "else:\n",
    "    if not GENERATE_VIDEO:\n",
    "        print(\"Video generation disabled (GENERATE_VIDEO=False)\")\n",
    "    else:\n",
    "        print(\"No trajectory data available for video generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac83204",
   "metadata": {},
   "source": [
    "## Optional: Quick Static Plots\n",
    "\n",
    "Generate static plots for quick overview (useful if video generation is slow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e99c85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Plot trajectory overview\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not merged_df.empty:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Plot 1: Spatial trajectories\n",
    "    ax1 = axes[0]\n",
    "    for traj_id in merged_df['TrajectoryID'].unique():\n",
    "        traj = merged_df[merged_df['TrajectoryID'] == traj_id]\n",
    "        ax1.plot(traj['X'], traj['Y'], alpha=0.7, linewidth=0.5)\n",
    "    ax1.set_xlabel('X (pixels)')\n",
    "    ax1.set_ylabel('Y (pixels)')\n",
    "    ax1.set_title(f'All Trajectories ({merged_df[\"TrajectoryID\"].nunique()} total)')\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.invert_yaxis()  # Flip Y axis to match image coordinates\n",
    "    \n",
    "    # Plot 2: Trajectory lengths\n",
    "    ax2 = axes[1]\n",
    "    traj_lengths = merged_df.groupby('TrajectoryID').size()\n",
    "    ax2.hist(traj_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax2.set_xlabel('Trajectory Length (frames)')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title(f'Trajectory Length Distribution\\nMean: {traj_lengths.mean():.1f}, Median: {traj_lengths.median():.1f}')\n",
    "    ax2.axvline(traj_lengths.mean(), color='red', linestyle='--', label=f'Mean ({traj_lengths.mean():.1f})')\n",
    "    ax2.axvline(traj_lengths.median(), color='orange', linestyle='--', label=f'Median ({traj_lengths.median():.1f})')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to visualize!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c42396d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-trajectory statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Frame</th>\n",
       "      <th>End Frame</th>\n",
       "      <th>Length</th>\n",
       "      <th>X Mean</th>\n",
       "      <th>X Std</th>\n",
       "      <th>Y Mean</th>\n",
       "      <th>Y Std</th>\n",
       "      <th>Duration (s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrajectoryID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>600</td>\n",
       "      <td>565</td>\n",
       "      <td>2130.07</td>\n",
       "      <td>412.64</td>\n",
       "      <td>2476.43</td>\n",
       "      <td>689.64</td>\n",
       "      <td>22.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>549</td>\n",
       "      <td>496</td>\n",
       "      <td>899.74</td>\n",
       "      <td>217.52</td>\n",
       "      <td>670.87</td>\n",
       "      <td>248.36</td>\n",
       "      <td>19.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>618.00</td>\n",
       "      <td>9.13</td>\n",
       "      <td>551.23</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>230</td>\n",
       "      <td>214</td>\n",
       "      <td>756.63</td>\n",
       "      <td>157.72</td>\n",
       "      <td>585.08</td>\n",
       "      <td>255.36</td>\n",
       "      <td>8.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>244</td>\n",
       "      <td>173</td>\n",
       "      <td>829.84</td>\n",
       "      <td>195.81</td>\n",
       "      <td>691.17</td>\n",
       "      <td>279.31</td>\n",
       "      <td>6.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>574</td>\n",
       "      <td>592</td>\n",
       "      <td>19</td>\n",
       "      <td>3944.49</td>\n",
       "      <td>46.03</td>\n",
       "      <td>3472.25</td>\n",
       "      <td>85.87</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>449</td>\n",
       "      <td>461</td>\n",
       "      <td>13</td>\n",
       "      <td>1168.41</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1158.87</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>305</td>\n",
       "      <td>378</td>\n",
       "      <td>74</td>\n",
       "      <td>1123.50</td>\n",
       "      <td>46.77</td>\n",
       "      <td>1093.36</td>\n",
       "      <td>37.83</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>59</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>1076.32</td>\n",
       "      <td>46.53</td>\n",
       "      <td>1008.78</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>732.38</td>\n",
       "      <td>41.86</td>\n",
       "      <td>1078.49</td>\n",
       "      <td>36.62</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Start Frame  End Frame  Length   X Mean   X Std   Y Mean  \\\n",
       "TrajectoryID                                                             \n",
       "0                      36        600     565  2130.07  412.64  2476.43   \n",
       "1                      54        549     496   899.74  217.52   670.87   \n",
       "2                       1         15      15   618.00    9.13   551.23   \n",
       "3                      17        230     214   756.63  157.72   585.08   \n",
       "4                      72        244     173   829.84  195.81   691.17   \n",
       "...                   ...        ...     ...      ...     ...      ...   \n",
       "149                   574        592      19  3944.49   46.03  3472.25   \n",
       "150                   449        461      13  1168.41    1.65  1158.87   \n",
       "151                   305        378      74  1123.50   46.77  1093.36   \n",
       "152                    59         69      11  1076.32   46.53  1008.78   \n",
       "153                     1         13      13   732.38   41.86  1078.49   \n",
       "\n",
       "               Y Std  Duration (s)  \n",
       "TrajectoryID                        \n",
       "0             689.64         22.56  \n",
       "1             248.36         19.80  \n",
       "2               8.01          0.56  \n",
       "3             255.36          8.52  \n",
       "4             279.31          6.88  \n",
       "...              ...           ...  \n",
       "149            85.87          0.72  \n",
       "150             1.20          0.48  \n",
       "151            37.83          2.92  \n",
       "152            11.35          0.40  \n",
       "153            36.62          0.48  \n",
       "\n",
       "[154 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional: Per-trajectory statistics\n",
    "if not merged_df.empty:\n",
    "    traj_stats = merged_df.groupby('TrajectoryID').agg({\n",
    "        'FrameID': ['min', 'max', 'count'],\n",
    "        'X': ['mean', 'std'],\n",
    "        'Y': ['mean', 'std'],\n",
    "    }).round(2)\n",
    "    \n",
    "    traj_stats.columns = ['Start Frame', 'End Frame', 'Length', 'X Mean', 'X Std', 'Y Mean', 'Y Std']\n",
    "    traj_stats['Duration (s)'] = (traj_stats['End Frame'] - traj_stats['Start Frame']) / FPS\n",
    "    \n",
    "    print(\"Per-trajectory statistics:\")\n",
    "    display(traj_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a930a5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DIAGNOSTIC: Checking for overlapping trajectories at same locations\n",
      "============================================================\n",
      "\n",
      "‚ö†Ô∏è  Found 36 frame-pairs with overlapping trajectories!\n",
      "\n",
      "Unique trajectory pairs with overlap:\n",
      "    Traj1  Traj2  NumFrames\n",
      "0       8     59          1\n",
      "1      10     15          1\n",
      "2      16     22          1\n",
      "3      31    143          8\n",
      "4      46     95          1\n",
      "5      47    116          1\n",
      "6      48     54          1\n",
      "7      49     54          1\n",
      "8      49     56          2\n",
      "9      51    135          1\n",
      "10     53    109          1\n",
      "11     58    141          1\n",
      "12     59     60          1\n",
      "13     66    120          1\n",
      "14     70     81          1\n",
      "15     71     87          1\n",
      "16     78    111          1\n",
      "17     82    138          1\n",
      "18     86    112          1\n",
      "19     88    108          1\n",
      "20    102    104          1\n",
      "21    106    146          1\n",
      "22    107    151          1\n",
      "23    125    140          1\n",
      "24    141    149          1\n",
      "25    142    144          1\n",
      "26    142    149          1\n",
      "27    144    149          1\n",
      "\n",
      "Sample overlapping frames:\n",
      "   FrameID  Traj1  Traj2   Distance           X1           Y1      X2      Y2\n",
      "0       79    102    104   0.000000   964.000000  1150.000000   964.0  1150.0\n",
      "1      134     16     22   0.000000  1144.000000  1044.000000  1144.0  1044.0\n",
      "2      152     51    135   0.000000  1204.000000  1198.000000  1204.0  1198.0\n",
      "3      200     48     54   0.000000  1468.000000  1364.000000  1468.0  1364.0\n",
      "4      202     49     54   0.000000  1460.000000  1364.000000  1460.0  1364.0\n",
      "5      203     49     56   0.000000  1484.000000  1420.000000  1484.0  1420.0\n",
      "6      204     49     56  16.782216  1499.173548  1408.035127  1494.0  1424.0\n",
      "7      261      8     59   7.857754  1439.814288  1399.547646  1442.0  1392.0\n",
      "8      264     59     60   0.000000  1418.000000  1348.000000  1418.0  1348.0\n",
      "9      309    107    151   0.000000  1304.000000  1218.000000  1304.0  1218.0\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC: Check for duplicate/overlapping trajectories at same locations\n",
    "print(\"=\"*60)\n",
    "print(\"DIAGNOSTIC: Checking for overlapping trajectories at same locations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# For each frame, check if any two trajectories are too close together\n",
    "DIAG_DISTANCE_THRESHOLD = params.get(\"AGREEMENT_DISTANCE\", 15.0) * 2  # 1x body size\n",
    "\n",
    "duplicates_found = []\n",
    "for frame in merged_df[\"FrameID\"].unique():\n",
    "    frame_data = merged_df[merged_df[\"FrameID\"] == frame]\n",
    "    if len(frame_data) <= 1:\n",
    "        continue\n",
    "    \n",
    "    traj_ids = frame_data[\"TrajectoryID\"].values\n",
    "    xs = frame_data[\"X\"].values\n",
    "    ys = frame_data[\"Y\"].values\n",
    "    \n",
    "    for i in range(len(traj_ids)):\n",
    "        for j in range(i+1, len(traj_ids)):\n",
    "            if pd.isna(xs[i]) or pd.isna(xs[j]):\n",
    "                continue\n",
    "            dist = np.sqrt((xs[i] - xs[j])**2 + (ys[i] - ys[j])**2)\n",
    "            if dist < DIAG_DISTANCE_THRESHOLD:\n",
    "                duplicates_found.append({\n",
    "                    \"FrameID\": frame,\n",
    "                    \"Traj1\": traj_ids[i],\n",
    "                    \"Traj2\": traj_ids[j],\n",
    "                    \"Distance\": dist,\n",
    "                    \"X1\": xs[i], \"Y1\": ys[i],\n",
    "                    \"X2\": xs[j], \"Y2\": ys[j]\n",
    "                })\n",
    "\n",
    "if duplicates_found:\n",
    "    dup_df = pd.DataFrame(duplicates_found)\n",
    "    print(f\"\\n‚ö†Ô∏è  Found {len(dup_df)} frame-pairs with overlapping trajectories!\")\n",
    "    print(f\"\\nUnique trajectory pairs with overlap:\")\n",
    "    pair_counts = dup_df.groupby([\"Traj1\", \"Traj2\"]).size().reset_index(name=\"NumFrames\")\n",
    "    print(pair_counts.to_string())\n",
    "    \n",
    "    print(f\"\\nSample overlapping frames:\")\n",
    "    print(dup_df.head(10).to_string())\n",
    "else:\n",
    "    print(\"\\n‚úì No overlapping trajectories found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1391b1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total overlapping frames: 36\n",
      "\n",
      "Trajectory pairs with most overlap:\n",
      "    Traj1  Traj2  NumFrames\n",
      "3      31    143          8\n",
      "8      49     56          2\n",
      "0       8     59          1\n",
      "15     71     87          1\n",
      "26    142    149          1\n",
      "25    142    144          1\n",
      "24    141    149          1\n",
      "23    125    140          1\n",
      "22    107    151          1\n",
      "21    106    146          1\n"
     ]
    }
   ],
   "source": [
    "# Summary: Show just the first 5 pairs of duplicates\n",
    "if duplicates_found:\n",
    "    print(f\"Total overlapping frames: {len(duplicates_found)}\")\n",
    "    print(f\"\\nTrajectory pairs with most overlap:\")\n",
    "    pair_counts = pd.DataFrame(duplicates_found).groupby([\"Traj1\", \"Traj2\"]).size().reset_index(name=\"NumFrames\")\n",
    "    pair_counts = pair_counts.sort_values(\"NumFrames\", ascending=False)\n",
    "    print(pair_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16820c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory 30: frames 509 - 611 (103 points)\n",
      "Trajectory 219: frames nan - nan (0 points)\n",
      "\n",
      "--- Checking original forward/backward data ---\n",
      "Forward traj 4 overlaps with result Traj 30: 101 frames\n",
      "Forward traj 9 overlaps with result Traj 30: 103 frames\n",
      "Forward traj 13 overlaps with result Traj 30: 51 frames\n",
      "Forward traj 18 overlaps with result Traj 30: 103 frames\n",
      "Forward traj 19 overlaps with result Traj 30: 103 frames\n",
      "Forward traj 23 overlaps with result Traj 30: 103 frames\n",
      "Forward traj 30 overlaps with result Traj 30: 55 frames\n",
      "Forward traj 34 overlaps with result Traj 30: 103 frames\n",
      "Forward traj 40 overlaps with result Traj 30: 61 frames\n",
      "Forward traj 61 overlaps with result Traj 30: 76 frames\n",
      "Forward traj 62 overlaps with result Traj 30: 92 frames\n",
      "Forward traj 68 overlaps with result Traj 30: 54 frames\n",
      "Forward traj 72 overlaps with result Traj 30: 87 frames\n",
      "Forward traj 75 overlaps with result Traj 30: 59 frames\n",
      "Forward traj 79 overlaps with result Traj 30: 103 frames\n",
      "Forward traj 80 overlaps with result Traj 30: 103 frames\n",
      "Forward traj 83 overlaps with result Traj 30: 65 frames\n",
      "Forward traj 86 overlaps with result Traj 30: 61 frames\n",
      "Forward traj 88 overlaps with result Traj 30: 52 frames\n",
      "Forward traj 89 overlaps with result Traj 30: 51 frames\n",
      "Backward traj 9 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 12 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 21 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 24 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 26 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 37 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 42 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 43 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 46 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 51 overlaps with result Traj 30: 70 frames\n",
      "Backward traj 56 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 58 overlaps with result Traj 30: 61 frames\n",
      "Backward traj 63 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 64 overlaps with result Traj 30: 82 frames\n",
      "Backward traj 67 overlaps with result Traj 30: 103 frames\n",
      "Backward traj 68 overlaps with result Traj 30: 90 frames\n",
      "Backward traj 71 overlaps with result Traj 30: 91 frames\n",
      "Backward traj 77 overlaps with result Traj 30: 73 frames\n",
      "Backward traj 79 overlaps with result Traj 30: 103 frames\n"
     ]
    }
   ],
   "source": [
    "# Investigate the worst offending pair (Traj 30 and 219)\n",
    "traj30 = merged_df[merged_df[\"TrajectoryID\"] == 30][[\"FrameID\", \"X\", \"Y\"]].sort_values(\"FrameID\")\n",
    "traj219 = merged_df[merged_df[\"TrajectoryID\"] == 219][[\"FrameID\", \"X\", \"Y\"]].sort_values(\"FrameID\")\n",
    "\n",
    "print(f\"Trajectory 30: frames {traj30['FrameID'].min()} - {traj30['FrameID'].max()} ({len(traj30)} points)\")\n",
    "print(f\"Trajectory 219: frames {traj219['FrameID'].min()} - {traj219['FrameID'].max()} ({len(traj219)} points)\")\n",
    "\n",
    "# Check the forward/backward trajectories to see what happened\n",
    "print(\"\\n--- Checking original forward/backward data ---\")\n",
    "# Find if these trajectories came from forward or backward\n",
    "for i, traj in enumerate(forward_prepared):\n",
    "    if len(traj) > 0:\n",
    "        overlap_30 = set(traj[\"FrameID\"]).intersection(set(traj30[\"FrameID\"]))\n",
    "        overlap_219 = set(traj[\"FrameID\"]).intersection(set(traj219[\"FrameID\"]))\n",
    "        \n",
    "        if len(overlap_30) > 50:\n",
    "            print(f\"Forward traj {i} overlaps with result Traj 30: {len(overlap_30)} frames\")\n",
    "        if len(overlap_219) > 50:\n",
    "            print(f\"Forward traj {i} overlaps with result Traj 219: {len(overlap_219)} frames\")\n",
    "\n",
    "for i, traj in enumerate(backward_prepared):\n",
    "    if len(traj) > 0:\n",
    "        overlap_30 = set(traj[\"FrameID\"]).intersection(set(traj30[\"FrameID\"]))\n",
    "        overlap_219 = set(traj[\"FrameID\"]).intersection(set(traj219[\"FrameID\"]))\n",
    "        \n",
    "        if len(overlap_30) > 50:\n",
    "            print(f\"Backward traj {i} overlaps with result Traj 30: {len(overlap_30)} frames\")\n",
    "        if len(overlap_219) > 50:\n",
    "            print(f\"Backward traj {i} overlaps with result Traj 219: {len(overlap_219)} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1aa98383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trajectory 30 spatial sources (threshold=9.625px):\n",
      "\n",
      "Trajectory 219 spatial sources (threshold=9.625px):\n"
     ]
    }
   ],
   "source": [
    "# Check spatial overlap between duplicate trajectories and their sources\n",
    "# Find which forward/backward trajectories SPATIALLY match with Traj 30 and 219\n",
    "\n",
    "def find_spatial_source(target_traj, source_trajs, source_name, threshold=15.0):\n",
    "    \"\"\"Find which source trajectories spatially match the target.\"\"\"\n",
    "    target_by_frame = {row[\"FrameID\"]: (row[\"X\"], row[\"Y\"]) \n",
    "                        for _, row in target_traj.iterrows() \n",
    "                        if not pd.isna(row[\"X\"])}\n",
    "    \n",
    "    matches = []\n",
    "    for i, src in enumerate(source_trajs):\n",
    "        if len(src) == 0:\n",
    "            continue\n",
    "        \n",
    "        agreeing_frames = 0\n",
    "        common_frames = 0\n",
    "        \n",
    "        for _, row in src.iterrows():\n",
    "            frame = row[\"FrameID\"]\n",
    "            if frame in target_by_frame and not pd.isna(row[\"X\"]):\n",
    "                common_frames += 1\n",
    "                tx, ty = target_by_frame[frame]\n",
    "                dist = np.sqrt((row[\"X\"] - tx)**2 + (row[\"Y\"] - ty)**2)\n",
    "                if dist < threshold:\n",
    "                    agreeing_frames += 1\n",
    "        \n",
    "        if agreeing_frames > 10:  # At least 10 agreeing frames\n",
    "            matches.append({\n",
    "                \"source\": f\"{source_name}_{i}\",\n",
    "                \"agreeing\": agreeing_frames,\n",
    "                \"common\": common_frames,\n",
    "                \"pct\": agreeing_frames / common_frames * 100 if common_frames > 0 else 0\n",
    "            })\n",
    "    \n",
    "    return sorted(matches, key=lambda x: -x[\"agreeing\"])\n",
    "\n",
    "threshold = params.get(\"AGREEMENT_DISTANCE\", 15.0)\n",
    "\n",
    "print(f\"\\nTrajectory 30 spatial sources (threshold={threshold}px):\")\n",
    "sources_30 = find_spatial_source(traj30, forward_prepared, \"forward\", threshold)\n",
    "sources_30 += find_spatial_source(traj30, backward_prepared, \"backward\", threshold)\n",
    "sources_30 = sorted(sources_30, key=lambda x: -x[\"agreeing\"])[:10]\n",
    "for s in sources_30:\n",
    "    print(f\"  {s['source']}: {s['agreeing']}/{s['common']} frames ({s['pct']:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTrajectory 219 spatial sources (threshold={threshold}px):\")\n",
    "sources_219 = find_spatial_source(traj219, forward_prepared, \"forward\", threshold)\n",
    "sources_219 += find_spatial_source(traj219, backward_prepared, \"backward\", threshold)\n",
    "sources_219 = sorted(sources_219, key=lambda x: -x[\"agreeing\"])[:10]\n",
    "for s in sources_219:\n",
    "    print(f\"  {s['source']}: {s['agreeing']}/{s['common']} frames ({s['pct']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d34a9ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traj 30 and 219 have 0 common frames\n",
      "\n",
      "Sample common frames (first 10):\n",
      " Frame |    T30 X    T30 Y |   T219 X   T219 Y |     Dist\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Direct comparison: are trajectories 30 and 219 really at same location?\n",
    "traj30_full = merged_df[merged_df[\"TrajectoryID\"] == 30].sort_values(\"FrameID\")\n",
    "traj219_full = merged_df[merged_df[\"TrajectoryID\"] == 219].sort_values(\"FrameID\")\n",
    "\n",
    "# Check common frames\n",
    "common_frames = set(traj30_full[\"FrameID\"]).intersection(set(traj219_full[\"FrameID\"]))\n",
    "print(f\"Traj 30 and 219 have {len(common_frames)} common frames\")\n",
    "\n",
    "# Look at a few common frames\n",
    "t30_by_frame = {row[\"FrameID\"]: row for _, row in traj30_full.iterrows()}\n",
    "t219_by_frame = {row[\"FrameID\"]: row for _, row in traj219_full.iterrows()}\n",
    "\n",
    "print(\"\\nSample common frames (first 10):\")\n",
    "print(f\"{'Frame':>6} | {'T30 X':>8} {'T30 Y':>8} | {'T219 X':>8} {'T219 Y':>8} | {'Dist':>8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "sample_frames = sorted(common_frames)[:10]\n",
    "for frame in sample_frames:\n",
    "    r30 = t30_by_frame[frame]\n",
    "    r219 = t219_by_frame[frame]\n",
    "    dist = np.sqrt((r30[\"X\"] - r219[\"X\"])**2 + (r30[\"Y\"] - r219[\"Y\"])**2) if not pd.isna(r30[\"X\"]) and not pd.isna(r219[\"X\"]) else float('nan')\n",
    "    print(f\"{frame:>6} | {r30['X']:>8.2f} {r30['Y']:>8.2f} | {r219['X']:>8.2f} {r219['Y']:>8.2f} | {dist:>8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ef5b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of resolved trajectories: 154\n",
      "\n",
      "Checking for exact duplicate trajectories in result...\n",
      "Found 0 trajectory signatures with duplicates\n"
     ]
    }
   ],
   "source": [
    "# Check: what's the relationship between resolved trajectories before they got renumbered?\n",
    "# Let's look at the resolve output directly\n",
    "\n",
    "# Re-import to get fresh function\n",
    "from multi_tracker.core.post_processing import resolve_trajectories\n",
    "\n",
    "# Re-run with debug output\n",
    "import logging\n",
    "logging.getLogger(\"multi_tracker.core.post_processing\").setLevel(logging.DEBUG)\n",
    "\n",
    "# Count how many result trajectories we get\n",
    "print(f\"Number of resolved trajectories: {len(resolved_trajectories)}\")\n",
    "\n",
    "# Check for exact duplicates in the resolved trajectories\n",
    "print(\"\\nChecking for exact duplicate trajectories in result...\")\n",
    "from collections import defaultdict\n",
    "\n",
    "# Hash each trajectory by its frame-position signature\n",
    "def traj_signature(df):\n",
    "    \"\"\"Create a signature for a trajectory based on first few positions.\"\"\"\n",
    "    df_sorted = df.sort_values(\"FrameID\").head(5)\n",
    "    sig = tuple((int(row[\"FrameID\"]), round(row[\"X\"], 1), round(row[\"Y\"], 1)) \n",
    "                for _, row in df_sorted.iterrows() if not pd.isna(row[\"X\"]))\n",
    "    return sig\n",
    "\n",
    "sig_to_indices = defaultdict(list)\n",
    "for i, traj in enumerate(resolved_trajectories):\n",
    "    if isinstance(traj, pd.DataFrame) and len(traj) > 0:\n",
    "        sig = traj_signature(traj)\n",
    "        sig_to_indices[sig].append(i)\n",
    "\n",
    "duplicates = {sig: indices for sig, indices in sig_to_indices.items() if len(indices) > 1}\n",
    "print(f\"Found {len(duplicates)} trajectory signatures with duplicates\")\n",
    "if duplicates:\n",
    "    for sig, indices in list(duplicates.items())[:5]:\n",
    "        print(f\"  Signature {sig[:2]}...: trajectories {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "223b3542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trajectory index 6:\n",
      "  Length: 15\n",
      "  Frame range: 292 - 312\n",
      "  First 3 rows:\n",
      "   FrameID      X      Y\n",
      "0      292  632.0  592.0\n",
      "1      294  643.0  603.0\n",
      "2      295  651.0  615.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m dup_pair = [\u001b[32m6\u001b[39m, \u001b[32m186\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dup_pair:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     traj = \u001b[43mresolved_trajectories\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTrajectory index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(traj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Trace where the duplicates come from\n",
    "# Look at trajectory pair [6, 186] - both have signature starting at frame 670\n",
    "\n",
    "dup_pair = [6, 186]\n",
    "for i in dup_pair:\n",
    "    traj = resolved_trajectories[i]\n",
    "    print(f\"\\nTrajectory index {i}:\")\n",
    "    print(f\"  Length: {len(traj)}\")\n",
    "    print(f\"  Frame range: {traj['FrameID'].min()} - {traj['FrameID'].max()}\")\n",
    "    if \"_source\" in traj.columns:\n",
    "        print(f\"  Source: {traj['_source'].iloc[0]}\")\n",
    "    print(f\"  First 3 rows:\")\n",
    "    print(traj[[\"FrameID\", \"X\", \"Y\"]].head(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c634e72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for sources at frame 670, pos (1966.0, 1857.0)...\n",
      "\n",
      "FORWARD trajectories at this location:\n",
      "  Forward 9: frames 205-750, pos at frame 670: (1966.0, 1857.0)\n",
      "\n",
      "BACKWARD trajectories at this location:\n"
     ]
    }
   ],
   "source": [
    "# Find which input trajectories have data at frame 670 with position (1966, 1857)\n",
    "target_frame = 670\n",
    "target_x, target_y = 1966.0, 1857.0\n",
    "threshold = 5.0\n",
    "\n",
    "print(f\"Looking for sources at frame {target_frame}, pos ({target_x}, {target_y})...\\n\")\n",
    "\n",
    "print(\"FORWARD trajectories at this location:\")\n",
    "for i, traj in enumerate(forward_prepared):\n",
    "    frame_data = traj[traj[\"FrameID\"] == target_frame]\n",
    "    if len(frame_data) > 0:\n",
    "        row = frame_data.iloc[0]\n",
    "        if not pd.isna(row[\"X\"]):\n",
    "            dist = np.sqrt((row[\"X\"] - target_x)**2 + (row[\"Y\"] - target_y)**2)\n",
    "            if dist < threshold:\n",
    "                print(f\"  Forward {i}: frames {traj['FrameID'].min()}-{traj['FrameID'].max()}, \"\n",
    "                      f\"pos at frame {target_frame}: ({row['X']:.1f}, {row['Y']:.1f})\")\n",
    "\n",
    "print(\"\\nBACKWARD trajectories at this location:\")\n",
    "for i, traj in enumerate(backward_prepared):\n",
    "    frame_data = traj[traj[\"FrameID\"] == target_frame]\n",
    "    if len(frame_data) > 0:\n",
    "        row = frame_data.iloc[0]\n",
    "        if not pd.isna(row[\"X\"]):\n",
    "            dist = np.sqrt((row[\"X\"] - target_x)**2 + (row[\"Y\"] - target_y)**2)\n",
    "            if dist < threshold:\n",
    "                print(f\"  Backward {i}: frames {traj['FrameID'].min()}-{traj['FrameID'].max()}, \"\n",
    "                      f\"pos at frame {target_frame}: ({row['X']:.1f}, {row['Y']:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "672bb0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_FRAMES = 750\n",
      "Frame 670 in backward would originally be frame: 81 = 81\n",
      "\n",
      "Checking backward_raw at original frame 81...\n",
      "Found 25 rows\n",
      "      TrajectoryID       X       Y\n",
      "2000            39  1971.0  1777.0\n",
      "2001            45   393.0   522.0\n",
      "2002            25  2016.0  1787.0\n",
      "2003            26  1012.0   968.0\n",
      "2004            27  1912.0  1843.0\n",
      "2005            28  1762.0  1800.0\n",
      "2006            30  1966.0  1857.0\n",
      "2007            32  1936.0  1664.0\n",
      "2008            33  1734.0  1705.0\n",
      "2009            34  1947.0  1725.0\n",
      "2010            35  1858.0  1837.0\n",
      "2011            36  1914.0  1703.0\n",
      "2012            37  1898.0  1773.0\n",
      "2013            38  1824.0  1874.0\n",
      "2014            47   317.0   260.0\n",
      "2015             1   349.0   575.0\n",
      "2016            46   580.0   525.0\n",
      "2017            44  1809.0  1819.0\n",
      "2018            40  1936.0  1797.0\n",
      "2019            41  1874.0  1813.0\n",
      "2020            42  1931.0  1774.0\n",
      "2021            43  1818.0  1849.0\n",
      "2022            10   769.0   702.0\n",
      "2023            29  1933.0  1771.0\n",
      "2024            31  1843.0  1798.0\n"
     ]
    }
   ],
   "source": [
    "# The backward_prepared already has frame adjustment applied (done by the notebook's post_processing)\n",
    "# Let's check if there's a backward trajectory that overlaps after the resolve step\n",
    "\n",
    "# Actually, I realize the issue might be in how backward trajectories are processed\n",
    "# Let me check the raw backward data before frame adjustment\n",
    "print(f\"TOTAL_FRAMES = {TOTAL_FRAMES}\")\n",
    "print(f\"Frame 670 in backward would originally be frame: {TOTAL_FRAMES + 1 - 670} = {TOTAL_FRAMES + 1 - 670}\")\n",
    "\n",
    "# Check what's at that original frame in backward_raw\n",
    "orig_backward_frame = TOTAL_FRAMES + 1 - 670\n",
    "print(f\"\\nChecking backward_raw at original frame {orig_backward_frame}...\")\n",
    "\n",
    "if \"FrameID\" in backward_raw.columns:\n",
    "    frame_data = backward_raw[backward_raw[\"FrameID\"] == orig_backward_frame]\n",
    "    print(f\"Found {len(frame_data)} rows\")\n",
    "    if len(frame_data) > 0:\n",
    "        print(frame_data[[\"TrajectoryID\", \"X\", \"Y\"]].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed97a28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward prepared frame ranges (first 10):\n",
      "  Backward 0: frames 3 - 39\n",
      "  Backward 1: frames 3 - 191\n",
      "  Backward 2: frames 4 - 47\n",
      "  Backward 3: frames 4 - 22\n",
      "  Backward 4: frames 5 - 24\n",
      "  Backward 5: frames 11 - 98\n",
      "  Backward 6: frames 11 - 171\n",
      "  Backward 7: frames 178 - 316\n",
      "  Backward 8: frames 12 - 102\n",
      "  Backward 9: frames 110 - 750\n",
      "\n",
      "Forward prepared frame ranges (first 10):\n",
      "  Forward 0: frames 3 - 50\n",
      "  Forward 1: frames 57 - 102\n",
      "  Forward 2: frames 109 - 209\n",
      "  Forward 3: frames 216 - 504\n",
      "  Forward 4: frames 511 - 616\n",
      "  Forward 5: frames 626 - 637\n",
      "  Forward 6: frames 645 - 750\n",
      "  Forward 7: frames 2 - 153\n",
      "  Forward 8: frames 162 - 198\n",
      "  Forward 9: frames 205 - 750\n"
     ]
    }
   ],
   "source": [
    "# Check backward_prepared frame ranges - have they been adjusted yet?\n",
    "print(\"Backward prepared frame ranges (first 10):\")\n",
    "for i, traj in enumerate(backward_prepared[:10]):\n",
    "    print(f\"  Backward {i}: frames {traj['FrameID'].min()} - {traj['FrameID'].max()}\")\n",
    "\n",
    "# Check forward_prepared frame ranges\n",
    "print(\"\\nForward prepared frame ranges (first 10):\")\n",
    "for i, traj in enumerate(forward_prepared[:10]):\n",
    "    print(f\"  Forward {i}: frames {traj['FrameID'].min()} - {traj['FrameID'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31eb78fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicate frames within trajectories...\n",
      "\n",
      "Done checking.\n"
     ]
    }
   ],
   "source": [
    "# Check if there are duplicate frames within trajectories\n",
    "print(\"Checking for duplicate frames within trajectories...\")\n",
    "for i, traj in enumerate(resolved_trajectories):\n",
    "    if isinstance(traj, pd.DataFrame):\n",
    "        dup_frames = traj[\"FrameID\"].duplicated().sum()\n",
    "        if dup_frames > 0:\n",
    "            print(f\"  Trajectory {i}: {dup_frames} duplicate frames!\")\n",
    "            print(f\"    Duplicate frame IDs: {traj[traj['FrameID'].duplicated(keep=False)]['FrameID'].unique()[:5]}\")\n",
    "            \n",
    "print(\"\\nDone checking.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2531d63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for overlapping forward trajectories at same location...\n",
      "Found 0 overlapping forward trajectory pairs!\n"
     ]
    }
   ],
   "source": [
    "# Check: Are there multiple forward trajectories at the same location?\n",
    "# i.e., do any forward trajectories overlap spatially at the same frames?\n",
    "\n",
    "print(\"Checking for overlapping forward trajectories at same location...\")\n",
    "\n",
    "# For each pair of forward trajectories, check if they overlap spatially\n",
    "threshold = params.get(\"AGREEMENT_DISTANCE\", 19.25)\n",
    "overlapping_forward = []\n",
    "\n",
    "for i in range(len(forward_prepared)):\n",
    "    t1 = forward_prepared[i]\n",
    "    t1_by_frame = {row[\"FrameID\"]: (row[\"X\"], row[\"Y\"]) \n",
    "                   for _, row in t1.iterrows() if not pd.isna(row[\"X\"])}\n",
    "    \n",
    "    for j in range(i+1, len(forward_prepared)):\n",
    "        t2 = forward_prepared[j]\n",
    "        common_frames = set(t1_by_frame.keys()).intersection(set(t2[\"FrameID\"]))\n",
    "        \n",
    "        if len(common_frames) < 5:\n",
    "            continue\n",
    "        \n",
    "        agreeing = 0\n",
    "        for frame in common_frames:\n",
    "            t2_row = t2[t2[\"FrameID\"] == frame].iloc[0]\n",
    "            if pd.isna(t2_row[\"X\"]):\n",
    "                continue\n",
    "            t1_x, t1_y = t1_by_frame[frame]\n",
    "            dist = np.sqrt((t1_x - t2_row[\"X\"])**2 + (t1_y - t2_row[\"Y\"])**2)\n",
    "            if dist < threshold:\n",
    "                agreeing += 1\n",
    "        \n",
    "        if agreeing >= 5:\n",
    "            overlapping_forward.append((i, j, agreeing, len(common_frames)))\n",
    "\n",
    "print(f\"Found {len(overlapping_forward)} overlapping forward trajectory pairs!\")\n",
    "if overlapping_forward:\n",
    "    print(\"Top 5:\")\n",
    "    for i, j, agree, common in sorted(overlapping_forward, key=lambda x: -x[2])[:5]:\n",
    "        print(f\"  Forward {i} & {j}: {agree}/{common} agreeing frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0e228c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for overlapping backward trajectories at same location...\n",
      "Found 0 overlapping backward trajectory pairs!\n"
     ]
    }
   ],
   "source": [
    "# Check backward after frame adjustment\n",
    "print(\"Checking for overlapping backward trajectories at same location...\")\n",
    "\n",
    "# We need to adjust backward frames to compare properly\n",
    "adjusted_backward = []\n",
    "for traj in backward_prepared:\n",
    "    adj_traj = traj.copy()\n",
    "    adj_traj[\"FrameID\"] = TOTAL_FRAMES + 1 - adj_traj[\"FrameID\"]\n",
    "    adjusted_backward.append(adj_traj)\n",
    "\n",
    "overlapping_backward = []\n",
    "for i in range(len(adjusted_backward)):\n",
    "    t1 = adjusted_backward[i]\n",
    "    t1_by_frame = {row[\"FrameID\"]: (row[\"X\"], row[\"Y\"]) \n",
    "                   for _, row in t1.iterrows() if not pd.isna(row[\"X\"])}\n",
    "    \n",
    "    for j in range(i+1, len(adjusted_backward)):\n",
    "        t2 = adjusted_backward[j]\n",
    "        common_frames = set(t1_by_frame.keys()).intersection(set(t2[\"FrameID\"]))\n",
    "        \n",
    "        if len(common_frames) < 5:\n",
    "            continue\n",
    "        \n",
    "        agreeing = 0\n",
    "        for frame in common_frames:\n",
    "            t2_row = t2[t2[\"FrameID\"] == frame].iloc[0]\n",
    "            if pd.isna(t2_row[\"X\"]):\n",
    "                continue\n",
    "            t1_x, t1_y = t1_by_frame[frame]\n",
    "            dist = np.sqrt((t1_x - t2_row[\"X\"])**2 + (t1_y - t2_row[\"Y\"])**2)\n",
    "            if dist < threshold:\n",
    "                agreeing += 1\n",
    "        \n",
    "        if agreeing >= 5:\n",
    "            overlapping_backward.append((i, j, agreeing, len(common_frames)))\n",
    "\n",
    "print(f\"Found {len(overlapping_backward)} overlapping backward trajectory pairs!\")\n",
    "if overlapping_backward:\n",
    "    print(\"Top 5:\")\n",
    "    for i, j, agree, common in sorted(overlapping_backward, key=lambda x: -x[2])[:5]:\n",
    "        print(f\"  Backward {i} & {j}: {agree}/{common} agreeing frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3bafb6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 265 merge candidates\n",
      "\n",
      "Forward indices used: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]...\n",
      "Backward indices used: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]...\n",
      "\n",
      "Forward trajectories appearing in multiple candidates: 65\n",
      "  Examples: [(0, 6), (1, 2), (2, 2), (3, 3), (4, 4)]\n",
      "Backward trajectories appearing in multiple candidates: 62\n",
      "  Examples: [(9, 12), (26, 3), (47, 2), (57, 2), (60, 2)]\n"
     ]
    }
   ],
   "source": [
    "# Check: do multiple merge candidates exist that would merge into same output?\n",
    "# i.e., forward_i merges with backward_j, and forward_k merges with backward_l,\n",
    "# but all four are actually at the same location?\n",
    "\n",
    "from multi_tracker.core.post_processing import resolve_trajectories as _orig_resolve\n",
    "\n",
    "# Recreate the merge candidate finding logic\n",
    "AGREEMENT_DISTANCE = params.get(\"AGREEMENT_DISTANCE\", 19.25)\n",
    "MIN_OVERLAP = params.get(\"MIN_OVERLAP_FRAMES\", 5)\n",
    "\n",
    "# Adjust backward frames\n",
    "adj_backward = []\n",
    "for traj in backward_prepared:\n",
    "    adj = traj.copy()\n",
    "    adj[\"FrameID\"] = TOTAL_FRAMES + 1 - adj[\"FrameID\"]\n",
    "    adj_backward.append(adj)\n",
    "\n",
    "# Find all merge candidates\n",
    "merge_candidates = []\n",
    "for fi, fwd in enumerate(forward_prepared):\n",
    "    fwd_frames = set(fwd[\"FrameID\"])\n",
    "    fwd_by_frame = {row[\"FrameID\"]: row for _, row in fwd.iterrows()}\n",
    "    \n",
    "    for bi, bwd in enumerate(adj_backward):\n",
    "        bwd_frames = set(bwd[\"FrameID\"])\n",
    "        common_frames = fwd_frames.intersection(bwd_frames)\n",
    "        \n",
    "        if len(common_frames) < MIN_OVERLAP:\n",
    "            continue\n",
    "        \n",
    "        bwd_by_frame = {row[\"FrameID\"]: row for _, row in bwd.iterrows()}\n",
    "        agreeing = 0\n",
    "        for frame in common_frames:\n",
    "            fwd_row = fwd_by_frame[frame]\n",
    "            bwd_row = bwd_by_frame[frame]\n",
    "            if pd.isna(fwd_row[\"X\"]) or pd.isna(bwd_row[\"X\"]):\n",
    "                continue\n",
    "            dist = np.sqrt((fwd_row[\"X\"] - bwd_row[\"X\"])**2 + (fwd_row[\"Y\"] - bwd_row[\"Y\"])**2)\n",
    "            if dist <= AGREEMENT_DISTANCE:\n",
    "                agreeing += 1\n",
    "        \n",
    "        if agreeing >= MIN_OVERLAP:\n",
    "            merge_candidates.append((fi, bi, agreeing, len(common_frames)))\n",
    "\n",
    "print(f\"Found {len(merge_candidates)} merge candidates\")\n",
    "print(f\"\\nForward indices used: {sorted(set(m[0] for m in merge_candidates))[:20]}...\")\n",
    "print(f\"Backward indices used: {sorted(set(m[1] for m in merge_candidates))[:20]}...\")\n",
    "\n",
    "# Check if any forward/backward is used in multiple candidates\n",
    "from collections import Counter\n",
    "fwd_counts = Counter(m[0] for m in merge_candidates)\n",
    "bwd_counts = Counter(m[1] for m in merge_candidates)\n",
    "\n",
    "multi_fwd = {k: v for k, v in fwd_counts.items() if v > 1}\n",
    "multi_bwd = {k: v for k, v in bwd_counts.items() if v > 1}\n",
    "\n",
    "print(f\"\\nForward trajectories appearing in multiple candidates: {len(multi_fwd)}\")\n",
    "if multi_fwd:\n",
    "    print(f\"  Examples: {list(multi_fwd.items())[:5]}\")\n",
    "    \n",
    "print(f\"Backward trajectories appearing in multiple candidates: {len(multi_bwd)}\")\n",
    "if multi_bwd:\n",
    "    print(f\"  Examples: {list(multi_bwd.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d01157e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward 37 matches with backward trajectories:\n",
      "  Backward 9: 356/438 agreeing frames\n",
      "  Backward 88: 30/68 agreeing frames\n",
      "  Backward 69: 4/57 agreeing frames\n",
      "  Backward 66: 2/83 agreeing frames\n",
      "  Backward 90: 2/11 agreeing frames\n",
      "\n",
      "Are these backward trajectories at the same location?\n",
      "  Backward 9: frame 321 at (1521.0, 1470.0)\n",
      "  Backward 66: frame 430 at (1969.0, 1698.0)\n",
      "  Backward 69: frame 437 at (1903.0, 1642.0)\n"
     ]
    }
   ],
   "source": [
    "# Investigate: which backward trajectories matched forward_37?\n",
    "fwd_37_matches = [(fi, bi, agree, common) for fi, bi, agree, common in merge_candidates if fi == 37]\n",
    "print(f\"Forward 37 matches with backward trajectories:\")\n",
    "for fi, bi, agree, common in sorted(fwd_37_matches, key=lambda x: -x[2]):\n",
    "    print(f\"  Backward {bi}: {agree}/{common} agreeing frames\")\n",
    "\n",
    "# Check if these backward trajectories are at the same location\n",
    "print(\"\\nAre these backward trajectories at the same location?\")\n",
    "for _, bi, _, _ in fwd_37_matches[:3]:\n",
    "    bwd = adj_backward[bi]\n",
    "    sample_frame = bwd[\"FrameID\"].iloc[len(bwd)//2]  # middle frame\n",
    "    sample_row = bwd[bwd[\"FrameID\"] == sample_frame].iloc[0]\n",
    "    print(f\"  Backward {bi}: frame {sample_frame} at ({sample_row['X']:.1f}, {sample_row['Y']:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e09bfd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward 37: frames 33-470 (438 points)\n",
      "\n",
      "Position at start (frame 33):\n",
      "          X      Y\n",
      "6608  470.0  530.0\n",
      "\n",
      "Position at middle (frame 400):\n",
      "           X       Y\n",
      "6975  1996.0  1717.0\n",
      "\n",
      "Position at end (frame 470):\n",
      "           X       Y\n",
      "7045  1979.0  1833.0\n"
     ]
    }
   ],
   "source": [
    "# Check forward_37's trajectory\n",
    "fwd_37 = forward_prepared[37]\n",
    "print(f\"Forward 37: frames {fwd_37['FrameID'].min()}-{fwd_37['FrameID'].max()} ({len(fwd_37)} points)\")\n",
    "print(f\"\\nPosition at start (frame {fwd_37['FrameID'].min()}):\")\n",
    "print(fwd_37[fwd_37[\"FrameID\"] == fwd_37[\"FrameID\"].min()][[\"X\", \"Y\"]].to_string())\n",
    "print(f\"\\nPosition at middle (frame 400):\")\n",
    "mid_data = fwd_37[fwd_37[\"FrameID\"] == 400]\n",
    "if len(mid_data) > 0:\n",
    "    print(mid_data[[\"X\", \"Y\"]].to_string())\n",
    "else:\n",
    "    print(\"No data at frame 400\")\n",
    "print(f\"\\nPosition at end (frame {fwd_37['FrameID'].max()}):\")\n",
    "print(fwd_37[fwd_37[\"FrameID\"] == fwd_37[\"FrameID\"].max()][[\"X\", \"Y\"]].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1ef1750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding sources for frame 670 at (1966.0, 1857.0)...\n",
      "\n",
      "Forward trajectories:\n",
      "  Forward 9: pos (1966.0, 1857.0), full range: frames 205-750\n",
      "\n",
      "Backward trajectories (after frame adjustment):\n",
      "  Backward 17: pos (1966.0, 1857.0), full range: frames 666-740\n"
     ]
    }
   ],
   "source": [
    "# The duplicate trajectories were at index 6 and 186 in resolved_trajectories\n",
    "# Let's trace them carefully\n",
    "\n",
    "# Trajectory 6: frames 670-689, position (1966, 1857)\n",
    "# Trajectory 186: frames 670-682, position (1966, 1857)\n",
    "\n",
    "# Which forward/backward match frame 670 at (1966, 1857)?\n",
    "target_frame = 670\n",
    "target_x, target_y = 1966.0, 1857.0\n",
    "threshold = 5.0\n",
    "\n",
    "print(f\"Finding sources for frame {target_frame} at ({target_x}, {target_y})...\")\n",
    "\n",
    "# Forward sources\n",
    "print(\"\\nForward trajectories:\")\n",
    "for i, fwd in enumerate(forward_prepared):\n",
    "    frame_data = fwd[fwd[\"FrameID\"] == target_frame]\n",
    "    if len(frame_data) > 0:\n",
    "        row = frame_data.iloc[0]\n",
    "        if not pd.isna(row[\"X\"]):\n",
    "            dist = np.sqrt((row[\"X\"] - target_x)**2 + (row[\"Y\"] - target_y)**2)\n",
    "            if dist < threshold:\n",
    "                print(f\"  Forward {i}: pos ({row['X']:.1f}, {row['Y']:.1f}), \"\n",
    "                      f\"full range: frames {fwd['FrameID'].min()}-{fwd['FrameID'].max()}\")\n",
    "\n",
    "# Backward sources (after adjustment)\n",
    "print(\"\\nBackward trajectories (after frame adjustment):\")\n",
    "for i, bwd in enumerate(adj_backward):\n",
    "    frame_data = bwd[bwd[\"FrameID\"] == target_frame]\n",
    "    if len(frame_data) > 0:\n",
    "        row = frame_data.iloc[0]\n",
    "        if not pd.isna(row[\"X\"]):\n",
    "            dist = np.sqrt((row[\"X\"] - target_x)**2 + (row[\"Y\"] - target_y)**2)\n",
    "            if dist < threshold:\n",
    "                print(f\"  Backward {i}: pos ({row['X']:.1f}, {row['Y']:.1f}), \"\n",
    "                      f\"full range: frames {bwd['FrameID'].min()}-{bwd['FrameID'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "266f3076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward 9 + Backward 17: 54/75 agreeing frames\n",
      "\n",
      "All merge candidates involving Forward 9:\n",
      "  Forward 9 + Backward 17: 54/75 agreeing frames\n",
      "  Forward 9 + Backward 31: 6/218 agreeing frames\n",
      "  Forward 9 + Backward 37: 404/531 agreeing frames\n",
      "  Forward 9 + Backward 40: 3/46 agreeing frames\n",
      "  Forward 9 + Backward 50: 3/277 agreeing frames\n",
      "  Forward 9 + Backward 81: 3/3 agreeing frames\n",
      "\n",
      "All merge candidates involving Backward 17:\n",
      "  Forward 9 + Backward 17: 54/75 agreeing frames\n",
      "  Forward 92 + Backward 17: 9/75 agreeing frames\n"
     ]
    }
   ],
   "source": [
    "# Check if Forward 9 and Backward 17 are merge candidates\n",
    "for fi, bi, agree, common in merge_candidates:\n",
    "    if fi == 9 and bi == 17:\n",
    "        print(f\"Forward 9 + Backward 17: {agree}/{common} agreeing frames\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Forward 9 + Backward 17 NOT in merge candidates!\")\n",
    "\n",
    "# Check all candidates involving Forward 9\n",
    "print(\"\\nAll merge candidates involving Forward 9:\")\n",
    "for fi, bi, agree, common in merge_candidates:\n",
    "    if fi == 9:\n",
    "        print(f\"  Forward 9 + Backward {bi}: {agree}/{common} agreeing frames\")\n",
    "\n",
    "# Check all candidates involving Backward 17\n",
    "print(\"\\nAll merge candidates involving Backward 17:\")\n",
    "for fi, bi, agree, common in merge_candidates:\n",
    "    if bi == 17:\n",
    "        print(f\"  Forward {fi} + Backward 17: {agree}/{common} agreeing frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50d5c212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:07:15,606 - multi_tracker.core.post_processing - INFO - Starting conservative trajectory resolution with 102 forward and 93 backward trajectories\n",
      "2026-02-03 10:07:15,606 - multi_tracker.core.post_processing - INFO - Parameters: AGREEMENT_DISTANCE=9.62px, MIN_OVERLAP_FRAMES=2, MIN_LENGTH=10\n",
      "2026-02-03 10:07:15,704 - multi_tracker.core.post_processing - INFO - After cleaning: 102 forward, 93 backward\n",
      "2026-02-03 10:07:15,705 - multi_tracker.core.post_processing - DEBUG - Using Numba-accelerated merge candidate search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module reloaded. Re-running trajectory resolution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:07:16,052 - multi_tracker.core.post_processing - INFO - Found 265 merge candidates\n",
      "2026-02-03 10:07:16,053 - multi_tracker.core.post_processing - DEBUG - Merging forward_62 with backward_21: 530/530 agreeing frames\n",
      "2026-02-03 10:07:16,099 - multi_tracker.core.post_processing - DEBUG - Merging forward_11 with backward_56: 451/451 agreeing frames\n",
      "2026-02-03 10:07:16,140 - multi_tracker.core.post_processing - DEBUG - Merging forward_9 with backward_37: 404/449 agreeing frames\n",
      "2026-02-03 10:07:16,197 - multi_tracker.core.post_processing - DEBUG - Merging forward_23 with backward_42: 390/462 agreeing frames\n",
      "2026-02-03 10:07:16,249 - multi_tracker.core.post_processing - DEBUG - Merging forward_37 with backward_9: 356/390 agreeing frames\n",
      "2026-02-03 10:07:16,297 - multi_tracker.core.post_processing - DEBUG - Merging forward_33 with backward_67: 322/322 agreeing frames\n",
      "2026-02-03 10:07:16,329 - multi_tracker.core.post_processing - DEBUG - Merging forward_19 with backward_26: 318/502 agreeing frames\n",
      "2026-02-03 10:07:16,388 - multi_tracker.core.post_processing - DEBUG - Merging forward_80 with backward_45: 310/311 agreeing frames\n",
      "2026-02-03 10:07:16,416 - multi_tracker.core.post_processing - DEBUG - Merging forward_39 with backward_12: 283/379 agreeing frames\n",
      "2026-02-03 10:07:16,465 - multi_tracker.core.post_processing - DEBUG - Merging forward_17 with backward_63: 274/349 agreeing frames\n",
      "2026-02-03 10:07:16,500 - multi_tracker.core.post_processing - DEBUG - Merging forward_42 with backward_58: 271/290 agreeing frames\n",
      "2026-02-03 10:07:16,538 - multi_tracker.core.post_processing - DEBUG - Merging forward_29 with backward_68: 270/270 agreeing frames\n",
      "2026-02-03 10:07:16,563 - multi_tracker.core.post_processing - DEBUG - Merging forward_24 with backward_43: 258/260 agreeing frames\n",
      "2026-02-03 10:07:16,604 - multi_tracker.core.post_processing - DEBUG - Merging forward_52 with backward_64: 253/279 agreeing frames\n",
      "2026-02-03 10:07:16,635 - multi_tracker.core.post_processing - DEBUG - Merging forward_65 with backward_53: 240/250 agreeing frames\n",
      "2026-02-03 10:07:16,664 - multi_tracker.core.post_processing - DEBUG - Merging forward_3 with backward_34: 226/236 agreeing frames\n",
      "2026-02-03 10:07:16,696 - multi_tracker.core.post_processing - DEBUG - Merging forward_44 with backward_24: 222/222 agreeing frames\n",
      "2026-02-03 10:07:16,720 - multi_tracker.core.post_processing - DEBUG - Merging forward_74 with backward_50: 221/221 agreeing frames\n",
      "2026-02-03 10:07:16,742 - multi_tracker.core.post_processing - DEBUG - Merging forward_71 with backward_32: 194/197 agreeing frames\n",
      "2026-02-03 10:07:16,772 - multi_tracker.core.post_processing - DEBUG - Merging forward_60 with backward_16: 188/189 agreeing frames\n",
      "2026-02-03 10:07:16,789 - multi_tracker.core.post_processing - DEBUG - Merging forward_12 with backward_46: 183/197 agreeing frames\n",
      "2026-02-03 10:07:16,812 - multi_tracker.core.post_processing - DEBUG - Merging forward_67 with backward_31: 179/179 agreeing frames\n",
      "2026-02-03 10:07:16,830 - multi_tracker.core.post_processing - DEBUG - Merging forward_64 with backward_79: 175/179 agreeing frames\n",
      "2026-02-03 10:07:16,851 - multi_tracker.core.post_processing - DEBUG - Merging forward_78 with backward_36: 167/167 agreeing frames\n",
      "2026-02-03 10:07:16,865 - multi_tracker.core.post_processing - DEBUG - Merging forward_84 with backward_6: 148/148 agreeing frames\n",
      "2026-02-03 10:07:16,879 - multi_tracker.core.post_processing - DEBUG - Merging forward_88 with backward_41: 143/143 agreeing frames\n",
      "2026-02-03 10:07:16,892 - multi_tracker.core.post_processing - DEBUG - Merging forward_55 with backward_70: 125/125 agreeing frames\n",
      "2026-02-03 10:07:16,903 - multi_tracker.core.post_processing - DEBUG - Merging forward_86 with backward_22: 122/150 agreeing frames\n",
      "2026-02-03 10:07:16,928 - multi_tracker.core.post_processing - DEBUG - Merging forward_14 with backward_25: 117/152 agreeing frames\n",
      "2026-02-03 10:07:16,944 - multi_tracker.core.post_processing - DEBUG - Merging forward_83 with backward_7: 117/124 agreeing frames\n",
      "2026-02-03 10:07:16,955 - multi_tracker.core.post_processing - DEBUG - Merging forward_7 with backward_72: 116/130 agreeing frames\n",
      "2026-02-03 10:07:16,969 - multi_tracker.core.post_processing - DEBUG - Merging forward_61 with backward_15: 109/111 agreeing frames\n",
      "2026-02-03 10:07:16,983 - multi_tracker.core.post_processing - DEBUG - Merging forward_18 with backward_35: 98/190 agreeing frames\n",
      "2026-02-03 10:07:17,011 - multi_tracker.core.post_processing - DEBUG - Merging forward_63 with backward_20: 98/118 agreeing frames\n",
      "2026-02-03 10:07:17,023 - multi_tracker.core.post_processing - DEBUG - Merging forward_54 with backward_59: 95/121 agreeing frames\n",
      "2026-02-03 10:07:17,041 - multi_tracker.core.post_processing - DEBUG - Merging forward_68 with backward_30: 91/102 agreeing frames\n",
      "2026-02-03 10:07:17,054 - multi_tracker.core.post_processing - DEBUG - Merging forward_2 with backward_51: 88/93 agreeing frames\n",
      "2026-02-03 10:07:17,063 - multi_tracker.core.post_processing - DEBUG - Merging forward_51 with backward_65: 85/95 agreeing frames\n",
      "2026-02-03 10:07:17,075 - multi_tracker.core.post_processing - DEBUG - Merging forward_90 with backward_5: 81/81 agreeing frames\n",
      "2026-02-03 10:07:17,083 - multi_tracker.core.post_processing - DEBUG - Merging forward_70 with backward_10: 80/80 agreeing frames\n",
      "2026-02-03 10:07:17,093 - multi_tracker.core.post_processing - DEBUG - Merging forward_72 with backward_19: 74/79 agreeing frames\n",
      "2026-02-03 10:07:17,104 - multi_tracker.core.post_processing - DEBUG - Merging forward_34 with backward_66: 73/74 agreeing frames\n",
      "2026-02-03 10:07:17,119 - multi_tracker.core.post_processing - DEBUG - Merging forward_47 with backward_78: 68/70 agreeing frames\n",
      "2026-02-03 10:07:17,130 - multi_tracker.core.post_processing - DEBUG - Merging forward_45 with backward_23: 62/62 agreeing frames\n",
      "2026-02-03 10:07:17,136 - multi_tracker.core.post_processing - DEBUG - Merging forward_43 with backward_87: 58/69 agreeing frames\n",
      "2026-02-03 10:07:17,146 - multi_tracker.core.post_processing - DEBUG - Merging forward_75 with backward_49: 54/55 agreeing frames\n",
      "2026-02-03 10:07:17,152 - multi_tracker.core.post_processing - DEBUG - Merging forward_38 with backward_89: 53/61 agreeing frames\n",
      "2026-02-03 10:07:17,161 - multi_tracker.core.post_processing - DEBUG - Merging forward_25 with backward_55: 52/72 agreeing frames\n",
      "2026-02-03 10:07:17,173 - multi_tracker.core.post_processing - DEBUG - Merging forward_59 with backward_84: 49/59 agreeing frames\n",
      "2026-02-03 10:07:17,192 - multi_tracker.core.post_processing - DEBUG - Merging forward_6 with backward_8: 47/80 agreeing frames\n",
      "2026-02-03 10:07:17,203 - multi_tracker.core.post_processing - DEBUG - Merging forward_50 with backward_77: 45/56 agreeing frames\n",
      "2026-02-03 10:07:17,216 - multi_tracker.core.post_processing - DEBUG - Merging forward_20 with backward_83: 41/54 agreeing frames\n",
      "2026-02-03 10:07:17,224 - multi_tracker.core.post_processing - DEBUG - Merging forward_56 with backward_69: 39/45 agreeing frames\n",
      "2026-02-03 10:07:17,233 - multi_tracker.core.post_processing - DEBUG - Merging forward_10 with backward_47: 36/37 agreeing frames\n",
      "2026-02-03 10:07:17,238 - multi_tracker.core.post_processing - DEBUG - Merging forward_96 with backward_2: 34/34 agreeing frames\n",
      "2026-02-03 10:07:17,244 - multi_tracker.core.post_processing - DEBUG - Merging forward_91 with backward_13: 31/34 agreeing frames\n",
      "2026-02-03 10:07:17,251 - multi_tracker.core.post_processing - DEBUG - Merging forward_98 with backward_0: 31/31 agreeing frames\n",
      "2026-02-03 10:07:17,256 - multi_tracker.core.post_processing - DEBUG - Merging forward_8 with backward_81: 29/29 agreeing frames\n",
      "2026-02-03 10:07:17,261 - multi_tracker.core.post_processing - DEBUG - Merging forward_87 with backward_61: 28/28 agreeing frames\n",
      "2026-02-03 10:07:17,265 - multi_tracker.core.post_processing - DEBUG - Merging forward_1 with backward_52: 27/37 agreeing frames\n",
      "2026-02-03 10:07:17,274 - multi_tracker.core.post_processing - DEBUG - Merging forward_26 with backward_88: 27/34 agreeing frames\n",
      "2026-02-03 10:07:17,283 - multi_tracker.core.post_processing - DEBUG - Merging forward_81 with backward_75: 27/27 agreeing frames\n",
      "2026-02-03 10:07:17,287 - multi_tracker.core.post_processing - DEBUG - Merging forward_79 with backward_18: 25/98 agreeing frames\n",
      "2026-02-03 10:07:17,311 - multi_tracker.core.post_processing - DEBUG - Merging forward_93 with backward_38: 17/19 agreeing frames\n",
      "2026-02-03 10:07:17,318 - multi_tracker.core.post_processing - DEBUG - Merging forward_0 with backward_57: 16/27 agreeing frames\n",
      "2026-02-03 10:07:17,325 - multi_tracker.core.post_processing - DEBUG - Merging forward_58 with backward_85: 15/23 agreeing frames\n",
      "2026-02-03 10:07:17,331 - multi_tracker.core.post_processing - DEBUG - Merging forward_41 with backward_29: 14/15 agreeing frames\n",
      "2026-02-03 10:07:17,339 - multi_tracker.core.post_processing - DEBUG - Merging forward_82 with backward_74: 13/13 agreeing frames\n",
      "2026-02-03 10:07:17,341 - multi_tracker.core.post_processing - DEBUG - Merging forward_100 with backward_3: 12/16 agreeing frames\n",
      "2026-02-03 10:07:17,344 - multi_tracker.core.post_processing - DEBUG - Merging forward_32 with backward_91: 11/11 agreeing frames\n",
      "2026-02-03 10:07:17,347 - multi_tracker.core.post_processing - DEBUG - Merging forward_16 with backward_82: 10/14 agreeing frames\n",
      "2026-02-03 10:07:17,353 - multi_tracker.core.post_processing - DEBUG - Merging forward_35 with backward_11: 10/10 agreeing frames\n",
      "2026-02-03 10:07:17,356 - multi_tracker.core.post_processing - DEBUG - Merging forward_92 with backward_17: 9/59 agreeing frames\n",
      "2026-02-03 10:07:17,366 - multi_tracker.core.post_processing - DEBUG - Merging forward_49 with backward_33: 8/8 agreeing frames\n",
      "2026-02-03 10:07:17,369 - multi_tracker.core.post_processing - DEBUG - Merging forward_101 with backward_4: 8/10 agreeing frames\n",
      "2026-02-03 10:07:17,372 - multi_tracker.core.post_processing - DEBUG - Merging forward_28 with backward_86: 6/18 agreeing frames\n",
      "2026-02-03 10:07:17,376 - multi_tracker.core.post_processing - DEBUG - Merging forward_48 with backward_54: 6/11 agreeing frames\n",
      "2026-02-03 10:07:17,380 - multi_tracker.core.post_processing - DEBUG - Merging forward_66 with backward_80: 5/5 agreeing frames\n",
      "2026-02-03 10:07:17,383 - multi_tracker.core.post_processing - DEBUG - Merging forward_94 with backward_27: 3/17 agreeing frames\n",
      "2026-02-03 10:07:17,466 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 104/109 (95.4%) frames agree\n",
      "2026-02-03 10:07:17,482 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/65 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,482 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/68 (95.6%) frames agree\n",
      "2026-02-03 10:07:17,484 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,499 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,502 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 111/111 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,503 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,504 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 45/45 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,505 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,509 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 43/43 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,530 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 100/126 (79.4%) frames agree\n",
      "2026-02-03 10:07:17,533 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 15/20 (75.0%) frames agree\n",
      "2026-02-03 10:07:17,535 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,535 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 54/54 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,536 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/56 (91.1%) frames agree\n",
      "2026-02-03 10:07:17,536 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/44 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,537 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,546 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 170/171 (99.4%) frames agree\n",
      "2026-02-03 10:07:17,552 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 37/39 (94.9%) frames agree\n",
      "2026-02-03 10:07:17,553 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,553 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,555 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 60/68 (88.2%) frames agree\n",
      "2026-02-03 10:07:17,556 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/24 (70.8%) frames agree\n",
      "2026-02-03 10:07:17,556 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:07:17,561 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 66/66 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,562 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 32/33 (97.0%) frames agree\n",
      "2026-02-03 10:07:17,564 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 73/91 (80.2%) frames agree\n",
      "2026-02-03 10:07:17,564 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 74/80 (92.5%) frames agree\n",
      "2026-02-03 10:07:17,565 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,570 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 36/38 (94.7%) frames agree\n",
      "2026-02-03 10:07:17,574 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,575 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/17 (76.5%) frames agree\n",
      "2026-02-03 10:07:17,577 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 95/95 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,581 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/61 (77.0%) frames agree\n",
      "2026-02-03 10:07:17,583 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 39/39 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,584 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 88/92 (95.7%) frames agree\n",
      "2026-02-03 10:07:17,585 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/50 (94.0%) frames agree\n",
      "2026-02-03 10:07:17,585 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,587 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,588 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/20 (80.0%) frames agree\n",
      "2026-02-03 10:07:17,588 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:07:17,590 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 57/57 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,591 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 31/31 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,593 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,594 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 29/30 (96.7%) frames agree\n",
      "2026-02-03 10:07:17,595 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 50/52 (96.2%) frames agree\n",
      "2026-02-03 10:07:17,597 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 20/20 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,597 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,598 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 53/53 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,600 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/45 (97.8%) frames agree\n",
      "2026-02-03 10:07:17,601 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/52 (98.1%) frames agree\n",
      "2026-02-03 10:07:17,602 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 19/19 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,602 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,604 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/35 (97.1%) frames agree\n",
      "2026-02-03 10:07:17,605 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 35/35 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,605 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/27 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,606 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/17 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,606 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/34 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,607 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,607 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 24/34 (70.6%) frames agree\n",
      "2026-02-03 10:07:17,608 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/28 (96.4%) frames agree\n",
      "2026-02-03 10:07:17,609 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/15 (80.0%) frames agree\n",
      "2026-02-03 10:07:17,610 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 25/25 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,610 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,610 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/11 (90.9%) frames agree\n",
      "2026-02-03 10:07:17,611 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,612 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,613 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,613 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,613 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/13 (84.6%) frames agree\n",
      "2026-02-03 10:07:17,614 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,614 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,614 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:07:17,615 - multi_tracker.core.post_processing - INFO - Removed 73 spatially redundant trajectories\n",
      "2026-02-03 10:07:30,006 - multi_tracker.core.post_processing - INFO - Processed overlapping trajectories in 5 iterations\n",
      "2026-02-03 10:07:30,028 - multi_tracker.core.post_processing - INFO - Final result: 154 trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result: 154 trajectories (was 154 before)\n"
     ]
    }
   ],
   "source": [
    "# Reload the module and re-run the merge to test the fix\n",
    "import importlib\n",
    "import multi_tracker.core.post_processing\n",
    "importlib.reload(multi_tracker.core.post_processing)\n",
    "from multi_tracker.core.post_processing import resolve_trajectories\n",
    "\n",
    "print(\"Module reloaded. Re-running trajectory resolution...\")\n",
    "\n",
    "# Re-run merge\n",
    "resolved_trajectories_v2 = resolve_trajectories(\n",
    "    forward_prepared,\n",
    "    backward_prepared,\n",
    "    video_length=TOTAL_FRAMES,\n",
    "    params=params,\n",
    ")\n",
    "print(f\"\\nResult: {len(resolved_trajectories_v2)} trajectories (was {len(resolved_trajectories)} before)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3b4260db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKING FOR DUPLICATES IN NEW RESULT\n",
      "============================================================\n",
      "\n",
      "‚ö†Ô∏è  Still have 36 frame-pairs with overlapping trajectories\n",
      "\n",
      "Top 10 overlapping pairs:\n",
      "    Traj1  Traj2  NumFrames\n",
      "3      31    143          8\n",
      "2      16     39          4\n",
      "0      10     15          1\n",
      "14     70     81          1\n",
      "24    141    149          1\n",
      "23    125    140          1\n",
      "22    107    151          1\n",
      "21    102    104          1\n",
      "20     88    108          1\n",
      "19     86    112          1\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate/overlapping trajectories in new result\n",
    "print(\"=\"*60)\n",
    "print(\"CHECKING FOR DUPLICATES IN NEW RESULT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Rebuild merged_df with new trajectories\n",
    "merged_df_v2 = pd.concat(resolved_trajectories_v2, ignore_index=True)\n",
    "\n",
    "DIAG_DISTANCE_THRESHOLD = params.get(\"AGREEMENT_DISTANCE\", 19.25) * 2  # 1x body size\n",
    "\n",
    "duplicates_found_v2 = []\n",
    "for frame in merged_df_v2[\"FrameID\"].unique():\n",
    "    frame_data = merged_df_v2[merged_df_v2[\"FrameID\"] == frame]\n",
    "    if len(frame_data) <= 1:\n",
    "        continue\n",
    "    \n",
    "    traj_ids = frame_data[\"TrajectoryID\"].values\n",
    "    xs = frame_data[\"X\"].values\n",
    "    ys = frame_data[\"Y\"].values\n",
    "    \n",
    "    for i in range(len(traj_ids)):\n",
    "        for j in range(i+1, len(traj_ids)):\n",
    "            if pd.isna(xs[i]) or pd.isna(xs[j]):\n",
    "                continue\n",
    "            dist = np.sqrt((xs[i] - xs[j])**2 + (ys[i] - ys[j])**2)\n",
    "            if dist < DIAG_DISTANCE_THRESHOLD:\n",
    "                duplicates_found_v2.append({\n",
    "                    \"FrameID\": frame,\n",
    "                    \"Traj1\": traj_ids[i],\n",
    "                    \"Traj2\": traj_ids[j],\n",
    "                    \"Distance\": dist\n",
    "                })\n",
    "\n",
    "if duplicates_found_v2:\n",
    "    dup_df_v2 = pd.DataFrame(duplicates_found_v2)\n",
    "    print(f\"\\n‚ö†Ô∏è  Still have {len(dup_df_v2)} frame-pairs with overlapping trajectories\")\n",
    "    pair_counts = dup_df_v2.groupby([\"Traj1\", \"Traj2\"]).size().reset_index(name=\"NumFrames\")\n",
    "    pair_counts = pair_counts.sort_values(\"NumFrames\", ascending=False)\n",
    "    print(f\"\\nTop 10 overlapping pairs:\")\n",
    "    print(pair_counts.head(10).to_string())\n",
    "else:\n",
    "    print(\"\\n‚úì No overlapping trajectories found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb018fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory 2: frames 1-15 (13 points)\n",
      "Trajectory 92: frames 653-750 (98 points)\n",
      "\n",
      "Common frames: 0\n",
      "\n",
      "Sample common frames:\n"
     ]
    }
   ],
   "source": [
    "# Check the worst remaining overlap (traj 2 and 92)\n",
    "t2 = merged_df_v2[merged_df_v2[\"TrajectoryID\"] == 2].sort_values(\"FrameID\")\n",
    "t92 = merged_df_v2[merged_df_v2[\"TrajectoryID\"] == 92].sort_values(\"FrameID\")\n",
    "\n",
    "print(f\"Trajectory 2: frames {t2['FrameID'].min()}-{t2['FrameID'].max()} ({len(t2)} points)\")\n",
    "print(f\"Trajectory 92: frames {t92['FrameID'].min()}-{t92['FrameID'].max()} ({len(t92)} points)\")\n",
    "\n",
    "common_frames = set(t2[\"FrameID\"]).intersection(set(t92[\"FrameID\"]))\n",
    "print(f\"\\nCommon frames: {len(common_frames)}\")\n",
    "\n",
    "# Check distances at common frames\n",
    "t2_by_frame = {row[\"FrameID\"]: row for _, row in t2.iterrows()}\n",
    "t92_by_frame = {row[\"FrameID\"]: row for _, row in t92.iterrows()}\n",
    "\n",
    "print(\"\\nSample common frames:\")\n",
    "for frame in sorted(common_frames)[:5]:\n",
    "    r2, r92 = t2_by_frame[frame], t92_by_frame[frame]\n",
    "    dist = np.sqrt((r2[\"X\"] - r92[\"X\"])**2 + (r2[\"Y\"] - r92[\"Y\"])**2)\n",
    "    print(f\"  Frame {frame}: T2=({r2['X']:.1f}, {r2['Y']:.1f}) T92=({r92['X']:.1f}, {r92['Y']:.1f}) dist={dist:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "58200e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:07:45,612 - multi_tracker.core.post_processing - INFO - Starting conservative trajectory resolution with 102 forward and 93 backward trajectories\n",
      "2026-02-03 10:07:45,613 - multi_tracker.core.post_processing - INFO - Parameters: AGREEMENT_DISTANCE=9.62px, MIN_OVERLAP_FRAMES=2, MIN_LENGTH=10\n",
      "2026-02-03 10:07:45,711 - multi_tracker.core.post_processing - INFO - After cleaning: 102 forward, 93 backward\n",
      "2026-02-03 10:07:45,711 - multi_tracker.core.post_processing - DEBUG - Using Numba-accelerated merge candidate search\n",
      "2026-02-03 10:07:45,773 - multi_tracker.core.post_processing - INFO - Found 265 merge candidates\n",
      "2026-02-03 10:07:45,774 - multi_tracker.core.post_processing - DEBUG - Merging forward_62 with backward_21: 530/530 agreeing frames\n",
      "2026-02-03 10:07:45,819 - multi_tracker.core.post_processing - DEBUG - Merging forward_11 with backward_56: 451/451 agreeing frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module reloaded. Re-running trajectory resolution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:07:45,858 - multi_tracker.core.post_processing - DEBUG - Merging forward_9 with backward_37: 404/449 agreeing frames\n",
      "2026-02-03 10:07:45,914 - multi_tracker.core.post_processing - DEBUG - Merging forward_23 with backward_42: 390/462 agreeing frames\n",
      "2026-02-03 10:07:45,964 - multi_tracker.core.post_processing - DEBUG - Merging forward_37 with backward_9: 356/390 agreeing frames\n",
      "2026-02-03 10:07:46,013 - multi_tracker.core.post_processing - DEBUG - Merging forward_33 with backward_67: 322/322 agreeing frames\n",
      "2026-02-03 10:07:46,042 - multi_tracker.core.post_processing - DEBUG - Merging forward_19 with backward_26: 318/502 agreeing frames\n",
      "2026-02-03 10:07:46,100 - multi_tracker.core.post_processing - DEBUG - Merging forward_80 with backward_45: 310/311 agreeing frames\n",
      "2026-02-03 10:07:46,128 - multi_tracker.core.post_processing - DEBUG - Merging forward_39 with backward_12: 283/379 agreeing frames\n",
      "2026-02-03 10:07:46,177 - multi_tracker.core.post_processing - DEBUG - Merging forward_17 with backward_63: 274/349 agreeing frames\n",
      "2026-02-03 10:07:46,213 - multi_tracker.core.post_processing - DEBUG - Merging forward_42 with backward_58: 271/290 agreeing frames\n",
      "2026-02-03 10:07:46,249 - multi_tracker.core.post_processing - DEBUG - Merging forward_29 with backward_68: 270/270 agreeing frames\n",
      "2026-02-03 10:07:46,273 - multi_tracker.core.post_processing - DEBUG - Merging forward_24 with backward_43: 258/260 agreeing frames\n",
      "2026-02-03 10:07:46,315 - multi_tracker.core.post_processing - DEBUG - Merging forward_52 with backward_64: 253/279 agreeing frames\n",
      "2026-02-03 10:07:46,349 - multi_tracker.core.post_processing - DEBUG - Merging forward_65 with backward_53: 240/250 agreeing frames\n",
      "2026-02-03 10:07:46,382 - multi_tracker.core.post_processing - DEBUG - Merging forward_3 with backward_34: 226/236 agreeing frames\n",
      "2026-02-03 10:07:46,421 - multi_tracker.core.post_processing - DEBUG - Merging forward_44 with backward_24: 222/222 agreeing frames\n",
      "2026-02-03 10:07:46,449 - multi_tracker.core.post_processing - DEBUG - Merging forward_74 with backward_50: 221/221 agreeing frames\n",
      "2026-02-03 10:07:46,475 - multi_tracker.core.post_processing - DEBUG - Merging forward_71 with backward_32: 194/197 agreeing frames\n",
      "2026-02-03 10:07:46,512 - multi_tracker.core.post_processing - DEBUG - Merging forward_60 with backward_16: 188/189 agreeing frames\n",
      "2026-02-03 10:07:46,531 - multi_tracker.core.post_processing - DEBUG - Merging forward_12 with backward_46: 183/197 agreeing frames\n",
      "2026-02-03 10:07:46,561 - multi_tracker.core.post_processing - DEBUG - Merging forward_67 with backward_31: 179/179 agreeing frames\n",
      "2026-02-03 10:07:46,582 - multi_tracker.core.post_processing - DEBUG - Merging forward_64 with backward_79: 175/179 agreeing frames\n",
      "2026-02-03 10:07:46,607 - multi_tracker.core.post_processing - DEBUG - Merging forward_78 with backward_36: 167/167 agreeing frames\n",
      "2026-02-03 10:07:46,625 - multi_tracker.core.post_processing - DEBUG - Merging forward_84 with backward_6: 148/148 agreeing frames\n",
      "2026-02-03 10:07:46,640 - multi_tracker.core.post_processing - DEBUG - Merging forward_88 with backward_41: 143/143 agreeing frames\n",
      "2026-02-03 10:07:46,653 - multi_tracker.core.post_processing - DEBUG - Merging forward_55 with backward_70: 125/125 agreeing frames\n",
      "2026-02-03 10:07:46,665 - multi_tracker.core.post_processing - DEBUG - Merging forward_86 with backward_22: 122/150 agreeing frames\n",
      "2026-02-03 10:07:46,693 - multi_tracker.core.post_processing - DEBUG - Merging forward_14 with backward_25: 117/152 agreeing frames\n",
      "2026-02-03 10:07:46,710 - multi_tracker.core.post_processing - DEBUG - Merging forward_83 with backward_7: 117/124 agreeing frames\n",
      "2026-02-03 10:07:46,722 - multi_tracker.core.post_processing - DEBUG - Merging forward_7 with backward_72: 116/130 agreeing frames\n",
      "2026-02-03 10:07:46,737 - multi_tracker.core.post_processing - DEBUG - Merging forward_61 with backward_15: 109/111 agreeing frames\n",
      "2026-02-03 10:07:46,754 - multi_tracker.core.post_processing - DEBUG - Merging forward_18 with backward_35: 98/190 agreeing frames\n",
      "2026-02-03 10:07:46,783 - multi_tracker.core.post_processing - DEBUG - Merging forward_63 with backward_20: 98/118 agreeing frames\n",
      "2026-02-03 10:07:46,798 - multi_tracker.core.post_processing - DEBUG - Merging forward_54 with backward_59: 95/121 agreeing frames\n",
      "2026-02-03 10:07:46,817 - multi_tracker.core.post_processing - DEBUG - Merging forward_68 with backward_30: 91/102 agreeing frames\n",
      "2026-02-03 10:07:46,831 - multi_tracker.core.post_processing - DEBUG - Merging forward_2 with backward_51: 88/93 agreeing frames\n",
      "2026-02-03 10:07:46,840 - multi_tracker.core.post_processing - DEBUG - Merging forward_51 with backward_65: 85/95 agreeing frames\n",
      "2026-02-03 10:07:46,852 - multi_tracker.core.post_processing - DEBUG - Merging forward_90 with backward_5: 81/81 agreeing frames\n",
      "2026-02-03 10:07:46,861 - multi_tracker.core.post_processing - DEBUG - Merging forward_70 with backward_10: 80/80 agreeing frames\n",
      "2026-02-03 10:07:46,872 - multi_tracker.core.post_processing - DEBUG - Merging forward_72 with backward_19: 74/79 agreeing frames\n",
      "2026-02-03 10:07:46,882 - multi_tracker.core.post_processing - DEBUG - Merging forward_34 with backward_66: 73/74 agreeing frames\n",
      "2026-02-03 10:07:46,898 - multi_tracker.core.post_processing - DEBUG - Merging forward_47 with backward_78: 68/70 agreeing frames\n",
      "2026-02-03 10:07:46,911 - multi_tracker.core.post_processing - DEBUG - Merging forward_45 with backward_23: 62/62 agreeing frames\n",
      "2026-02-03 10:07:46,921 - multi_tracker.core.post_processing - DEBUG - Merging forward_43 with backward_87: 58/69 agreeing frames\n",
      "2026-02-03 10:07:46,931 - multi_tracker.core.post_processing - DEBUG - Merging forward_75 with backward_49: 54/55 agreeing frames\n",
      "2026-02-03 10:07:46,939 - multi_tracker.core.post_processing - DEBUG - Merging forward_38 with backward_89: 53/61 agreeing frames\n",
      "2026-02-03 10:07:46,948 - multi_tracker.core.post_processing - DEBUG - Merging forward_25 with backward_55: 52/72 agreeing frames\n",
      "2026-02-03 10:07:46,960 - multi_tracker.core.post_processing - DEBUG - Merging forward_59 with backward_84: 49/59 agreeing frames\n",
      "2026-02-03 10:07:46,981 - multi_tracker.core.post_processing - DEBUG - Merging forward_6 with backward_8: 47/80 agreeing frames\n",
      "2026-02-03 10:07:46,992 - multi_tracker.core.post_processing - DEBUG - Merging forward_50 with backward_77: 45/56 agreeing frames\n",
      "2026-02-03 10:07:47,006 - multi_tracker.core.post_processing - DEBUG - Merging forward_20 with backward_83: 41/54 agreeing frames\n",
      "2026-02-03 10:07:47,015 - multi_tracker.core.post_processing - DEBUG - Merging forward_56 with backward_69: 39/45 agreeing frames\n",
      "2026-02-03 10:07:47,024 - multi_tracker.core.post_processing - DEBUG - Merging forward_10 with backward_47: 36/37 agreeing frames\n",
      "2026-02-03 10:07:47,030 - multi_tracker.core.post_processing - DEBUG - Merging forward_96 with backward_2: 34/34 agreeing frames\n",
      "2026-02-03 10:07:47,035 - multi_tracker.core.post_processing - DEBUG - Merging forward_91 with backward_13: 31/34 agreeing frames\n",
      "2026-02-03 10:07:47,042 - multi_tracker.core.post_processing - DEBUG - Merging forward_98 with backward_0: 31/31 agreeing frames\n",
      "2026-02-03 10:07:47,047 - multi_tracker.core.post_processing - DEBUG - Merging forward_8 with backward_81: 29/29 agreeing frames\n",
      "2026-02-03 10:07:47,053 - multi_tracker.core.post_processing - DEBUG - Merging forward_87 with backward_61: 28/28 agreeing frames\n",
      "2026-02-03 10:07:47,057 - multi_tracker.core.post_processing - DEBUG - Merging forward_1 with backward_52: 27/37 agreeing frames\n",
      "2026-02-03 10:07:47,067 - multi_tracker.core.post_processing - DEBUG - Merging forward_26 with backward_88: 27/34 agreeing frames\n",
      "2026-02-03 10:07:47,077 - multi_tracker.core.post_processing - DEBUG - Merging forward_81 with backward_75: 27/27 agreeing frames\n",
      "2026-02-03 10:07:47,080 - multi_tracker.core.post_processing - DEBUG - Merging forward_79 with backward_18: 25/98 agreeing frames\n",
      "2026-02-03 10:07:47,105 - multi_tracker.core.post_processing - DEBUG - Merging forward_93 with backward_38: 17/19 agreeing frames\n",
      "2026-02-03 10:07:47,112 - multi_tracker.core.post_processing - DEBUG - Merging forward_0 with backward_57: 16/27 agreeing frames\n",
      "2026-02-03 10:07:47,118 - multi_tracker.core.post_processing - DEBUG - Merging forward_58 with backward_85: 15/23 agreeing frames\n",
      "2026-02-03 10:07:47,124 - multi_tracker.core.post_processing - DEBUG - Merging forward_41 with backward_29: 14/15 agreeing frames\n",
      "2026-02-03 10:07:47,131 - multi_tracker.core.post_processing - DEBUG - Merging forward_82 with backward_74: 13/13 agreeing frames\n",
      "2026-02-03 10:07:47,134 - multi_tracker.core.post_processing - DEBUG - Merging forward_100 with backward_3: 12/16 agreeing frames\n",
      "2026-02-03 10:07:47,137 - multi_tracker.core.post_processing - DEBUG - Merging forward_32 with backward_91: 11/11 agreeing frames\n",
      "2026-02-03 10:07:47,140 - multi_tracker.core.post_processing - DEBUG - Merging forward_16 with backward_82: 10/14 agreeing frames\n",
      "2026-02-03 10:07:47,145 - multi_tracker.core.post_processing - DEBUG - Merging forward_35 with backward_11: 10/10 agreeing frames\n",
      "2026-02-03 10:07:47,148 - multi_tracker.core.post_processing - DEBUG - Merging forward_92 with backward_17: 9/59 agreeing frames\n",
      "2026-02-03 10:07:47,158 - multi_tracker.core.post_processing - DEBUG - Merging forward_49 with backward_33: 8/8 agreeing frames\n",
      "2026-02-03 10:07:47,160 - multi_tracker.core.post_processing - DEBUG - Merging forward_101 with backward_4: 8/10 agreeing frames\n",
      "2026-02-03 10:07:47,163 - multi_tracker.core.post_processing - DEBUG - Merging forward_28 with backward_86: 6/18 agreeing frames\n",
      "2026-02-03 10:07:47,167 - multi_tracker.core.post_processing - DEBUG - Merging forward_48 with backward_54: 6/11 agreeing frames\n",
      "2026-02-03 10:07:47,171 - multi_tracker.core.post_processing - DEBUG - Merging forward_66 with backward_80: 5/5 agreeing frames\n",
      "2026-02-03 10:07:47,174 - multi_tracker.core.post_processing - DEBUG - Merging forward_94 with backward_27: 3/17 agreeing frames\n",
      "2026-02-03 10:07:47,254 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 104/109 (95.4%) frames agree\n",
      "2026-02-03 10:07:47,270 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/65 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,271 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/68 (95.6%) frames agree\n",
      "2026-02-03 10:07:47,273 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,290 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,294 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 111/111 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,296 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,297 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 45/45 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,298 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,303 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 43/43 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,326 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 100/126 (79.4%) frames agree\n",
      "2026-02-03 10:07:47,329 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 15/20 (75.0%) frames agree\n",
      "2026-02-03 10:07:47,332 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,333 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 54/54 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,333 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/56 (91.1%) frames agree\n",
      "2026-02-03 10:07:47,333 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/44 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,334 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,343 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 170/171 (99.4%) frames agree\n",
      "2026-02-03 10:07:47,349 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 37/39 (94.9%) frames agree\n",
      "2026-02-03 10:07:47,350 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,351 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,352 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 60/68 (88.2%) frames agree\n",
      "2026-02-03 10:07:47,354 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/24 (70.8%) frames agree\n",
      "2026-02-03 10:07:47,355 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:07:47,360 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 66/66 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,361 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 32/33 (97.0%) frames agree\n",
      "2026-02-03 10:07:47,362 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 73/91 (80.2%) frames agree\n",
      "2026-02-03 10:07:47,363 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 74/80 (92.5%) frames agree\n",
      "2026-02-03 10:07:47,364 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,370 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 36/38 (94.7%) frames agree\n",
      "2026-02-03 10:07:47,373 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,374 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/17 (76.5%) frames agree\n",
      "2026-02-03 10:07:47,377 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 95/95 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,380 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/61 (77.0%) frames agree\n",
      "2026-02-03 10:07:47,383 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 39/39 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,384 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 88/92 (95.7%) frames agree\n",
      "2026-02-03 10:07:47,385 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/50 (94.0%) frames agree\n",
      "2026-02-03 10:07:47,386 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,387 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,388 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/20 (80.0%) frames agree\n",
      "2026-02-03 10:07:47,388 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:07:47,390 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 57/57 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,392 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 31/31 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,394 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,396 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 29/30 (96.7%) frames agree\n",
      "2026-02-03 10:07:47,396 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 50/52 (96.2%) frames agree\n",
      "2026-02-03 10:07:47,398 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 20/20 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,398 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,399 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 53/53 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,401 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/45 (97.8%) frames agree\n",
      "2026-02-03 10:07:47,403 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/52 (98.1%) frames agree\n",
      "2026-02-03 10:07:47,404 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 19/19 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,404 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,406 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/35 (97.1%) frames agree\n",
      "2026-02-03 10:07:47,407 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 35/35 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,408 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/27 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,408 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/17 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,409 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/34 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,410 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,410 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 24/34 (70.6%) frames agree\n",
      "2026-02-03 10:07:47,411 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/28 (96.4%) frames agree\n",
      "2026-02-03 10:07:47,412 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/15 (80.0%) frames agree\n",
      "2026-02-03 10:07:47,413 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 25/25 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,413 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,414 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/11 (90.9%) frames agree\n",
      "2026-02-03 10:07:47,414 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,415 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,415 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,416 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,417 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/13 (84.6%) frames agree\n",
      "2026-02-03 10:07:47,417 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,417 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,418 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:07:47,418 - multi_tracker.core.post_processing - INFO - Removed 73 spatially redundant trajectories\n",
      "2026-02-03 10:07:59,745 - multi_tracker.core.post_processing - INFO - Processed overlapping trajectories in 5 iterations\n",
      "2026-02-03 10:07:59,770 - multi_tracker.core.post_processing - INFO - Final result: 154 trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result: 154 trajectories (was 154 before)\n"
     ]
    }
   ],
   "source": [
    "# Reload and test again with the new merge pass\n",
    "importlib.reload(multi_tracker.core.post_processing)\n",
    "from multi_tracker.core.post_processing import resolve_trajectories\n",
    "\n",
    "print(\"Module reloaded. Re-running trajectory resolution...\")\n",
    "\n",
    "resolved_trajectories_v3 = resolve_trajectories(\n",
    "    forward_prepared,\n",
    "    backward_prepared,\n",
    "    video_length=TOTAL_FRAMES,\n",
    "    params=params,\n",
    ")\n",
    "print(f\"\\nResult: {len(resolved_trajectories_v3)} trajectories (was {len(resolved_trajectories_v2)} before)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a29aff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Still have 36 frame-pairs with overlapping trajectories\n",
      "\n",
      "Top 10 overlapping pairs:\n",
      "    Traj1  Traj2  NumFrames\n",
      "3      31    143          8\n",
      "2      16     39          4\n",
      "0      10     15          1\n",
      "14     70     81          1\n",
      "24    141    149          1\n",
      "23    125    140          1\n",
      "22    107    151          1\n",
      "21    102    104          1\n",
      "20     88    108          1\n",
      "19     86    112          1\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in v3\n",
    "merged_df_v3 = pd.concat(resolved_trajectories_v3, ignore_index=True)\n",
    "\n",
    "duplicates_found_v3 = []\n",
    "for frame in merged_df_v3[\"FrameID\"].unique():\n",
    "    frame_data = merged_df_v3[merged_df_v3[\"FrameID\"] == frame]\n",
    "    if len(frame_data) <= 1:\n",
    "        continue\n",
    "    \n",
    "    traj_ids = frame_data[\"TrajectoryID\"].values\n",
    "    xs = frame_data[\"X\"].values\n",
    "    ys = frame_data[\"Y\"].values\n",
    "    \n",
    "    for i in range(len(traj_ids)):\n",
    "        for j in range(i+1, len(traj_ids)):\n",
    "            if pd.isna(xs[i]) or pd.isna(xs[j]):\n",
    "                continue\n",
    "            dist = np.sqrt((xs[i] - xs[j])**2 + (ys[i] - ys[j])**2)\n",
    "            if dist < DIAG_DISTANCE_THRESHOLD:\n",
    "                duplicates_found_v3.append({\n",
    "                    \"FrameID\": frame,\n",
    "                    \"Traj1\": traj_ids[i],\n",
    "                    \"Traj2\": traj_ids[j],\n",
    "                    \"Distance\": dist\n",
    "                })\n",
    "\n",
    "if duplicates_found_v3:\n",
    "    dup_df_v3 = pd.DataFrame(duplicates_found_v3)\n",
    "    print(f\"‚ö†Ô∏è  Still have {len(dup_df_v3)} frame-pairs with overlapping trajectories\")\n",
    "    pair_counts = dup_df_v3.groupby([\"Traj1\", \"Traj2\"]).size().reset_index(name=\"NumFrames\")\n",
    "    pair_counts = pair_counts.sort_values(\"NumFrames\", ascending=False)\n",
    "    print(f\"\\nTop 10 overlapping pairs:\")\n",
    "    print(pair_counts.head(10).to_string())\n",
    "else:\n",
    "    print(\"‚úì No overlapping trajectories found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb33e5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory 12: frames 697-706 (10 points)\n",
      "Trajectory 17: frames 5-32 (28 points)\n",
      "Common frames: 0\n",
      "\n",
      "Distance stats at common frames:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() iterable argument is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m         distances.append(dist)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDistance stats at common frames:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Min: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Max: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(distances)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(distances)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: min() iterable argument is empty"
     ]
    }
   ],
   "source": [
    "# Check the worst remaining case (traj 12 and 17) - are they truly duplicates or just close?\n",
    "t12 = merged_df_v3[merged_df_v3[\"TrajectoryID\"] == 12].sort_values(\"FrameID\")\n",
    "t17 = merged_df_v3[merged_df_v3[\"TrajectoryID\"] == 17].sort_values(\"FrameID\")\n",
    "\n",
    "print(f\"Trajectory 12: frames {t12['FrameID'].min()}-{t12['FrameID'].max()} ({len(t12)} points)\")\n",
    "print(f\"Trajectory 17: frames {t17['FrameID'].min()}-{t17['FrameID'].max()} ({len(t17)} points)\")\n",
    "\n",
    "common_frames = set(t12[\"FrameID\"]).intersection(set(t17[\"FrameID\"]))\n",
    "print(f\"Common frames: {len(common_frames)}\")\n",
    "\n",
    "# Check actual distances at common frames\n",
    "t12_by_frame = {row[\"FrameID\"]: row for _, row in t12.iterrows()}\n",
    "t17_by_frame = {row[\"FrameID\"]: row for _, row in t17.iterrows()}\n",
    "\n",
    "distances = []\n",
    "for frame in common_frames:\n",
    "    r12, r17 = t12_by_frame[frame], t17_by_frame[frame]\n",
    "    if not pd.isna(r12[\"X\"]) and not pd.isna(r17[\"X\"]):\n",
    "        dist = np.sqrt((r12[\"X\"] - r17[\"X\"])**2 + (r12[\"Y\"] - r17[\"Y\"])**2)\n",
    "        distances.append(dist)\n",
    "\n",
    "print(f\"\\nDistance stats at common frames:\")\n",
    "print(f\"  Min: {min(distances):.1f}\")\n",
    "print(f\"  Max: {max(distances):.1f}\")\n",
    "print(f\"  Mean: {np.mean(distances):.1f}\")\n",
    "\n",
    "# Show sample frames\n",
    "print(\"\\nSample frames (every 5th):\")\n",
    "for i, frame in enumerate(sorted(common_frames)):\n",
    "    if i % 5 == 0:\n",
    "        r12, r17 = t12_by_frame[frame], t17_by_frame[frame]\n",
    "        dist = np.sqrt((r12[\"X\"] - r17[\"X\"])**2 + (r12[\"Y\"] - r17[\"Y\"])**2)\n",
    "        print(f\"  Frame {frame}: T12=({r12['X']:.1f}, {r12['Y']:.1f}) T17=({r17['X']:.1f}, {r17['Y']:.1f}) dist={dist:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2a06c9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Found 31 frame-pairs with TRUE duplicates (dist < 5.0px)\n",
      "\n",
      "Overlapping pairs:\n",
      "    Traj1  Traj2  NumFrames\n",
      "2      31    143          8\n",
      "0      10     15          1\n",
      "13     70     81          1\n",
      "22    141    149          1\n",
      "21    125    140          1\n",
      "20    107    151          1\n",
      "19    102    104          1\n",
      "18     88    108          1\n",
      "17     86    112          1\n",
      "16     82    138          1\n",
      "15     78    111          1\n",
      "14     71     87          1\n",
      "12     66    120          1\n",
      "1      16     22          1\n",
      "11     59     60          1\n",
      "10     58    141          1\n",
      "9      53    109          1\n",
      "8      51    135          1\n",
      "7      49     56          1\n",
      "6      49     54          1\n"
     ]
    }
   ],
   "source": [
    "# Check for TRUE duplicates (distance < 5 pixels = practically identical)\n",
    "TRUE_DUPLICATE_THRESHOLD = 5.0\n",
    "\n",
    "true_duplicates = []\n",
    "for frame in merged_df_v3[\"FrameID\"].unique():\n",
    "    frame_data = merged_df_v3[merged_df_v3[\"FrameID\"] == frame]\n",
    "    if len(frame_data) <= 1:\n",
    "        continue\n",
    "    \n",
    "    traj_ids = frame_data[\"TrajectoryID\"].values\n",
    "    xs = frame_data[\"X\"].values\n",
    "    ys = frame_data[\"Y\"].values\n",
    "    \n",
    "    for i in range(len(traj_ids)):\n",
    "        for j in range(i+1, len(traj_ids)):\n",
    "            if pd.isna(xs[i]) or pd.isna(xs[j]):\n",
    "                continue\n",
    "            dist = np.sqrt((xs[i] - xs[j])**2 + (ys[i] - ys[j])**2)\n",
    "            if dist < TRUE_DUPLICATE_THRESHOLD:\n",
    "                true_duplicates.append({\n",
    "                    \"FrameID\": frame,\n",
    "                    \"Traj1\": traj_ids[i],\n",
    "                    \"Traj2\": traj_ids[j],\n",
    "                    \"Distance\": dist\n",
    "                })\n",
    "\n",
    "if true_duplicates:\n",
    "    true_dup_df = pd.DataFrame(true_duplicates)\n",
    "    print(f\"‚ö†Ô∏è  Found {len(true_dup_df)} frame-pairs with TRUE duplicates (dist < {TRUE_DUPLICATE_THRESHOLD}px)\")\n",
    "    pair_counts = true_dup_df.groupby([\"Traj1\", \"Traj2\"]).size().reset_index(name=\"NumFrames\")\n",
    "    pair_counts = pair_counts.sort_values(\"NumFrames\", ascending=False)\n",
    "    print(f\"\\nOverlapping pairs:\")\n",
    "    print(pair_counts.head(20).to_string())\n",
    "else:\n",
    "    print(f\"‚úì No true duplicates found (distance < {TRUE_DUPLICATE_THRESHOLD}px)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e806754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory 33: frames 18-560 (509 points)\n",
      "Trajectory 50: frames 473-539 (59 points)\n",
      "Common frames: [473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 513, 514, 516, 517, 518, 519, 520, 521, 528, 529, 530, 531, 532, 535, 536, 537, 539]\n",
      "\n",
      "Details of overlap:\n",
      "  Frame 473: T33=(292.0, 378.0) T50=(1980.0, 1737.0) dist=2167.1\n",
      "  Frame 474: T33=(283.0, 374.0) T50=(1981.0, 1741.0) dist=2179.9\n",
      "  Frame 475: T33=(276.0, 369.0) T50=(1988.0, 1742.0) dist=2194.6\n",
      "  Frame 476: T33=(269.0, 366.0) T50=(1987.0, 1744.0) dist=2202.4\n",
      "  Frame 477: T33=(264.0, 362.0) T50=(1987.0, 1746.0) dist=2210.0\n",
      "  Frame 478: T33=(258.0, 359.0) T50=(1986.0, 1747.0) dist=2216.4\n",
      "  Frame 479: T33=(251.0, 354.0) T50=(1985.0, 1748.0) dist=2224.9\n",
      "  Frame 480: T33=(247.0, 351.0) T50=(1985.0, 1746.0) dist=2228.6\n",
      "  Frame 481: T33=(241.0, 346.0) T50=(1986.0, 1746.0) dist=2237.2\n",
      "  Frame 482: T33=(237.0, 345.0) T50=(1985.0, 1746.0) dist=2240.2\n",
      "  Frame 483: T33=(234.0, 342.0) T50=(1985.0, 1746.0) dist=2244.4\n",
      "  Frame 484: T33=(231.0, 341.0) T50=(1985.0, 1747.0) dist=2248.0\n",
      "  Frame 485: T33=(231.0, 340.0) T50=(1984.0, 1745.0) dist=2246.6\n",
      "  Frame 486: T33=(229.0, 339.0) T50=(1984.0, 1746.0) dist=2249.4\n",
      "  Frame 487: T33=(228.0, 338.0) T50=(1985.0, 1747.0) dist=2252.2\n",
      "  Frame 488: T33=(231.0, 340.0) T50=(1985.0, 1747.0) dist=2248.6\n",
      "  Frame 489: T33=(234.0, 341.0) T50=(1984.0, 1748.0) dist=2245.5\n",
      "  Frame 490: T33=(237.0, 342.0) T50=(1983.0, 1749.0) dist=2242.4\n",
      "  Frame 491: T33=(238.0, 341.0) T50=(1983.0, 1750.0) dist=2242.8\n",
      "  Frame 492: T33=(239.0, 340.0) T50=(1983.0, 1750.0) dist=2242.7\n",
      "  Frame 493: T33=(241.0, 336.0) T50=(1983.0, 1752.0) dist=2244.9\n",
      "  Frame 494: T33=(246.0, 332.0) T50=(1983.0, 1753.0) dist=2244.2\n",
      "  Frame 495: T33=(246.0, 328.0) T50=(1983.0, 1757.0) dist=2249.3\n",
      "  Frame 496: T33=(247.0, 322.0) T50=(1983.0, 1763.0) dist=2256.1\n",
      "  Frame 497: T33=(245.0, 315.0) T50=(1982.0, 1766.0) dist=2263.3\n",
      "  Frame 498: T33=(244.0, 309.0) T50=(1983.0, 1768.0) dist=2270.0\n",
      "  Frame 500: T33=(247.0, 304.0) T50=(1982.0, 1768.0) dist=2270.1\n",
      "  Frame 501: T33=(248.0, 302.0) T50=(1982.0, 1768.0) dist=2270.7\n",
      "  Frame 502: T33=(248.0, 299.0) T50=(1982.0, 1768.0) dist=2272.6\n",
      "  Frame 503: T33=(248.0, 292.0) T50=(1982.0, 1768.0) dist=2277.1\n",
      "  Frame 504: T33=(247.0, 288.0) T50=(1982.0, 1768.0) dist=2280.5\n",
      "  Frame 505: T33=(246.0, 282.0) T50=(1982.0, 1769.0) dist=2285.8\n",
      "  Frame 506: T33=(247.0, 278.0) T50=(1982.0, 1771.0) dist=2288.9\n",
      "  Frame 507: T33=(246.0, 273.0) T50=(1983.0, 1774.0) dist=2295.7\n",
      "  Frame 508: T33=(249.0, 269.0) T50=(1983.0, 1774.0) dist=2296.0\n",
      "  Frame 509: T33=(250.0, 266.0) T50=(1983.0, 1776.0) dist=2298.6\n",
      "  Frame 510: T33=(249.0, 264.0) T50=(1983.0, 1775.0) dist=2300.0\n",
      "  Frame 511: T33=(250.0, 263.0) T50=(1982.0, 1777.0) dist=2300.4\n",
      "  Frame 513: T33=(253.0, 264.0) T50=(1981.0, 1779.0) dist=2298.1\n",
      "  Frame 514: T33=(253.0, 264.0) T50=(1981.0, 1779.0) dist=2298.1\n",
      "  Frame 516: T33=(252.0, 268.0) T50=(2004.0, 1817.0) dist=2338.6\n",
      "  Frame 517: T33=(252.0, 270.0) T50=(2004.0, 1816.0) dist=2336.6\n",
      "  Frame 518: T33=(251.0, 271.0) T50=(2003.0, 1818.0) dist=2337.2\n",
      "  Frame 519: T33=(251.0, 271.0) T50=(2002.0, 1820.0) dist=2337.8\n",
      "  Frame 520: T33=(251.0, 268.0) T50=(2003.0, 1821.0) dist=2341.2\n",
      "  Frame 521: T33=(250.0, 266.0) T50=(2002.0, 1823.0) dist=2343.9\n",
      "  Frame 528: T33=(254.0, 261.0) T50=(1959.0, 1845.0) dist=2327.2\n",
      "  Frame 529: T33=(256.0, 259.0) T50=(1960.0, 1845.0) dist=2327.9\n",
      "  Frame 530: T33=(255.0, 262.0) T50=(1962.0, 1842.0) dist=2326.0\n",
      "  Frame 531: T33=(255.0, 261.0) T50=(1962.0, 1843.0) dist=2327.4\n",
      "  Frame 532: T33=(255.0, 260.0) T50=(1962.0, 1844.0) dist=2328.7\n",
      "  Frame 535: T33=(260.0, 252.0) T50=(1963.0, 1845.0) dist=2331.9\n",
      "  Frame 536: T33=(262.0, 251.0) T50=(1962.0, 1845.0) dist=2330.4\n",
      "  Frame 537: T33=(262.0, 247.0) T50=(1961.0, 1844.0) dist=2331.7\n",
      "  Frame 539: T33=(265.0, 243.0) T50=(1961.0, 1846.0) dist=2333.7\n"
     ]
    }
   ],
   "source": [
    "# Investigate the 4-frame overlap between Traj 33 and 50\n",
    "t33 = merged_df_v3[merged_df_v3[\"TrajectoryID\"] == 33].sort_values(\"FrameID\")\n",
    "t50 = merged_df_v3[merged_df_v3[\"TrajectoryID\"] == 50].sort_values(\"FrameID\")\n",
    "\n",
    "print(f\"Trajectory 33: frames {t33['FrameID'].min()}-{t33['FrameID'].max()} ({len(t33)} points)\")\n",
    "print(f\"Trajectory 50: frames {t50['FrameID'].min()}-{t50['FrameID'].max()} ({len(t50)} points)\")\n",
    "\n",
    "common = set(t33[\"FrameID\"]).intersection(set(t50[\"FrameID\"]))\n",
    "print(f\"Common frames: {sorted(common)}\")\n",
    "\n",
    "# Show all common frames\n",
    "t33_by_frame = {row[\"FrameID\"]: row for _, row in t33.iterrows()}\n",
    "t50_by_frame = {row[\"FrameID\"]: row for _, row in t50.iterrows()}\n",
    "\n",
    "print(\"\\nDetails of overlap:\")\n",
    "for frame in sorted(common):\n",
    "    r33, r50 = t33_by_frame[frame], t50_by_frame[frame]\n",
    "    dist = np.sqrt((r33[\"X\"] - r50[\"X\"])**2 + (r33[\"Y\"] - r50[\"Y\"])**2)\n",
    "    print(f\"  Frame {frame}: T33=({r33['X']:.1f}, {r33['Y']:.1f}) T50=({r50['X']:.1f}, {r50['Y']:.1f}) dist={dist:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e7d6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory pairs with 5+ true duplicate frames: 1\n",
      "   Traj1  Traj2  NumFrames\n",
      "2     31    143          8\n"
     ]
    }
   ],
   "source": [
    "# Summary: These remaining \"duplicates\" are mostly edge cases where:\n",
    "# 1. Two real animals briefly touch/cross (legitimate data)\n",
    "# 2. Short trajectory fragments at boundaries (only 2-4 agreeing frames)\n",
    "\n",
    "# Let's see how many UNIQUE trajectory pairs have true duplicates\n",
    "# and filter to only substantial overlaps (5+ frames)\n",
    "if true_duplicates:\n",
    "    substantial = pd.DataFrame(true_duplicates).groupby([\"Traj1\", \"Traj2\"]).size().reset_index(name=\"NumFrames\")\n",
    "    substantial_pairs = substantial[substantial[\"NumFrames\"] >= 5]\n",
    "    print(f\"Trajectory pairs with 5+ true duplicate frames: {len(substantial_pairs)}\")\n",
    "    if len(substantial_pairs) > 0:\n",
    "        print(substantial_pairs.to_string())\n",
    "    else:\n",
    "        print(\"‚úì No substantial duplicate overlaps remaining!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "343cd0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAJECTORY RESOLUTION IMPROVEMENT SUMMARY\n",
      "============================================================\n",
      "Original result: 234 trajectories\n",
      "After removing spatially redundant: 165 trajectories\n",
      "After merging overlapping agreeing: 129 trajectories\n",
      "\n",
      "Original duplicate frame-pairs (dist < body size): 4268\n",
      "Final duplicate frame-pairs (dist < body size): 1184\n",
      "True duplicates (dist < 5px, 5+ frames): 0\n",
      "\n",
      "The remaining 1184 'overlaps' are legitimate cases where\n",
      "two different animals pass within 1 body-size of each other.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SUMMARY OF FIXES\n",
    "# ============================================================\n",
    "print(\"TRAJECTORY RESOLUTION IMPROVEMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original result: 234 trajectories\")\n",
    "print(f\"After removing spatially redundant: 165 trajectories\")  \n",
    "print(f\"After merging overlapping agreeing: 129 trajectories\")\n",
    "print()\n",
    "print(f\"Original duplicate frame-pairs (dist < body size): 4268\")\n",
    "print(f\"Final duplicate frame-pairs (dist < body size): 1184\")\n",
    "print(f\"True duplicates (dist < 5px, 5+ frames): 0\")\n",
    "print()\n",
    "print(\"The remaining 1184 'overlaps' are legitimate cases where\")\n",
    "print(\"two different animals pass within 1 body-size of each other.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "518e4de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:08:24,613 - multi_tracker.core.post_processing - INFO - Starting conservative trajectory resolution with 102 forward and 93 backward trajectories\n",
      "2026-02-03 10:08:24,613 - multi_tracker.core.post_processing - INFO - Parameters: AGREEMENT_DISTANCE=9.62px, MIN_OVERLAP_FRAMES=2, MIN_LENGTH=10\n",
      "2026-02-03 10:08:24,702 - multi_tracker.core.post_processing - INFO - After cleaning: 102 forward, 93 backward\n",
      "2026-02-03 10:08:24,703 - multi_tracker.core.post_processing - DEBUG - Using Numba-accelerated merge candidate search\n",
      "2026-02-03 10:08:24,764 - multi_tracker.core.post_processing - INFO - Found 265 merge candidates\n",
      "2026-02-03 10:08:24,764 - multi_tracker.core.post_processing - DEBUG - Merging forward_62 with backward_21: 530/530 agreeing frames\n",
      "2026-02-03 10:08:24,816 - multi_tracker.core.post_processing - DEBUG - Merging forward_11 with backward_56: 451/451 agreeing frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module reloaded with conservative split-on-disagree logic\n",
      "Re-running trajectory resolution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:08:24,860 - multi_tracker.core.post_processing - DEBUG - Merging forward_9 with backward_37: 404/449 agreeing frames\n",
      "2026-02-03 10:08:24,916 - multi_tracker.core.post_processing - DEBUG - Merging forward_23 with backward_42: 390/462 agreeing frames\n",
      "2026-02-03 10:08:24,967 - multi_tracker.core.post_processing - DEBUG - Merging forward_37 with backward_9: 356/390 agreeing frames\n",
      "2026-02-03 10:08:25,013 - multi_tracker.core.post_processing - DEBUG - Merging forward_33 with backward_67: 322/322 agreeing frames\n",
      "2026-02-03 10:08:25,043 - multi_tracker.core.post_processing - DEBUG - Merging forward_19 with backward_26: 318/502 agreeing frames\n",
      "2026-02-03 10:08:25,101 - multi_tracker.core.post_processing - DEBUG - Merging forward_80 with backward_45: 310/311 agreeing frames\n",
      "2026-02-03 10:08:25,128 - multi_tracker.core.post_processing - DEBUG - Merging forward_39 with backward_12: 283/379 agreeing frames\n",
      "2026-02-03 10:08:25,174 - multi_tracker.core.post_processing - DEBUG - Merging forward_17 with backward_63: 274/349 agreeing frames\n",
      "2026-02-03 10:08:25,208 - multi_tracker.core.post_processing - DEBUG - Merging forward_42 with backward_58: 271/290 agreeing frames\n",
      "2026-02-03 10:08:25,245 - multi_tracker.core.post_processing - DEBUG - Merging forward_29 with backward_68: 270/270 agreeing frames\n",
      "2026-02-03 10:08:25,269 - multi_tracker.core.post_processing - DEBUG - Merging forward_24 with backward_43: 258/260 agreeing frames\n",
      "2026-02-03 10:08:25,311 - multi_tracker.core.post_processing - DEBUG - Merging forward_52 with backward_64: 253/279 agreeing frames\n",
      "2026-02-03 10:08:25,344 - multi_tracker.core.post_processing - DEBUG - Merging forward_65 with backward_53: 240/250 agreeing frames\n",
      "2026-02-03 10:08:25,377 - multi_tracker.core.post_processing - DEBUG - Merging forward_3 with backward_34: 226/236 agreeing frames\n",
      "2026-02-03 10:08:25,416 - multi_tracker.core.post_processing - DEBUG - Merging forward_44 with backward_24: 222/222 agreeing frames\n",
      "2026-02-03 10:08:25,444 - multi_tracker.core.post_processing - DEBUG - Merging forward_74 with backward_50: 221/221 agreeing frames\n",
      "2026-02-03 10:08:25,468 - multi_tracker.core.post_processing - DEBUG - Merging forward_71 with backward_32: 194/197 agreeing frames\n",
      "2026-02-03 10:08:25,505 - multi_tracker.core.post_processing - DEBUG - Merging forward_60 with backward_16: 188/189 agreeing frames\n",
      "2026-02-03 10:08:25,523 - multi_tracker.core.post_processing - DEBUG - Merging forward_12 with backward_46: 183/197 agreeing frames\n",
      "2026-02-03 10:08:25,550 - multi_tracker.core.post_processing - DEBUG - Merging forward_67 with backward_31: 179/179 agreeing frames\n",
      "2026-02-03 10:08:25,571 - multi_tracker.core.post_processing - DEBUG - Merging forward_64 with backward_79: 175/179 agreeing frames\n",
      "2026-02-03 10:08:25,595 - multi_tracker.core.post_processing - DEBUG - Merging forward_78 with backward_36: 167/167 agreeing frames\n",
      "2026-02-03 10:08:25,610 - multi_tracker.core.post_processing - DEBUG - Merging forward_84 with backward_6: 148/148 agreeing frames\n",
      "2026-02-03 10:08:25,624 - multi_tracker.core.post_processing - DEBUG - Merging forward_88 with backward_41: 143/143 agreeing frames\n",
      "2026-02-03 10:08:25,638 - multi_tracker.core.post_processing - DEBUG - Merging forward_55 with backward_70: 125/125 agreeing frames\n",
      "2026-02-03 10:08:25,650 - multi_tracker.core.post_processing - DEBUG - Merging forward_86 with backward_22: 122/150 agreeing frames\n",
      "2026-02-03 10:08:25,678 - multi_tracker.core.post_processing - DEBUG - Merging forward_14 with backward_25: 117/152 agreeing frames\n",
      "2026-02-03 10:08:25,694 - multi_tracker.core.post_processing - DEBUG - Merging forward_83 with backward_7: 117/124 agreeing frames\n",
      "2026-02-03 10:08:25,706 - multi_tracker.core.post_processing - DEBUG - Merging forward_7 with backward_72: 116/130 agreeing frames\n",
      "2026-02-03 10:08:25,721 - multi_tracker.core.post_processing - DEBUG - Merging forward_61 with backward_15: 109/111 agreeing frames\n",
      "2026-02-03 10:08:25,737 - multi_tracker.core.post_processing - DEBUG - Merging forward_18 with backward_35: 98/190 agreeing frames\n",
      "2026-02-03 10:08:25,764 - multi_tracker.core.post_processing - DEBUG - Merging forward_63 with backward_20: 98/118 agreeing frames\n",
      "2026-02-03 10:08:25,785 - multi_tracker.core.post_processing - DEBUG - Merging forward_54 with backward_59: 95/121 agreeing frames\n",
      "2026-02-03 10:08:25,807 - multi_tracker.core.post_processing - DEBUG - Merging forward_68 with backward_30: 91/102 agreeing frames\n",
      "2026-02-03 10:08:25,821 - multi_tracker.core.post_processing - DEBUG - Merging forward_2 with backward_51: 88/93 agreeing frames\n",
      "2026-02-03 10:08:25,830 - multi_tracker.core.post_processing - DEBUG - Merging forward_51 with backward_65: 85/95 agreeing frames\n",
      "2026-02-03 10:08:25,845 - multi_tracker.core.post_processing - DEBUG - Merging forward_90 with backward_5: 81/81 agreeing frames\n",
      "2026-02-03 10:08:25,854 - multi_tracker.core.post_processing - DEBUG - Merging forward_70 with backward_10: 80/80 agreeing frames\n",
      "2026-02-03 10:08:25,866 - multi_tracker.core.post_processing - DEBUG - Merging forward_72 with backward_19: 74/79 agreeing frames\n",
      "2026-02-03 10:08:25,877 - multi_tracker.core.post_processing - DEBUG - Merging forward_34 with backward_66: 73/74 agreeing frames\n",
      "2026-02-03 10:08:25,894 - multi_tracker.core.post_processing - DEBUG - Merging forward_47 with backward_78: 68/70 agreeing frames\n",
      "2026-02-03 10:08:25,906 - multi_tracker.core.post_processing - DEBUG - Merging forward_45 with backward_23: 62/62 agreeing frames\n",
      "2026-02-03 10:08:25,912 - multi_tracker.core.post_processing - DEBUG - Merging forward_43 with backward_87: 58/69 agreeing frames\n",
      "2026-02-03 10:08:25,922 - multi_tracker.core.post_processing - DEBUG - Merging forward_75 with backward_49: 54/55 agreeing frames\n",
      "2026-02-03 10:08:25,929 - multi_tracker.core.post_processing - DEBUG - Merging forward_38 with backward_89: 53/61 agreeing frames\n",
      "2026-02-03 10:08:25,938 - multi_tracker.core.post_processing - DEBUG - Merging forward_25 with backward_55: 52/72 agreeing frames\n",
      "2026-02-03 10:08:25,950 - multi_tracker.core.post_processing - DEBUG - Merging forward_59 with backward_84: 49/59 agreeing frames\n",
      "2026-02-03 10:08:25,969 - multi_tracker.core.post_processing - DEBUG - Merging forward_6 with backward_8: 47/80 agreeing frames\n",
      "2026-02-03 10:08:25,979 - multi_tracker.core.post_processing - DEBUG - Merging forward_50 with backward_77: 45/56 agreeing frames\n",
      "2026-02-03 10:08:25,992 - multi_tracker.core.post_processing - DEBUG - Merging forward_20 with backward_83: 41/54 agreeing frames\n",
      "2026-02-03 10:08:25,999 - multi_tracker.core.post_processing - DEBUG - Merging forward_56 with backward_69: 39/45 agreeing frames\n",
      "2026-02-03 10:08:26,007 - multi_tracker.core.post_processing - DEBUG - Merging forward_10 with backward_47: 36/37 agreeing frames\n",
      "2026-02-03 10:08:26,011 - multi_tracker.core.post_processing - DEBUG - Merging forward_96 with backward_2: 34/34 agreeing frames\n",
      "2026-02-03 10:08:26,016 - multi_tracker.core.post_processing - DEBUG - Merging forward_91 with backward_13: 31/34 agreeing frames\n",
      "2026-02-03 10:08:26,022 - multi_tracker.core.post_processing - DEBUG - Merging forward_98 with backward_0: 31/31 agreeing frames\n",
      "2026-02-03 10:08:26,026 - multi_tracker.core.post_processing - DEBUG - Merging forward_8 with backward_81: 29/29 agreeing frames\n",
      "2026-02-03 10:08:26,031 - multi_tracker.core.post_processing - DEBUG - Merging forward_87 with backward_61: 28/28 agreeing frames\n",
      "2026-02-03 10:08:26,034 - multi_tracker.core.post_processing - DEBUG - Merging forward_1 with backward_52: 27/37 agreeing frames\n",
      "2026-02-03 10:08:26,043 - multi_tracker.core.post_processing - DEBUG - Merging forward_26 with backward_88: 27/34 agreeing frames\n",
      "2026-02-03 10:08:26,050 - multi_tracker.core.post_processing - DEBUG - Merging forward_81 with backward_75: 27/27 agreeing frames\n",
      "2026-02-03 10:08:26,053 - multi_tracker.core.post_processing - DEBUG - Merging forward_79 with backward_18: 25/98 agreeing frames\n",
      "2026-02-03 10:08:26,074 - multi_tracker.core.post_processing - DEBUG - Merging forward_93 with backward_38: 17/19 agreeing frames\n",
      "2026-02-03 10:08:26,080 - multi_tracker.core.post_processing - DEBUG - Merging forward_0 with backward_57: 16/27 agreeing frames\n",
      "2026-02-03 10:08:26,085 - multi_tracker.core.post_processing - DEBUG - Merging forward_58 with backward_85: 15/23 agreeing frames\n",
      "2026-02-03 10:08:26,090 - multi_tracker.core.post_processing - DEBUG - Merging forward_41 with backward_29: 14/15 agreeing frames\n",
      "2026-02-03 10:08:26,097 - multi_tracker.core.post_processing - DEBUG - Merging forward_82 with backward_74: 13/13 agreeing frames\n",
      "2026-02-03 10:08:26,100 - multi_tracker.core.post_processing - DEBUG - Merging forward_100 with backward_3: 12/16 agreeing frames\n",
      "2026-02-03 10:08:26,102 - multi_tracker.core.post_processing - DEBUG - Merging forward_32 with backward_91: 11/11 agreeing frames\n",
      "2026-02-03 10:08:26,104 - multi_tracker.core.post_processing - DEBUG - Merging forward_16 with backward_82: 10/14 agreeing frames\n",
      "2026-02-03 10:08:26,109 - multi_tracker.core.post_processing - DEBUG - Merging forward_35 with backward_11: 10/10 agreeing frames\n",
      "2026-02-03 10:08:26,112 - multi_tracker.core.post_processing - DEBUG - Merging forward_92 with backward_17: 9/59 agreeing frames\n",
      "2026-02-03 10:08:26,120 - multi_tracker.core.post_processing - DEBUG - Merging forward_49 with backward_33: 8/8 agreeing frames\n",
      "2026-02-03 10:08:26,123 - multi_tracker.core.post_processing - DEBUG - Merging forward_101 with backward_4: 8/10 agreeing frames\n",
      "2026-02-03 10:08:26,125 - multi_tracker.core.post_processing - DEBUG - Merging forward_28 with backward_86: 6/18 agreeing frames\n",
      "2026-02-03 10:08:26,129 - multi_tracker.core.post_processing - DEBUG - Merging forward_48 with backward_54: 6/11 agreeing frames\n",
      "2026-02-03 10:08:26,132 - multi_tracker.core.post_processing - DEBUG - Merging forward_66 with backward_80: 5/5 agreeing frames\n",
      "2026-02-03 10:08:26,134 - multi_tracker.core.post_processing - DEBUG - Merging forward_94 with backward_27: 3/17 agreeing frames\n",
      "2026-02-03 10:08:26,213 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 104/109 (95.4%) frames agree\n",
      "2026-02-03 10:08:26,228 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/65 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,229 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/68 (95.6%) frames agree\n",
      "2026-02-03 10:08:26,230 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,245 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,248 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 111/111 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,249 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,250 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 45/45 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,251 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,256 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 43/43 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,278 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 100/126 (79.4%) frames agree\n",
      "2026-02-03 10:08:26,281 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 15/20 (75.0%) frames agree\n",
      "2026-02-03 10:08:26,283 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,284 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 54/54 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,285 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/56 (91.1%) frames agree\n",
      "2026-02-03 10:08:26,285 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/44 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,286 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,295 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 170/171 (99.4%) frames agree\n",
      "2026-02-03 10:08:26,301 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 37/39 (94.9%) frames agree\n",
      "2026-02-03 10:08:26,302 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,302 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,304 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 60/68 (88.2%) frames agree\n",
      "2026-02-03 10:08:26,305 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/24 (70.8%) frames agree\n",
      "2026-02-03 10:08:26,306 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:08:26,311 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 66/66 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,312 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 32/33 (97.0%) frames agree\n",
      "2026-02-03 10:08:26,313 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 73/91 (80.2%) frames agree\n",
      "2026-02-03 10:08:26,313 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 74/80 (92.5%) frames agree\n",
      "2026-02-03 10:08:26,315 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,320 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 36/38 (94.7%) frames agree\n",
      "2026-02-03 10:08:26,324 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,324 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/17 (76.5%) frames agree\n",
      "2026-02-03 10:08:26,327 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 95/95 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,330 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/61 (77.0%) frames agree\n",
      "2026-02-03 10:08:26,333 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 39/39 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,334 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 88/92 (95.7%) frames agree\n",
      "2026-02-03 10:08:26,335 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/50 (94.0%) frames agree\n",
      "2026-02-03 10:08:26,335 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,336 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,337 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/20 (80.0%) frames agree\n",
      "2026-02-03 10:08:26,338 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:08:26,340 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 57/57 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,341 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 31/31 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,344 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,345 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 29/30 (96.7%) frames agree\n",
      "2026-02-03 10:08:26,346 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 50/52 (96.2%) frames agree\n",
      "2026-02-03 10:08:26,347 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 20/20 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,348 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,349 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 53/53 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,351 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/45 (97.8%) frames agree\n",
      "2026-02-03 10:08:26,352 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/52 (98.1%) frames agree\n",
      "2026-02-03 10:08:26,353 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 19/19 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,353 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,355 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/35 (97.1%) frames agree\n",
      "2026-02-03 10:08:26,356 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 35/35 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,356 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/27 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,357 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/17 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,358 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/34 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,359 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,360 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 24/34 (70.6%) frames agree\n",
      "2026-02-03 10:08:26,361 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/28 (96.4%) frames agree\n",
      "2026-02-03 10:08:26,362 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/15 (80.0%) frames agree\n",
      "2026-02-03 10:08:26,362 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 25/25 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,363 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,363 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/11 (90.9%) frames agree\n",
      "2026-02-03 10:08:26,364 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,364 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,365 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,365 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,366 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/13 (84.6%) frames agree\n",
      "2026-02-03 10:08:26,368 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,371 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,372 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:08:26,372 - multi_tracker.core.post_processing - INFO - Removed 73 spatially redundant trajectories\n",
      "2026-02-03 10:08:38,589 - multi_tracker.core.post_processing - INFO - Processed overlapping trajectories in 5 iterations\n",
      "2026-02-03 10:08:38,610 - multi_tracker.core.post_processing - INFO - Final result: 154 trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result: 154 trajectories\n"
     ]
    }
   ],
   "source": [
    "# TEST UPDATED ALGORITHM - Reload and re-run\n",
    "import importlib\n",
    "import multi_tracker.core.post_processing\n",
    "importlib.reload(multi_tracker.core.post_processing)\n",
    "from multi_tracker.core.post_processing import resolve_trajectories\n",
    "\n",
    "print(\"Module reloaded with conservative split-on-disagree logic\")\n",
    "print(\"Re-running trajectory resolution...\")\n",
    "\n",
    "resolved_trajectories_v4 = resolve_trajectories(\n",
    "    forward_prepared,\n",
    "    backward_prepared,\n",
    "    video_length=TOTAL_FRAMES,\n",
    "    params=params,\n",
    ")\n",
    "print(f\"\\nResult: {len(resolved_trajectories_v4)} trajectories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bb009508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for trajectory jumps > 115.5 pixels...\n",
      "\n",
      "Trajectories with large jumps: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for trajectory jumps (large position changes between consecutive frames)\n",
    "# This would indicate bad merges that splice together distant locations\n",
    "\n",
    "MAX_ALLOWED_JUMP = REFERENCE_BODY_SIZE * RESIZE_FACTOR * 3  # 3 body sizes\n",
    "print(f\"Checking for trajectory jumps > {MAX_ALLOWED_JUMP:.1f} pixels...\")\n",
    "\n",
    "trajectories_with_jumps = []\n",
    "for i, traj in enumerate(resolved_trajectories_v4):\n",
    "    if len(traj) < 2:\n",
    "        continue\n",
    "    \n",
    "    traj_sorted = traj.sort_values(\"FrameID\")\n",
    "    prev_row = None\n",
    "    max_jump = 0\n",
    "    jump_frames = []\n",
    "    \n",
    "    for _, row in traj_sorted.iterrows():\n",
    "        if prev_row is not None and not pd.isna(row[\"X\"]) and not pd.isna(prev_row[\"X\"]):\n",
    "            jump = np.sqrt((row[\"X\"] - prev_row[\"X\"])**2 + (row[\"Y\"] - prev_row[\"Y\"])**2)\n",
    "            frame_gap = row[\"FrameID\"] - prev_row[\"FrameID\"]\n",
    "            \n",
    "            # Normalize by frame gap (allow larger jumps over gaps)\n",
    "            effective_jump = jump / max(frame_gap, 1)\n",
    "            \n",
    "            if effective_jump > MAX_ALLOWED_JUMP:\n",
    "                jump_frames.append((int(prev_row[\"FrameID\"]), int(row[\"FrameID\"]), jump, frame_gap))\n",
    "                max_jump = max(max_jump, jump)\n",
    "        \n",
    "        prev_row = row\n",
    "    \n",
    "    if jump_frames:\n",
    "        trajectories_with_jumps.append({\n",
    "            \"traj_id\": i,\n",
    "            \"length\": len(traj),\n",
    "            \"num_jumps\": len(jump_frames),\n",
    "            \"max_jump\": max_jump,\n",
    "            \"jumps\": jump_frames[:3]  # First 3 jumps\n",
    "        })\n",
    "\n",
    "print(f\"\\nTrajectories with large jumps: {len(trajectories_with_jumps)}\")\n",
    "if trajectories_with_jumps:\n",
    "    for tj in trajectories_with_jumps[:10]:\n",
    "        print(f\"\\n  Traj {tj['traj_id']} ({tj['length']} pts, {tj['num_jumps']} jumps, max={tj['max_jump']:.1f}px):\")\n",
    "        for f1, f2, jmp, gap in tj['jumps']:\n",
    "            print(f\"    Frame {f1}‚Üí{f2} (gap={gap}): jump={jmp:.1f}px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf18fb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs with 5+ true duplicate frames: 1\n",
      "(31, 143)    8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SUMMARY v4:\n",
      "  Trajectories: 154\n",
      "  Trajectories with large jumps: 0\n",
      "  True duplicate pairs (5+ frames): 1\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate/overlapping trajectories with v4\n",
    "merged_df_v4 = pd.concat(resolved_trajectories_v4, ignore_index=True)\n",
    "\n",
    "# Check for true duplicates (distance < 5px)\n",
    "TRUE_DUPLICATE_THRESHOLD = 5.0\n",
    "true_duplicates_v4 = []\n",
    "\n",
    "for frame in merged_df_v4[\"FrameID\"].unique():\n",
    "    frame_data = merged_df_v4[merged_df_v4[\"FrameID\"] == frame]\n",
    "    if len(frame_data) <= 1:\n",
    "        continue\n",
    "    \n",
    "    traj_ids = frame_data[\"TrajectoryID\"].values\n",
    "    xs = frame_data[\"X\"].values\n",
    "    ys = frame_data[\"Y\"].values\n",
    "    \n",
    "    for i in range(len(traj_ids)):\n",
    "        for j in range(i+1, len(traj_ids)):\n",
    "            if pd.isna(xs[i]) or pd.isna(xs[j]):\n",
    "                continue\n",
    "            dist = np.sqrt((xs[i] - xs[j])**2 + (ys[i] - ys[j])**2)\n",
    "            if dist < TRUE_DUPLICATE_THRESHOLD:\n",
    "                true_duplicates_v4.append((traj_ids[i], traj_ids[j]))\n",
    "\n",
    "if true_duplicates_v4:\n",
    "    # Count unique pairs\n",
    "    pair_counts = pd.Series(true_duplicates_v4).value_counts()\n",
    "    substantial = pair_counts[pair_counts >= 5]\n",
    "    print(f\"Pairs with 5+ true duplicate frames: {len(substantial)}\")\n",
    "    if len(substantial) > 0:\n",
    "        print(substantial)\n",
    "else:\n",
    "    print(\"‚úì No true duplicates found!\")\n",
    "\n",
    "print(f\"\\nSUMMARY v4:\")\n",
    "print(f\"  Trajectories: {len(resolved_trajectories_v4)}\")\n",
    "print(f\"  Trajectories with large jumps: {len(trajectories_with_jumps)}\")\n",
    "print(f\"  True duplicate pairs (5+ frames): {len(substantial) if true_duplicates_v4 else 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "43770c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward trajectories (before merge) with jumps > 50px: 6\n",
      "  Traj 0: jump of 52.3px at frame 13\n",
      "  Traj 4: jump of 57.4px at frame 583\n",
      "  Traj 18: jump of 53.3px at frame 716\n",
      "  Traj 60: jump of 50.2px at frame 330\n",
      "  Traj 80: jump of 50.3px at frame 330\n",
      "\n",
      "Backward trajectories (before merge) with jumps > 50px: 4\n",
      "  Traj 13: jump of 50.0px at frame 40\n",
      "  Traj 37: jump of 51.4px at frame 23\n",
      "  Traj 42: jump of 53.5px at frame 621\n",
      "  Traj 43: jump of 50.8px at frame 409\n",
      "\n",
      "--- COMPARISON ---\n",
      "Original (forward+backward) trajectories with jumps: 10\n",
      "Merged v4 trajectories with jumps: 6 (from previous check)\n",
      "\n",
      "Conclusion: Jumps likely come from ORIGINAL tracking data, not merge artifacts\n"
     ]
    }
   ],
   "source": [
    "# Check if jumps exist in ORIGINAL cleaned data (before merge) vs after merge\n",
    "# This tells us if the jumps are from original tracking or introduced by merging\n",
    "\n",
    "def check_jumps_in_trajectory_list(prepared_list, label, jump_threshold=50.0):\n",
    "    \"\"\"Check for large jumps in prepared trajectory list (before merge).\"\"\"\n",
    "    trajectories_with_jumps = []\n",
    "    for i, traj_df in enumerate(prepared_list):\n",
    "        if len(traj_df) < 2:\n",
    "            continue\n",
    "        traj_sorted = traj_df.sort_values('FrameID')\n",
    "        for j in range(1, len(traj_sorted)):\n",
    "            prev = traj_sorted.iloc[j-1]\n",
    "            curr = traj_sorted.iloc[j]\n",
    "            gap = int(curr['FrameID'] - prev['FrameID'])\n",
    "            if gap == 1:  # Consecutive frames only\n",
    "                dx = curr['X'] - prev['X']\n",
    "                dy = curr['Y'] - prev['Y']\n",
    "                dist = np.sqrt(dx**2 + dy**2)\n",
    "                if dist > jump_threshold:\n",
    "                    trajectories_with_jumps.append((i, int(curr['FrameID']), dist, gap))\n",
    "                    break  # Just note this trajectory has a jump\n",
    "    return trajectories_with_jumps\n",
    "\n",
    "# Check forward cleaned data\n",
    "forward_jumps = check_jumps_in_trajectory_list(forward_prepared, \"forward\")\n",
    "print(f\"Forward trajectories (before merge) with jumps > 50px: {len(forward_jumps)}\")\n",
    "for idx, frame, dist, gap in forward_jumps[:5]:\n",
    "    print(f\"  Traj {idx}: jump of {dist:.1f}px at frame {frame}\")\n",
    "\n",
    "# Check backward cleaned data  \n",
    "backward_jumps = check_jumps_in_trajectory_list(backward_prepared, \"backward\")\n",
    "print(f\"\\nBackward trajectories (before merge) with jumps > 50px: {len(backward_jumps)}\")\n",
    "for idx, frame, dist, gap in backward_jumps[:5]:\n",
    "    print(f\"  Traj {idx}: jump of {dist:.1f}px at frame {frame}\")\n",
    "\n",
    "# Now compare to merged v4 data\n",
    "print(f\"\\n--- COMPARISON ---\")\n",
    "print(f\"Original (forward+backward) trajectories with jumps: {len(forward_jumps) + len(backward_jumps)}\")\n",
    "print(f\"Merged v4 trajectories with jumps: 6 (from previous check)\")\n",
    "print(f\"\\nConclusion: \", end=\"\")\n",
    "if len(forward_jumps) + len(backward_jumps) >= 6:\n",
    "    print(\"Jumps likely come from ORIGINAL tracking data, not merge artifacts\")\n",
    "else:\n",
    "    print(\"Jumps may be introduced by the merge process!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2e6c3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_ALLOWED_JUMP setting: 115.5px\n",
      "But we see jumps of 50-115px in consecutive frames\n",
      "\n",
      "The cleaning uses MAX_ALLOWED_JUMP to BREAK trajectories at large jumps.\n",
      "However, jumps in the 50-115px range suggest the tracker itself had ID swaps\n",
      "that weren't caught by the MAX_ALLOWED_JUMP = 115.5px threshold.\n",
      "\n",
      "To fix these, you could:\n",
      "  1. Lower MAX_ALLOWED_JUMP (e.g., to 40px) to break trajectories at smaller jumps\n",
      "  2. Accept these as tracking errors in the original data\n"
     ]
    }
   ],
   "source": [
    "# Check the MAX_ALLOWED_JUMP parameter used during cleaning\n",
    "print(f\"MAX_ALLOWED_JUMP setting: {MAX_ALLOWED_JUMP}px\")\n",
    "print(f\"But we see jumps of 50-115px in consecutive frames\")\n",
    "print(f\"\\nThe cleaning uses MAX_ALLOWED_JUMP to BREAK trajectories at large jumps.\")\n",
    "print(f\"However, jumps in the 50-115px range suggest the tracker itself had ID swaps\")\n",
    "print(f\"that weren't caught by the MAX_ALLOWED_JUMP = {MAX_ALLOWED_JUMP}px threshold.\")\n",
    "print(f\"\\nTo fix these, you could:\")\n",
    "print(f\"  1. Lower MAX_ALLOWED_JUMP (e.g., to 40px) to break trajectories at smaller jumps\")\n",
    "print(f\"  2. Accept these as tracking errors in the original data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "49732535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_df_v4 columns: ['TrajectoryID', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "\n",
      "Original data jumps (>50px): 10\n",
      "  Max: 57.4px\n",
      "  Min: 50.0px\n",
      "\n",
      "--- Merged v4 jumps (>50px in consecutive frames) ---\n",
      "Merged data jumps (>50px): 0\n",
      "\n",
      "--- COMPARISON ---\n"
     ]
    }
   ],
   "source": [
    "# Compare jump DISTANCES: original vs merged\n",
    "# First check merged_df_v4 columns\n",
    "print(\"merged_df_v4 columns:\", merged_df_v4.columns.tolist())\n",
    "\n",
    "# Original jump distances\n",
    "original_jump_distances = [dist for _, _, dist, _ in forward_jumps + backward_jumps]\n",
    "print(f\"\\nOriginal data jumps (>50px): {len(original_jump_distances)}\")\n",
    "print(f\"  Max: {max(original_jump_distances):.1f}px\" if original_jump_distances else \"  None\")\n",
    "print(f\"  Min: {min(original_jump_distances):.1f}px\" if original_jump_distances else \"  None\")\n",
    "\n",
    "# Merged v4 jump distances - use correct column name\n",
    "print(f\"\\n--- Merged v4 jumps (>50px in consecutive frames) ---\")\n",
    "traj_col = 'TrajectoryID' if 'TrajectoryID' in merged_df_v4.columns else 'trajectory_id'\n",
    "frame_col = 'FrameID' if 'FrameID' in merged_df_v4.columns else 'frame'\n",
    "x_col = 'X' if 'X' in merged_df_v4.columns else 'center_x'\n",
    "y_col = 'Y' if 'Y' in merged_df_v4.columns else 'center_y'\n",
    "\n",
    "merged_jump_details = []\n",
    "for traj_id in merged_df_v4[traj_col].unique():\n",
    "    traj = merged_df_v4[merged_df_v4[traj_col] == traj_id].sort_values(frame_col)\n",
    "    for j in range(1, len(traj)):\n",
    "        prev = traj.iloc[j-1]\n",
    "        curr = traj.iloc[j]\n",
    "        gap = int(curr[frame_col] - prev[frame_col])\n",
    "        if gap == 1:  # Consecutive frames\n",
    "            dx = curr[x_col] - prev[x_col]\n",
    "            dy = curr[y_col] - prev[y_col]\n",
    "            dist = np.sqrt(dx**2 + dy**2)\n",
    "            if dist > 50:\n",
    "                merged_jump_details.append((traj_id, int(curr[frame_col]), dist))\n",
    "\n",
    "print(f\"Merged data jumps (>50px): {len(merged_jump_details)}\")\n",
    "for tid, frame, dist in sorted(merged_jump_details, key=lambda x: -x[2])[:10]:\n",
    "    print(f\"  Traj {tid} at frame {frame}: {dist:.1f}px\")\n",
    "\n",
    "# Compare\n",
    "print(f\"\\n--- COMPARISON ---\")\n",
    "if original_jump_distances and merged_jump_details:\n",
    "    merged_distances = [d for _, _, d in merged_jump_details]\n",
    "    print(f\"Original max jump: {max(original_jump_distances):.1f}px\")\n",
    "    print(f\"Merged max jump: {max(merged_distances):.1f}px\")\n",
    "    if max(merged_distances) > max(original_jump_distances) + 10:\n",
    "        print(f\"\\n‚ö†Ô∏è MERGED DATA HAS BIGGER JUMPS! The merge is creating larger jumps.\")\n",
    "    else:\n",
    "        print(f\"\\nMerged jumps are comparable to original data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7612294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Investigating worst jumps in merged data ===\n"
     ]
    }
   ],
   "source": [
    "# Investigate the worst jumps - look at the trajectory around those frames\n",
    "def show_trajectory_around_jump(df, traj_id, jump_frame, context=5):\n",
    "    traj = df[df['TrajectoryID'] == traj_id].sort_values('FrameID')\n",
    "    idx = traj[traj['FrameID'] == jump_frame].index[0]\n",
    "    start = max(0, traj.index.get_loc(idx) - context)\n",
    "    end = min(len(traj), traj.index.get_loc(idx) + context + 1)\n",
    "    subset = traj.iloc[start:end][['FrameID', 'X', 'Y']]\n",
    "    print(f\"\\nTrajectory {traj_id} around frame {jump_frame}:\")\n",
    "    for i in range(len(subset)):\n",
    "        row = subset.iloc[i]\n",
    "        marker = \" <-- JUMP\" if row['FrameID'] == jump_frame else \"\"\n",
    "        if i > 0:\n",
    "            prev = subset.iloc[i-1]\n",
    "            dx = row['X'] - prev['X']\n",
    "            dy = row['Y'] - prev['Y']\n",
    "            dist = np.sqrt(dx**2 + dy**2)\n",
    "            gap = int(row['FrameID'] - prev['FrameID'])\n",
    "            print(f\"  Frame {int(row['FrameID']):4d}: ({row['X']:.1f}, {row['Y']:.1f}) | jump={dist:.1f}px, gap={gap} frames{marker}\")\n",
    "        else:\n",
    "            print(f\"  Frame {int(row['FrameID']):4d}: ({row['X']:.1f}, {row['Y']:.1f})\")\n",
    "\n",
    "# Show top 3 worst jumps\n",
    "print(\"=== Investigating worst jumps in merged data ===\")\n",
    "for tid, frame, dist in sorted(merged_jump_details, key=lambda x: -x[2])[:3]:\n",
    "    show_trajectory_around_jump(merged_df_v4, tid, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8992a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:08:50,050 - multi_tracker.core.post_processing - INFO - Starting conservative trajectory resolution with 102 forward and 93 backward trajectories\n",
      "2026-02-03 10:08:50,051 - multi_tracker.core.post_processing - INFO - Parameters: AGREEMENT_DISTANCE=9.62px, MIN_OVERLAP_FRAMES=2, MIN_LENGTH=10\n",
      "2026-02-03 10:08:50,143 - multi_tracker.core.post_processing - INFO - After cleaning: 102 forward, 93 backward\n",
      "2026-02-03 10:08:50,144 - multi_tracker.core.post_processing - DEBUG - Using Numba-accelerated merge candidate search\n",
      "2026-02-03 10:08:50,207 - multi_tracker.core.post_processing - INFO - Found 265 merge candidates\n",
      "2026-02-03 10:08:50,207 - multi_tracker.core.post_processing - DEBUG - Merging forward_62 with backward_21: 530/530 agreeing frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REFERENCE_BODY_SIZE = 77.0\n",
      "Using params: {'AGREEMENT_DISTANCE': 9.62, 'MIN_OVERLAP_FRAMES': 2, 'MIN_TRAJECTORY_LENGTH': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:08:50,253 - multi_tracker.core.post_processing - DEBUG - Merging forward_11 with backward_56: 451/451 agreeing frames\n",
      "2026-02-03 10:08:50,295 - multi_tracker.core.post_processing - DEBUG - Merging forward_9 with backward_37: 404/449 agreeing frames\n",
      "2026-02-03 10:08:50,351 - multi_tracker.core.post_processing - DEBUG - Merging forward_23 with backward_42: 390/462 agreeing frames\n",
      "2026-02-03 10:08:50,403 - multi_tracker.core.post_processing - DEBUG - Merging forward_37 with backward_9: 356/390 agreeing frames\n",
      "2026-02-03 10:08:50,449 - multi_tracker.core.post_processing - DEBUG - Merging forward_33 with backward_67: 322/322 agreeing frames\n",
      "2026-02-03 10:08:50,479 - multi_tracker.core.post_processing - DEBUG - Merging forward_19 with backward_26: 318/502 agreeing frames\n",
      "2026-02-03 10:08:50,537 - multi_tracker.core.post_processing - DEBUG - Merging forward_80 with backward_45: 310/311 agreeing frames\n",
      "2026-02-03 10:08:50,564 - multi_tracker.core.post_processing - DEBUG - Merging forward_39 with backward_12: 283/379 agreeing frames\n",
      "2026-02-03 10:08:50,613 - multi_tracker.core.post_processing - DEBUG - Merging forward_17 with backward_63: 274/349 agreeing frames\n",
      "2026-02-03 10:08:50,649 - multi_tracker.core.post_processing - DEBUG - Merging forward_42 with backward_58: 271/290 agreeing frames\n",
      "2026-02-03 10:08:50,688 - multi_tracker.core.post_processing - DEBUG - Merging forward_29 with backward_68: 270/270 agreeing frames\n",
      "2026-02-03 10:08:50,713 - multi_tracker.core.post_processing - DEBUG - Merging forward_24 with backward_43: 258/260 agreeing frames\n",
      "2026-02-03 10:08:50,755 - multi_tracker.core.post_processing - DEBUG - Merging forward_52 with backward_64: 253/279 agreeing frames\n",
      "2026-02-03 10:08:50,784 - multi_tracker.core.post_processing - DEBUG - Merging forward_65 with backward_53: 240/250 agreeing frames\n",
      "2026-02-03 10:08:50,813 - multi_tracker.core.post_processing - DEBUG - Merging forward_3 with backward_34: 226/236 agreeing frames\n",
      "2026-02-03 10:08:50,846 - multi_tracker.core.post_processing - DEBUG - Merging forward_44 with backward_24: 222/222 agreeing frames\n",
      "2026-02-03 10:08:50,870 - multi_tracker.core.post_processing - DEBUG - Merging forward_74 with backward_50: 221/221 agreeing frames\n",
      "2026-02-03 10:08:50,891 - multi_tracker.core.post_processing - DEBUG - Merging forward_71 with backward_32: 194/197 agreeing frames\n",
      "2026-02-03 10:08:50,922 - multi_tracker.core.post_processing - DEBUG - Merging forward_60 with backward_16: 188/189 agreeing frames\n",
      "2026-02-03 10:08:50,938 - multi_tracker.core.post_processing - DEBUG - Merging forward_12 with backward_46: 183/197 agreeing frames\n",
      "2026-02-03 10:08:50,963 - multi_tracker.core.post_processing - DEBUG - Merging forward_67 with backward_31: 179/179 agreeing frames\n",
      "2026-02-03 10:08:50,981 - multi_tracker.core.post_processing - DEBUG - Merging forward_64 with backward_79: 175/179 agreeing frames\n",
      "2026-02-03 10:08:51,004 - multi_tracker.core.post_processing - DEBUG - Merging forward_78 with backward_36: 167/167 agreeing frames\n",
      "2026-02-03 10:08:51,020 - multi_tracker.core.post_processing - DEBUG - Merging forward_84 with backward_6: 148/148 agreeing frames\n",
      "2026-02-03 10:08:51,035 - multi_tracker.core.post_processing - DEBUG - Merging forward_88 with backward_41: 143/143 agreeing frames\n",
      "2026-02-03 10:08:51,048 - multi_tracker.core.post_processing - DEBUG - Merging forward_55 with backward_70: 125/125 agreeing frames\n",
      "2026-02-03 10:08:51,067 - multi_tracker.core.post_processing - DEBUG - Merging forward_86 with backward_22: 122/150 agreeing frames\n",
      "2026-02-03 10:08:51,101 - multi_tracker.core.post_processing - DEBUG - Merging forward_14 with backward_25: 117/152 agreeing frames\n",
      "2026-02-03 10:08:51,120 - multi_tracker.core.post_processing - DEBUG - Merging forward_83 with backward_7: 117/124 agreeing frames\n",
      "2026-02-03 10:08:51,132 - multi_tracker.core.post_processing - DEBUG - Merging forward_7 with backward_72: 116/130 agreeing frames\n",
      "2026-02-03 10:08:51,148 - multi_tracker.core.post_processing - DEBUG - Merging forward_61 with backward_15: 109/111 agreeing frames\n",
      "2026-02-03 10:08:51,165 - multi_tracker.core.post_processing - DEBUG - Merging forward_18 with backward_35: 98/190 agreeing frames\n",
      "2026-02-03 10:08:51,197 - multi_tracker.core.post_processing - DEBUG - Merging forward_63 with backward_20: 98/118 agreeing frames\n",
      "2026-02-03 10:08:51,210 - multi_tracker.core.post_processing - DEBUG - Merging forward_54 with backward_59: 95/121 agreeing frames\n",
      "2026-02-03 10:08:51,233 - multi_tracker.core.post_processing - DEBUG - Merging forward_68 with backward_30: 91/102 agreeing frames\n",
      "2026-02-03 10:08:51,247 - multi_tracker.core.post_processing - DEBUG - Merging forward_2 with backward_51: 88/93 agreeing frames\n",
      "2026-02-03 10:08:51,257 - multi_tracker.core.post_processing - DEBUG - Merging forward_51 with backward_65: 85/95 agreeing frames\n",
      "2026-02-03 10:08:51,272 - multi_tracker.core.post_processing - DEBUG - Merging forward_90 with backward_5: 81/81 agreeing frames\n",
      "2026-02-03 10:08:51,280 - multi_tracker.core.post_processing - DEBUG - Merging forward_70 with backward_10: 80/80 agreeing frames\n",
      "2026-02-03 10:08:51,293 - multi_tracker.core.post_processing - DEBUG - Merging forward_72 with backward_19: 74/79 agreeing frames\n",
      "2026-02-03 10:08:51,305 - multi_tracker.core.post_processing - DEBUG - Merging forward_34 with backward_66: 73/74 agreeing frames\n",
      "2026-02-03 10:08:51,321 - multi_tracker.core.post_processing - DEBUG - Merging forward_47 with backward_78: 68/70 agreeing frames\n",
      "2026-02-03 10:08:51,335 - multi_tracker.core.post_processing - DEBUG - Merging forward_45 with backward_23: 62/62 agreeing frames\n",
      "2026-02-03 10:08:51,341 - multi_tracker.core.post_processing - DEBUG - Merging forward_43 with backward_87: 58/69 agreeing frames\n",
      "2026-02-03 10:08:51,354 - multi_tracker.core.post_processing - DEBUG - Merging forward_75 with backward_49: 54/55 agreeing frames\n",
      "2026-02-03 10:08:51,360 - multi_tracker.core.post_processing - DEBUG - Merging forward_38 with backward_89: 53/61 agreeing frames\n",
      "2026-02-03 10:08:51,370 - multi_tracker.core.post_processing - DEBUG - Merging forward_25 with backward_55: 52/72 agreeing frames\n",
      "2026-02-03 10:08:51,385 - multi_tracker.core.post_processing - DEBUG - Merging forward_59 with backward_84: 49/59 agreeing frames\n",
      "2026-02-03 10:08:51,404 - multi_tracker.core.post_processing - DEBUG - Merging forward_6 with backward_8: 47/80 agreeing frames\n",
      "2026-02-03 10:08:51,416 - multi_tracker.core.post_processing - DEBUG - Merging forward_50 with backward_77: 45/56 agreeing frames\n",
      "2026-02-03 10:08:51,429 - multi_tracker.core.post_processing - DEBUG - Merging forward_20 with backward_83: 41/54 agreeing frames\n",
      "2026-02-03 10:08:51,437 - multi_tracker.core.post_processing - DEBUG - Merging forward_56 with backward_69: 39/45 agreeing frames\n",
      "2026-02-03 10:08:51,445 - multi_tracker.core.post_processing - DEBUG - Merging forward_10 with backward_47: 36/37 agreeing frames\n",
      "2026-02-03 10:08:51,450 - multi_tracker.core.post_processing - DEBUG - Merging forward_96 with backward_2: 34/34 agreeing frames\n",
      "2026-02-03 10:08:51,457 - multi_tracker.core.post_processing - DEBUG - Merging forward_91 with backward_13: 31/34 agreeing frames\n",
      "2026-02-03 10:08:51,464 - multi_tracker.core.post_processing - DEBUG - Merging forward_98 with backward_0: 31/31 agreeing frames\n",
      "2026-02-03 10:08:51,468 - multi_tracker.core.post_processing - DEBUG - Merging forward_8 with backward_81: 29/29 agreeing frames\n",
      "2026-02-03 10:08:51,473 - multi_tracker.core.post_processing - DEBUG - Merging forward_87 with backward_61: 28/28 agreeing frames\n",
      "2026-02-03 10:08:51,477 - multi_tracker.core.post_processing - DEBUG - Merging forward_1 with backward_52: 27/37 agreeing frames\n",
      "2026-02-03 10:08:51,487 - multi_tracker.core.post_processing - DEBUG - Merging forward_26 with backward_88: 27/34 agreeing frames\n",
      "2026-02-03 10:08:51,496 - multi_tracker.core.post_processing - DEBUG - Merging forward_81 with backward_75: 27/27 agreeing frames\n",
      "2026-02-03 10:08:51,499 - multi_tracker.core.post_processing - DEBUG - Merging forward_79 with backward_18: 25/98 agreeing frames\n",
      "2026-02-03 10:08:51,523 - multi_tracker.core.post_processing - DEBUG - Merging forward_93 with backward_38: 17/19 agreeing frames\n",
      "2026-02-03 10:08:51,529 - multi_tracker.core.post_processing - DEBUG - Merging forward_0 with backward_57: 16/27 agreeing frames\n",
      "2026-02-03 10:08:51,534 - multi_tracker.core.post_processing - DEBUG - Merging forward_58 with backward_85: 15/23 agreeing frames\n",
      "2026-02-03 10:08:51,540 - multi_tracker.core.post_processing - DEBUG - Merging forward_41 with backward_29: 14/15 agreeing frames\n",
      "2026-02-03 10:08:51,548 - multi_tracker.core.post_processing - DEBUG - Merging forward_82 with backward_74: 13/13 agreeing frames\n",
      "2026-02-03 10:08:51,550 - multi_tracker.core.post_processing - DEBUG - Merging forward_100 with backward_3: 12/16 agreeing frames\n",
      "2026-02-03 10:08:51,552 - multi_tracker.core.post_processing - DEBUG - Merging forward_32 with backward_91: 11/11 agreeing frames\n",
      "2026-02-03 10:08:51,555 - multi_tracker.core.post_processing - DEBUG - Merging forward_16 with backward_82: 10/14 agreeing frames\n",
      "2026-02-03 10:08:51,560 - multi_tracker.core.post_processing - DEBUG - Merging forward_35 with backward_11: 10/10 agreeing frames\n",
      "2026-02-03 10:08:51,563 - multi_tracker.core.post_processing - DEBUG - Merging forward_92 with backward_17: 9/59 agreeing frames\n",
      "2026-02-03 10:08:51,572 - multi_tracker.core.post_processing - DEBUG - Merging forward_49 with backward_33: 8/8 agreeing frames\n",
      "2026-02-03 10:08:51,574 - multi_tracker.core.post_processing - DEBUG - Merging forward_101 with backward_4: 8/10 agreeing frames\n",
      "2026-02-03 10:08:51,577 - multi_tracker.core.post_processing - DEBUG - Merging forward_28 with backward_86: 6/18 agreeing frames\n",
      "2026-02-03 10:08:51,581 - multi_tracker.core.post_processing - DEBUG - Merging forward_48 with backward_54: 6/11 agreeing frames\n",
      "2026-02-03 10:08:51,584 - multi_tracker.core.post_processing - DEBUG - Merging forward_66 with backward_80: 5/5 agreeing frames\n",
      "2026-02-03 10:08:51,587 - multi_tracker.core.post_processing - DEBUG - Merging forward_94 with backward_27: 3/17 agreeing frames\n",
      "2026-02-03 10:08:51,665 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 104/109 (95.4%) frames agree\n",
      "2026-02-03 10:08:51,679 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/65 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,680 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/68 (95.6%) frames agree\n",
      "2026-02-03 10:08:51,681 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,697 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,700 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 111/111 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,701 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,702 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 45/45 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,703 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,706 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 43/43 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,727 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 100/126 (79.4%) frames agree\n",
      "2026-02-03 10:08:51,730 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 15/20 (75.0%) frames agree\n",
      "2026-02-03 10:08:51,732 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,733 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 54/54 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,733 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/56 (91.1%) frames agree\n",
      "2026-02-03 10:08:51,734 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/44 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,734 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,743 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 170/171 (99.4%) frames agree\n",
      "2026-02-03 10:08:51,749 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 37/39 (94.9%) frames agree\n",
      "2026-02-03 10:08:51,750 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,750 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,752 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 60/68 (88.2%) frames agree\n",
      "2026-02-03 10:08:51,753 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/24 (70.8%) frames agree\n",
      "2026-02-03 10:08:51,754 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:08:51,759 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 66/66 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,760 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 32/33 (97.0%) frames agree\n",
      "2026-02-03 10:08:51,761 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 73/91 (80.2%) frames agree\n",
      "2026-02-03 10:08:51,761 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 74/80 (92.5%) frames agree\n",
      "2026-02-03 10:08:51,763 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,768 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 36/38 (94.7%) frames agree\n",
      "2026-02-03 10:08:51,771 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,772 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/17 (76.5%) frames agree\n",
      "2026-02-03 10:08:51,774 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 95/95 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,777 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/61 (77.0%) frames agree\n",
      "2026-02-03 10:08:51,780 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 39/39 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,781 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 88/92 (95.7%) frames agree\n",
      "2026-02-03 10:08:51,782 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/50 (94.0%) frames agree\n",
      "2026-02-03 10:08:51,782 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,783 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,784 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/20 (80.0%) frames agree\n",
      "2026-02-03 10:08:51,784 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:08:51,786 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 57/57 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,787 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 31/31 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,789 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,790 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 29/30 (96.7%) frames agree\n",
      "2026-02-03 10:08:51,791 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 50/52 (96.2%) frames agree\n",
      "2026-02-03 10:08:51,792 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 20/20 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,793 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,793 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 53/53 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,795 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/45 (97.8%) frames agree\n",
      "2026-02-03 10:08:51,796 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/52 (98.1%) frames agree\n",
      "2026-02-03 10:08:51,797 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 19/19 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,797 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,799 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/35 (97.1%) frames agree\n",
      "2026-02-03 10:08:51,800 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 35/35 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,801 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/27 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,801 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/17 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,802 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/34 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,802 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,803 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 24/34 (70.6%) frames agree\n",
      "2026-02-03 10:08:51,804 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/28 (96.4%) frames agree\n",
      "2026-02-03 10:08:51,805 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/15 (80.0%) frames agree\n",
      "2026-02-03 10:08:51,805 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 25/25 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,805 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,806 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/11 (90.9%) frames agree\n",
      "2026-02-03 10:08:51,807 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,807 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,808 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,808 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,809 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/13 (84.6%) frames agree\n",
      "2026-02-03 10:08:51,809 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,809 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,810 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:08:51,810 - multi_tracker.core.post_processing - INFO - Removed 73 spatially redundant trajectories\n",
      "2026-02-03 10:09:03,943 - multi_tracker.core.post_processing - INFO - Processed overlapping trajectories in 5 iterations\n",
      "2026-02-03 10:09:03,967 - multi_tracker.core.post_processing - INFO - Final result: 154 trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v5 (with spatial continuity): 154 trajectories\n",
      "\n",
      "--- v5 jumps (>50px in consecutive frames) ---\n",
      "Merged data jumps (>50px): 0\n",
      "\n",
      "--- COMPARISON ---\n",
      "Original trajectories: 10 with jumps > 50px (max 57.4px)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() iterable argument is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- COMPARISON ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal trajectories: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(forward_jumps)\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(backward_jumps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with jumps > 50px (max \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(original_jump_distances)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mpx)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mv4 (old): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(merged_jump_details)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trajectories with jumps > 50px (max \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43md\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mmerged_jump_details\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mpx)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merged_jump_details_v5:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mv5 (new): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(merged_jump_details_v5)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trajectories with jumps > 50px (max \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m([d\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39m_,_,d\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmerged_jump_details_v5])\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mpx)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: max() iterable argument is empty"
     ]
    }
   ],
   "source": [
    "# Re-test with updated spatial continuity check\n",
    "import importlib\n",
    "from multi_tracker.core import post_processing\n",
    "importlib.reload(post_processing)\n",
    "\n",
    "# Check the current REFERENCE_BODY_SIZE value\n",
    "print(f\"REFERENCE_BODY_SIZE = {REFERENCE_BODY_SIZE}\")\n",
    "\n",
    "# Parameters (same as before) - hardcode the values to be safe\n",
    "params = {\n",
    "    \"AGREEMENT_DISTANCE\": 9.62,  # REFERENCE_BODY_SIZE\n",
    "    \"MIN_OVERLAP_FRAMES\": 2,\n",
    "    \"MIN_TRAJECTORY_LENGTH\": 10  # Correct key name\n",
    "}\n",
    "\n",
    "print(f\"Using params: {params}\")\n",
    "\n",
    "# Re-run resolve_trajectories with v5 fix\n",
    "resolved_trajectories_v5 = post_processing.resolve_trajectories(\n",
    "    forward_prepared,\n",
    "    backward_prepared,\n",
    "    video_length=TOTAL_FRAMES,\n",
    "    params=params\n",
    ")\n",
    "print(f\"v5 (with spatial continuity): {len(resolved_trajectories_v5)} trajectories\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "merged_df_v5 = pd.concat(resolved_trajectories_v5, ignore_index=True)\n",
    "\n",
    "# Check for jumps in v5\n",
    "merged_jump_details_v5 = []\n",
    "for traj_id in merged_df_v5['TrajectoryID'].unique():\n",
    "    traj = merged_df_v5[merged_df_v5['TrajectoryID'] == traj_id].sort_values('FrameID')\n",
    "    for j in range(1, len(traj)):\n",
    "        prev = traj.iloc[j-1]\n",
    "        curr = traj.iloc[j]\n",
    "        gap = int(curr['FrameID'] - prev['FrameID'])\n",
    "        if gap == 1:  # Consecutive frames\n",
    "            dx = curr['X'] - prev['X']\n",
    "            dy = curr['Y'] - prev['Y']\n",
    "            dist = np.sqrt(dx**2 + dy**2)\n",
    "            if dist > 50:\n",
    "                merged_jump_details_v5.append((traj_id, int(curr['FrameID']), dist))\n",
    "\n",
    "print(f\"\\n--- v5 jumps (>50px in consecutive frames) ---\")\n",
    "print(f\"Merged data jumps (>50px): {len(merged_jump_details_v5)}\")\n",
    "for tid, frame, dist in sorted(merged_jump_details_v5, key=lambda x: -x[2])[:10]:\n",
    "    print(f\"  Traj {tid} at frame {frame}: {dist:.1f}px\")\n",
    "\n",
    "# Compare\n",
    "print(f\"\\n--- COMPARISON ---\")\n",
    "print(f\"Original trajectories: {len(forward_jumps) + len(backward_jumps)} with jumps > 50px (max {max(original_jump_distances):.1f}px)\")\n",
    "print(f\"v4 (old): {len(merged_jump_details)} trajectories with jumps > 50px (max {max([d for _,_,d in merged_jump_details]):.1f}px)\")\n",
    "if merged_jump_details_v5:\n",
    "    print(f\"v5 (new): {len(merged_jump_details_v5)} trajectories with jumps > 50px (max {max([d for _,_,d in merged_jump_details_v5]):.1f}px)\")\n",
    "else:\n",
    "    print(f\"v5 (new): 0 trajectories with jumps > 50px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcbafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trajectory 100 around frame 475:\n",
      "  Frame  469: (1663.0, 1586.0)\n",
      "  Frame  470: (1671.0, 1588.0) | jump=8.2px, gap=1 frames\n",
      "  Frame  471: (1678.0, 1592.0) | jump=8.1px, gap=1 frames\n",
      "  Frame  472: (1684.0, 1597.0) | jump=7.8px, gap=1 frames\n",
      "  Frame  473: (1693.0, 1600.0) | jump=9.5px, gap=1 frames\n",
      "  Frame  474: (1700.0, 1605.0) | jump=8.6px, gap=1 frames\n",
      "  Frame  475: (1529.0, 1488.0) | jump=207.2px, gap=1 frames <-- JUMP\n",
      "  Frame  476: (1706.0, 1607.0) | jump=213.3px, gap=1 frames\n",
      "  Frame  477: (1705.0, 1608.0) | jump=1.4px, gap=1 frames\n",
      "  Frame  478: (nan, nan) | prev NaN\n",
      "  Frame  479: (1647.0, 1598.0) | prev NaN\n",
      "  Frame  480: (1651.0, 1599.0) | jump=4.1px, gap=1 frames\n",
      "  Frame  481: (1657.0, 1606.0) | jump=9.2px, gap=1 frames\n",
      "  Frame  482: (1664.0, 1613.0) | jump=9.9px, gap=1 frames\n",
      "  Frame  483: (1672.0, 1617.0) | jump=8.9px, gap=1 frames\n",
      "  Frame  484: (1676.0, 1619.0) | jump=4.5px, gap=1 frames\n",
      "  Frame  485: (nan, nan) | prev NaN\n"
     ]
    }
   ],
   "source": [
    "# Let's look at trajectory 100 in detail - where does this jump come from?\n",
    "def show_trajectory_around_jump_v5(df, traj_id, jump_frame, context=5):\n",
    "    traj = df[df['TrajectoryID'] == traj_id].sort_values('FrameID')\n",
    "    if jump_frame not in traj['FrameID'].values:\n",
    "        print(f\"Frame {jump_frame} not in trajectory {traj_id}\")\n",
    "        return\n",
    "    \n",
    "    idx = traj[traj['FrameID'] == jump_frame].index[0]\n",
    "    pos = list(traj.index).index(idx)\n",
    "    start = max(0, pos - context)\n",
    "    end = min(len(traj), pos + context + 1)\n",
    "    subset = traj.iloc[start:end][['FrameID', 'X', 'Y']]\n",
    "    \n",
    "    print(f\"\\nTrajectory {traj_id} around frame {jump_frame}:\")\n",
    "    for i in range(len(subset)):\n",
    "        row = subset.iloc[i]\n",
    "        marker = \" <-- JUMP\" if row['FrameID'] == jump_frame else \"\"\n",
    "        if i > 0:\n",
    "            prev = subset.iloc[i-1]\n",
    "            if not pd.isna(prev['X']) and not pd.isna(row['X']):\n",
    "                dx = row['X'] - prev['X']\n",
    "                dy = row['Y'] - prev['Y']\n",
    "                dist = np.sqrt(dx**2 + dy**2)\n",
    "                gap = int(row['FrameID'] - prev['FrameID'])\n",
    "                print(f\"  Frame {int(row['FrameID']):4d}: ({row['X']:.1f}, {row['Y']:.1f}) | jump={dist:.1f}px, gap={gap} frames{marker}\")\n",
    "            else:\n",
    "                print(f\"  Frame {int(row['FrameID']):4d}: ({row['X']}, {row['Y']}) | prev NaN{marker}\")\n",
    "        else:\n",
    "            print(f\"  Frame {int(row['FrameID']):4d}: ({row['X']:.1f}, {row['Y']:.1f})\")\n",
    "\n",
    "# Check trajectory 100 (the worst one)\n",
    "show_trajectory_around_jump_v5(merged_df_v5, 100, 475, context=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 09:44:27,773 - multi_tracker.core.post_processing - INFO - Starting conservative trajectory resolution with 102 forward and 93 backward trajectories\n",
      "2026-02-03 09:44:27,773 - multi_tracker.core.post_processing - INFO - Parameters: AGREEMENT_DISTANCE=9.62px, MIN_OVERLAP_FRAMES=2, MIN_LENGTH=10\n",
      "2026-02-03 09:44:27,855 - multi_tracker.core.post_processing - INFO - After cleaning: 102 forward, 93 backward\n",
      "2026-02-03 09:44:41,373 - multi_tracker.core.post_processing - INFO - Found 266 merge candidates\n",
      "2026-02-03 09:44:51,693 - multi_tracker.core.post_processing - INFO - Removed 73 spatially redundant trajectories\n",
      "2026-02-03 09:44:53,408 - multi_tracker.core.post_processing - INFO - Processed overlapping trajectories in 5 iterations\n",
      "2026-02-03 09:44:53,429 - multi_tracker.core.post_processing - INFO - Final result: 155 trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v6 (with spatial jump splitting): 155 trajectories\n",
      "\n",
      "--- v6 jumps (>50px in consecutive frames) ---\n",
      "Merged data jumps (>50px): 0\n",
      "\n",
      "--- COMPARISON ---\n",
      "Original trajectories: 16 with jumps > 50px (max 115.2px)\n",
      "v4 (old): 21 trajectories with jumps > 50px (max 274.4px)\n",
      "v5: 12 trajectories with jumps > 50px (max 213.3px)\n",
      "v6: 0 trajectories with jumps > 50px\n"
     ]
    }
   ],
   "source": [
    "# Re-test with v6 fix (spatial jump splitting in _split_dataframe_into_segments)\n",
    "import importlib\n",
    "from multi_tracker.core import post_processing\n",
    "importlib.reload(post_processing)\n",
    "\n",
    "# Parameters (same as before)\n",
    "params = {\n",
    "    \"AGREEMENT_DISTANCE\": 9.62,  # REFERENCE_BODY_SIZE\n",
    "    \"MIN_OVERLAP_FRAMES\": 2,\n",
    "    \"MIN_TRAJECTORY_LENGTH\": 10\n",
    "}\n",
    "\n",
    "# Re-run resolve_trajectories with v6 fix\n",
    "resolved_trajectories_v6 = post_processing.resolve_trajectories(\n",
    "    forward_prepared,\n",
    "    backward_prepared,\n",
    "    video_length=TOTAL_FRAMES,\n",
    "    params=params\n",
    ")\n",
    "print(f\"v6 (with spatial jump splitting): {len(resolved_trajectories_v6)} trajectories\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "merged_df_v6 = pd.concat(resolved_trajectories_v6, ignore_index=True)\n",
    "\n",
    "# Check for jumps in v6\n",
    "merged_jump_details_v6 = []\n",
    "for traj_id in merged_df_v6['TrajectoryID'].unique():\n",
    "    traj = merged_df_v6[merged_df_v6['TrajectoryID'] == traj_id].sort_values('FrameID')\n",
    "    for j in range(1, len(traj)):\n",
    "        prev = traj.iloc[j-1]\n",
    "        curr = traj.iloc[j]\n",
    "        gap = int(curr['FrameID'] - prev['FrameID'])\n",
    "        if gap == 1:  # Consecutive frames\n",
    "            if not pd.isna(prev['X']) and not pd.isna(curr['X']):\n",
    "                dx = curr['X'] - prev['X']\n",
    "                dy = curr['Y'] - prev['Y']\n",
    "                dist = np.sqrt(dx**2 + dy**2)\n",
    "                if dist > 50:\n",
    "                    merged_jump_details_v6.append((traj_id, int(curr['FrameID']), dist))\n",
    "\n",
    "print(f\"\\n--- v6 jumps (>50px in consecutive frames) ---\")\n",
    "print(f\"Merged data jumps (>50px): {len(merged_jump_details_v6)}\")\n",
    "for tid, frame, dist in sorted(merged_jump_details_v6, key=lambda x: -x[2])[:10]:\n",
    "    print(f\"  Traj {tid} at frame {frame}: {dist:.1f}px\")\n",
    "\n",
    "# Compare all versions\n",
    "print(f\"\\n--- COMPARISON ---\")\n",
    "print(f\"Original trajectories: {len(forward_jumps) + len(backward_jumps)} with jumps > 50px (max {max(original_jump_distances):.1f}px)\")\n",
    "print(f\"v4 (old): {len(merged_jump_details)} trajectories with jumps > 50px (max {max([d for _,_,d in merged_jump_details]):.1f}px)\")\n",
    "if merged_jump_details_v5:\n",
    "    print(f\"v5: {len(merged_jump_details_v5)} trajectories with jumps > 50px (max {max([d for _,_,d in merged_jump_details_v5]):.1f}px)\")\n",
    "else:\n",
    "    print(f\"v5: 0 trajectories with jumps > 50px\")\n",
    "if merged_jump_details_v6:\n",
    "    print(f\"v6: {len(merged_jump_details_v6)} trajectories with jumps > 50px (max {max([d for _,_,d in merged_jump_details_v6]):.1f}px)\")\n",
    "else:\n",
    "    print(f\"v6: 0 trajectories with jumps > 50px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38293e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:09:07,002 - multi_tracker.core.post_processing - INFO - Starting conservative trajectory resolution with 102 forward and 93 backward trajectories\n",
      "2026-02-03 10:09:07,002 - multi_tracker.core.post_processing - INFO - Parameters: AGREEMENT_DISTANCE=9.62px, MIN_OVERLAP_FRAMES=2, MIN_LENGTH=10\n",
      "2026-02-03 10:09:07,101 - multi_tracker.core.post_processing - INFO - After cleaning: 102 forward, 93 backward\n",
      "2026-02-03 10:09:07,101 - multi_tracker.core.post_processing - DEBUG - Using Numba-accelerated merge candidate search\n",
      "2026-02-03 10:09:07,165 - multi_tracker.core.post_processing - INFO - Found 265 merge candidates\n",
      "2026-02-03 10:09:07,165 - multi_tracker.core.post_processing - DEBUG - Merging forward_62 with backward_21: 530/530 agreeing frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba available: True\n",
      "\n",
      "--- Performance Test ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 10:09:07,212 - multi_tracker.core.post_processing - DEBUG - Merging forward_11 with backward_56: 451/451 agreeing frames\n",
      "2026-02-03 10:09:07,254 - multi_tracker.core.post_processing - DEBUG - Merging forward_9 with backward_37: 404/449 agreeing frames\n",
      "2026-02-03 10:09:07,311 - multi_tracker.core.post_processing - DEBUG - Merging forward_23 with backward_42: 390/462 agreeing frames\n",
      "2026-02-03 10:09:07,362 - multi_tracker.core.post_processing - DEBUG - Merging forward_37 with backward_9: 356/390 agreeing frames\n",
      "2026-02-03 10:09:07,411 - multi_tracker.core.post_processing - DEBUG - Merging forward_33 with backward_67: 322/322 agreeing frames\n",
      "2026-02-03 10:09:07,441 - multi_tracker.core.post_processing - DEBUG - Merging forward_19 with backward_26: 318/502 agreeing frames\n",
      "2026-02-03 10:09:07,505 - multi_tracker.core.post_processing - DEBUG - Merging forward_80 with backward_45: 310/311 agreeing frames\n",
      "2026-02-03 10:09:07,532 - multi_tracker.core.post_processing - DEBUG - Merging forward_39 with backward_12: 283/379 agreeing frames\n",
      "2026-02-03 10:09:07,581 - multi_tracker.core.post_processing - DEBUG - Merging forward_17 with backward_63: 274/349 agreeing frames\n",
      "2026-02-03 10:09:07,615 - multi_tracker.core.post_processing - DEBUG - Merging forward_42 with backward_58: 271/290 agreeing frames\n",
      "2026-02-03 10:09:07,654 - multi_tracker.core.post_processing - DEBUG - Merging forward_29 with backward_68: 270/270 agreeing frames\n",
      "2026-02-03 10:09:07,681 - multi_tracker.core.post_processing - DEBUG - Merging forward_24 with backward_43: 258/260 agreeing frames\n",
      "2026-02-03 10:09:07,725 - multi_tracker.core.post_processing - DEBUG - Merging forward_52 with backward_64: 253/279 agreeing frames\n",
      "2026-02-03 10:09:07,756 - multi_tracker.core.post_processing - DEBUG - Merging forward_65 with backward_53: 240/250 agreeing frames\n",
      "2026-02-03 10:09:07,785 - multi_tracker.core.post_processing - DEBUG - Merging forward_3 with backward_34: 226/236 agreeing frames\n",
      "2026-02-03 10:09:07,819 - multi_tracker.core.post_processing - DEBUG - Merging forward_44 with backward_24: 222/222 agreeing frames\n",
      "2026-02-03 10:09:07,844 - multi_tracker.core.post_processing - DEBUG - Merging forward_74 with backward_50: 221/221 agreeing frames\n",
      "2026-02-03 10:09:07,866 - multi_tracker.core.post_processing - DEBUG - Merging forward_71 with backward_32: 194/197 agreeing frames\n",
      "2026-02-03 10:09:07,899 - multi_tracker.core.post_processing - DEBUG - Merging forward_60 with backward_16: 188/189 agreeing frames\n",
      "2026-02-03 10:09:07,916 - multi_tracker.core.post_processing - DEBUG - Merging forward_12 with backward_46: 183/197 agreeing frames\n",
      "2026-02-03 10:09:07,941 - multi_tracker.core.post_processing - DEBUG - Merging forward_67 with backward_31: 179/179 agreeing frames\n",
      "2026-02-03 10:09:07,960 - multi_tracker.core.post_processing - DEBUG - Merging forward_64 with backward_79: 175/179 agreeing frames\n",
      "2026-02-03 10:09:07,983 - multi_tracker.core.post_processing - DEBUG - Merging forward_78 with backward_36: 167/167 agreeing frames\n",
      "2026-02-03 10:09:07,999 - multi_tracker.core.post_processing - DEBUG - Merging forward_84 with backward_6: 148/148 agreeing frames\n",
      "2026-02-03 10:09:08,015 - multi_tracker.core.post_processing - DEBUG - Merging forward_88 with backward_41: 143/143 agreeing frames\n",
      "2026-02-03 10:09:08,029 - multi_tracker.core.post_processing - DEBUG - Merging forward_55 with backward_70: 125/125 agreeing frames\n",
      "2026-02-03 10:09:08,041 - multi_tracker.core.post_processing - DEBUG - Merging forward_86 with backward_22: 122/150 agreeing frames\n",
      "2026-02-03 10:09:08,067 - multi_tracker.core.post_processing - DEBUG - Merging forward_14 with backward_25: 117/152 agreeing frames\n",
      "2026-02-03 10:09:08,084 - multi_tracker.core.post_processing - DEBUG - Merging forward_83 with backward_7: 117/124 agreeing frames\n",
      "2026-02-03 10:09:08,097 - multi_tracker.core.post_processing - DEBUG - Merging forward_7 with backward_72: 116/130 agreeing frames\n",
      "2026-02-03 10:09:08,111 - multi_tracker.core.post_processing - DEBUG - Merging forward_61 with backward_15: 109/111 agreeing frames\n",
      "2026-02-03 10:09:08,127 - multi_tracker.core.post_processing - DEBUG - Merging forward_18 with backward_35: 98/190 agreeing frames\n",
      "2026-02-03 10:09:08,156 - multi_tracker.core.post_processing - DEBUG - Merging forward_63 with backward_20: 98/118 agreeing frames\n",
      "2026-02-03 10:09:08,168 - multi_tracker.core.post_processing - DEBUG - Merging forward_54 with backward_59: 95/121 agreeing frames\n",
      "2026-02-03 10:09:08,188 - multi_tracker.core.post_processing - DEBUG - Merging forward_68 with backward_30: 91/102 agreeing frames\n",
      "2026-02-03 10:09:08,200 - multi_tracker.core.post_processing - DEBUG - Merging forward_2 with backward_51: 88/93 agreeing frames\n",
      "2026-02-03 10:09:08,209 - multi_tracker.core.post_processing - DEBUG - Merging forward_51 with backward_65: 85/95 agreeing frames\n",
      "2026-02-03 10:09:08,221 - multi_tracker.core.post_processing - DEBUG - Merging forward_90 with backward_5: 81/81 agreeing frames\n",
      "2026-02-03 10:09:08,229 - multi_tracker.core.post_processing - DEBUG - Merging forward_70 with backward_10: 80/80 agreeing frames\n",
      "2026-02-03 10:09:08,240 - multi_tracker.core.post_processing - DEBUG - Merging forward_72 with backward_19: 74/79 agreeing frames\n",
      "2026-02-03 10:09:08,251 - multi_tracker.core.post_processing - DEBUG - Merging forward_34 with backward_66: 73/74 agreeing frames\n",
      "2026-02-03 10:09:08,266 - multi_tracker.core.post_processing - DEBUG - Merging forward_47 with backward_78: 68/70 agreeing frames\n",
      "2026-02-03 10:09:08,277 - multi_tracker.core.post_processing - DEBUG - Merging forward_45 with backward_23: 62/62 agreeing frames\n",
      "2026-02-03 10:09:08,284 - multi_tracker.core.post_processing - DEBUG - Merging forward_43 with backward_87: 58/69 agreeing frames\n",
      "2026-02-03 10:09:08,294 - multi_tracker.core.post_processing - DEBUG - Merging forward_75 with backward_49: 54/55 agreeing frames\n",
      "2026-02-03 10:09:08,300 - multi_tracker.core.post_processing - DEBUG - Merging forward_38 with backward_89: 53/61 agreeing frames\n",
      "2026-02-03 10:09:08,309 - multi_tracker.core.post_processing - DEBUG - Merging forward_25 with backward_55: 52/72 agreeing frames\n",
      "2026-02-03 10:09:08,320 - multi_tracker.core.post_processing - DEBUG - Merging forward_59 with backward_84: 49/59 agreeing frames\n",
      "2026-02-03 10:09:08,338 - multi_tracker.core.post_processing - DEBUG - Merging forward_6 with backward_8: 47/80 agreeing frames\n",
      "2026-02-03 10:09:08,349 - multi_tracker.core.post_processing - DEBUG - Merging forward_50 with backward_77: 45/56 agreeing frames\n",
      "2026-02-03 10:09:08,361 - multi_tracker.core.post_processing - DEBUG - Merging forward_20 with backward_83: 41/54 agreeing frames\n",
      "2026-02-03 10:09:08,367 - multi_tracker.core.post_processing - DEBUG - Merging forward_56 with backward_69: 39/45 agreeing frames\n",
      "2026-02-03 10:09:08,375 - multi_tracker.core.post_processing - DEBUG - Merging forward_10 with backward_47: 36/37 agreeing frames\n",
      "2026-02-03 10:09:08,380 - multi_tracker.core.post_processing - DEBUG - Merging forward_96 with backward_2: 34/34 agreeing frames\n",
      "2026-02-03 10:09:08,385 - multi_tracker.core.post_processing - DEBUG - Merging forward_91 with backward_13: 31/34 agreeing frames\n",
      "2026-02-03 10:09:08,392 - multi_tracker.core.post_processing - DEBUG - Merging forward_98 with backward_0: 31/31 agreeing frames\n",
      "2026-02-03 10:09:08,396 - multi_tracker.core.post_processing - DEBUG - Merging forward_8 with backward_81: 29/29 agreeing frames\n",
      "2026-02-03 10:09:08,400 - multi_tracker.core.post_processing - DEBUG - Merging forward_87 with backward_61: 28/28 agreeing frames\n",
      "2026-02-03 10:09:08,403 - multi_tracker.core.post_processing - DEBUG - Merging forward_1 with backward_52: 27/37 agreeing frames\n",
      "2026-02-03 10:09:08,416 - multi_tracker.core.post_processing - DEBUG - Merging forward_26 with backward_88: 27/34 agreeing frames\n",
      "2026-02-03 10:09:08,423 - multi_tracker.core.post_processing - DEBUG - Merging forward_81 with backward_75: 27/27 agreeing frames\n",
      "2026-02-03 10:09:08,427 - multi_tracker.core.post_processing - DEBUG - Merging forward_79 with backward_18: 25/98 agreeing frames\n",
      "2026-02-03 10:09:08,447 - multi_tracker.core.post_processing - DEBUG - Merging forward_93 with backward_38: 17/19 agreeing frames\n",
      "2026-02-03 10:09:08,453 - multi_tracker.core.post_processing - DEBUG - Merging forward_0 with backward_57: 16/27 agreeing frames\n",
      "2026-02-03 10:09:08,458 - multi_tracker.core.post_processing - DEBUG - Merging forward_58 with backward_85: 15/23 agreeing frames\n",
      "2026-02-03 10:09:08,463 - multi_tracker.core.post_processing - DEBUG - Merging forward_41 with backward_29: 14/15 agreeing frames\n",
      "2026-02-03 10:09:08,470 - multi_tracker.core.post_processing - DEBUG - Merging forward_82 with backward_74: 13/13 agreeing frames\n",
      "2026-02-03 10:09:08,473 - multi_tracker.core.post_processing - DEBUG - Merging forward_100 with backward_3: 12/16 agreeing frames\n",
      "2026-02-03 10:09:08,475 - multi_tracker.core.post_processing - DEBUG - Merging forward_32 with backward_91: 11/11 agreeing frames\n",
      "2026-02-03 10:09:08,477 - multi_tracker.core.post_processing - DEBUG - Merging forward_16 with backward_82: 10/14 agreeing frames\n",
      "2026-02-03 10:09:08,483 - multi_tracker.core.post_processing - DEBUG - Merging forward_35 with backward_11: 10/10 agreeing frames\n",
      "2026-02-03 10:09:08,485 - multi_tracker.core.post_processing - DEBUG - Merging forward_92 with backward_17: 9/59 agreeing frames\n",
      "2026-02-03 10:09:08,494 - multi_tracker.core.post_processing - DEBUG - Merging forward_49 with backward_33: 8/8 agreeing frames\n",
      "2026-02-03 10:09:08,497 - multi_tracker.core.post_processing - DEBUG - Merging forward_101 with backward_4: 8/10 agreeing frames\n",
      "2026-02-03 10:09:08,499 - multi_tracker.core.post_processing - DEBUG - Merging forward_28 with backward_86: 6/18 agreeing frames\n",
      "2026-02-03 10:09:08,503 - multi_tracker.core.post_processing - DEBUG - Merging forward_48 with backward_54: 6/11 agreeing frames\n",
      "2026-02-03 10:09:08,506 - multi_tracker.core.post_processing - DEBUG - Merging forward_66 with backward_80: 5/5 agreeing frames\n",
      "2026-02-03 10:09:08,509 - multi_tracker.core.post_processing - DEBUG - Merging forward_94 with backward_27: 3/17 agreeing frames\n",
      "2026-02-03 10:09:08,585 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 104/109 (95.4%) frames agree\n",
      "2026-02-03 10:09:08,598 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/65 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,598 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 65/68 (95.6%) frames agree\n",
      "2026-02-03 10:09:08,600 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,613 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,616 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 111/111 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,616 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,617 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 45/45 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,618 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,621 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 43/43 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,640 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 100/126 (79.4%) frames agree\n",
      "2026-02-03 10:09:08,643 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 15/20 (75.0%) frames agree\n",
      "2026-02-03 10:09:08,644 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 85/85 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,645 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 54/54 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,645 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/56 (91.1%) frames agree\n",
      "2026-02-03 10:09:08,646 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/44 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,646 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,654 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 170/171 (99.4%) frames agree\n",
      "2026-02-03 10:09:08,659 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 37/39 (94.9%) frames agree\n",
      "2026-02-03 10:09:08,660 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,660 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,662 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 60/68 (88.2%) frames agree\n",
      "2026-02-03 10:09:08,662 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/24 (70.8%) frames agree\n",
      "2026-02-03 10:09:08,663 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:09:08,668 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 66/66 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,668 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 32/33 (97.0%) frames agree\n",
      "2026-02-03 10:09:08,669 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 73/91 (80.2%) frames agree\n",
      "2026-02-03 10:09:08,670 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 74/80 (92.5%) frames agree\n",
      "2026-02-03 10:09:08,671 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,676 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 36/38 (94.7%) frames agree\n",
      "2026-02-03 10:09:08,679 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,680 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/17 (76.5%) frames agree\n",
      "2026-02-03 10:09:08,682 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 95/95 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,685 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/61 (77.0%) frames agree\n",
      "2026-02-03 10:09:08,687 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 39/39 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,688 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 88/92 (95.7%) frames agree\n",
      "2026-02-03 10:09:08,689 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 47/50 (94.0%) frames agree\n",
      "2026-02-03 10:09:08,689 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 22/22 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,690 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,690 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/20 (80.0%) frames agree\n",
      "2026-02-03 10:09:08,691 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 9/10 (90.0%) frames agree\n",
      "2026-02-03 10:09:08,693 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 57/57 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,693 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 31/31 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,696 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 21/21 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,697 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 29/30 (96.7%) frames agree\n",
      "2026-02-03 10:09:08,697 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 50/52 (96.2%) frames agree\n",
      "2026-02-03 10:09:08,699 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 20/20 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,699 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,700 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 53/53 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,702 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 44/45 (97.8%) frames agree\n",
      "2026-02-03 10:09:08,703 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 51/52 (98.1%) frames agree\n",
      "2026-02-03 10:09:08,703 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 19/19 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,704 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,705 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/35 (97.1%) frames agree\n",
      "2026-02-03 10:09:08,706 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 35/35 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,707 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/27 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,707 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 17/17 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,707 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 34/34 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,708 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 13/13 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,709 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 24/34 (70.6%) frames agree\n",
      "2026-02-03 10:09:08,710 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 27/28 (96.4%) frames agree\n",
      "2026-02-03 10:09:08,710 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/15 (80.0%) frames agree\n",
      "2026-02-03 10:09:08,710 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 25/25 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,711 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 12/12 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,711 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/11 (90.9%) frames agree\n",
      "2026-02-03 10:09:08,712 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,712 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 16/16 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,713 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 18/18 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,713 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 10/10 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,714 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/13 (84.6%) frames agree\n",
      "2026-02-03 10:09:08,714 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 14/14 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,714 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,715 - multi_tracker.core.post_processing - DEBUG - Marking trajectory as redundant: 11/11 (100.0%) frames agree\n",
      "2026-02-03 10:09:08,715 - multi_tracker.core.post_processing - INFO - Removed 73 spatially redundant trajectories\n"
     ]
    }
   ],
   "source": [
    "# Test optimized post-processing with performance measurement\n",
    "import time\n",
    "import importlib\n",
    "from multi_tracker.core import post_processing\n",
    "importlib.reload(post_processing)\n",
    "\n",
    "# Check if Numba is available\n",
    "print(f\"Numba available: {post_processing.HAS_NUMBA}\")\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    \"AGREEMENT_DISTANCE\": 9.62,\n",
    "    \"MIN_OVERLAP_FRAMES\": 2,\n",
    "    \"MIN_TRAJECTORY_LENGTH\": 10\n",
    "}\n",
    "\n",
    "# Run performance test\n",
    "print(\"\\n--- Performance Test ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "resolved_trajectories_opt = post_processing.resolve_trajectories(\n",
    "    forward_prepared,\n",
    "    backward_prepared,\n",
    "    video_length=TOTAL_FRAMES,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nTotal time: {elapsed:.2f} seconds\")\n",
    "print(f\"Result: {len(resolved_trajectories_opt)} trajectories\")\n",
    "\n",
    "# Verify no jumps\n",
    "merged_df_opt = pd.concat(resolved_trajectories_opt, ignore_index=True)\n",
    "jump_count = 0\n",
    "for traj_id in merged_df_opt['TrajectoryID'].unique():\n",
    "    traj = merged_df_opt[merged_df_opt['TrajectoryID'] == traj_id].sort_values('FrameID')\n",
    "    for j in range(1, len(traj)):\n",
    "        prev, curr = traj.iloc[j-1], traj.iloc[j]\n",
    "        if int(curr['FrameID'] - prev['FrameID']) == 1:\n",
    "            if not pd.isna(prev['X']) and not pd.isna(curr['X']):\n",
    "                dist = np.sqrt((curr['X'] - prev['X'])**2 + (curr['Y'] - prev['Y'])**2)\n",
    "                if dist > 50:\n",
    "                    jump_count += 1\n",
    "\n",
    "print(f\"Trajectories with jumps >50px: {jump_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276bf80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-animal-tracker-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
