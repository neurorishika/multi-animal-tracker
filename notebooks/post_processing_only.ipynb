{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6072494a",
   "metadata": {},
   "source": [
    "# Post-Processing Only Notebook\n",
    "\n",
    "This notebook runs post-processing on already-tracked data without re-running tracking.\n",
    "It assumes **bidirectional (forward + backward) tracking** was enabled and the following files exist:\n",
    "\n",
    "- `*_forward.csv` - Raw forward tracking output\n",
    "- `*_backward.csv` - Raw backward tracking output\n",
    "\n",
    "The notebook will:\n",
    "1. Load forward and backward CSV files\n",
    "2. Apply post-processing (break trajectories at velocity/distance jumps)\n",
    "3. Merge forward and backward trajectories into consensus trajectories\n",
    "4. Apply interpolation\n",
    "5. Scale coordinates back to original video space\n",
    "6. Save the final merged output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e468fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add the src directory to path if running from notebooks folder\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import post-processing functions\n",
    "from multi_tracker.core.post_processing import (\n",
    "    interpolate_trajectories,\n",
    "    process_trajectories_from_csv,\n",
    "    resolve_trajectories,\n",
    ")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✓ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b072b8b",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your file paths and parameters here. You need to provide:\n",
    "1. Path to the forward tracking CSV\n",
    "2. Path to the backward tracking CSV\n",
    "3. Path to the original video file (to get total frame count and verify resize factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "badb93ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward CSV:  emi_short_tracking_forward.csv\n",
      "Backward CSV: emi_short_tracking_backward.csv\n",
      "Output CSV:   emi_short_tracking_final.csv\n",
      "Video file:   emi_short.mp4\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# FILE PATHS - UPDATE THESE!\n",
    "# ===================================================================\n",
    "\n",
    "# Base path to your tracking output CSV (without _forward/_backward suffix)\n",
    "# Example: if your files are \"video_forward.csv\" and \"video_backward.csv\",\n",
    "# set this to \"video.csv\"\n",
    "BASE_CSV_PATH = \"emi_short_tracking.csv\"\n",
    "\n",
    "# Path to the original video file (used to get total frame count)\n",
    "VIDEO_PATH = \"emi_short.mp4\"\n",
    "\n",
    "# Output path for final merged trajectories\n",
    "OUTPUT_CSV_PATH = None  # Will auto-generate as *_final.csv if None\n",
    "\n",
    "# ===================================================================\n",
    "# DERIVED PATHS (auto-generated)\n",
    "# ===================================================================\n",
    "base, ext = os.path.splitext(BASE_CSV_PATH)\n",
    "FORWARD_CSV_PATH = f\"{base}_forward{ext}\"\n",
    "BACKWARD_CSV_PATH = f\"{base}_backward{ext}\"\n",
    "\n",
    "if OUTPUT_CSV_PATH is None:\n",
    "    OUTPUT_CSV_PATH = f\"{base}_final{ext}\"\n",
    "\n",
    "print(f\"Forward CSV:  {FORWARD_CSV_PATH}\")\n",
    "print(f\"Backward CSV: {BACKWARD_CSV_PATH}\")\n",
    "print(f\"Output CSV:   {OUTPUT_CSV_PATH}\")\n",
    "print(f\"Video file:   {VIDEO_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a110d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters configured:\n",
      "  MIN_TRAJECTORY_LENGTH: 10\n",
      "  MAX_VELOCITY_BREAK: 77.0\n",
      "  MAX_OCCLUSION_GAP: 5\n",
      "  AGREEMENT_DISTANCE: 19.25\n",
      "  MIN_OVERLAP_FRAMES: 2\n",
      "\n",
      "Interpolation: linear (max_gap=5)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# POST-PROCESSING PARAMETERS\n",
    "# ===================================================================\n",
    "# These should match the values used during tracking, or adjust as needed\n",
    "\n",
    "# Resize factor used during tracking (1.0 = no resize)\n",
    "# This is needed to scale coordinates back to original video space\n",
    "RESIZE_FACTOR = 1.0\n",
    "\n",
    "# Reference body size in pixels (used for scaling thresholds)\n",
    "# This is the typical size of your tracked animal\n",
    "REFERENCE_BODY_SIZE = 77.0\n",
    "\n",
    "# Trajectory post-processing parameters\n",
    "params = {\n",
    "    # Minimum trajectory length (in frames) - shorter ones are removed\n",
    "    \"MIN_TRAJECTORY_LENGTH\": 10,\n",
    "    # Maximum velocity before breaking trajectory (pixels/frame)\n",
    "    # Jumps faster than this indicate tracking errors\n",
    "    # Note: MAX_DISTANCE_BREAK is now computed dynamically as MAX_VELOCITY_BREAK * frame_diff\n",
    "    \"MAX_VELOCITY_BREAK\": 1.0 * REFERENCE_BODY_SIZE * RESIZE_FACTOR,\n",
    "    # Maximum consecutive occluded frames before breaking trajectory\n",
    "    \"MAX_OCCLUSION_GAP\": 5,\n",
    "    # Conservative merge parameters for forward/backward trajectory resolution\n",
    "    # AGREEMENT_DISTANCE: Max distance (px) for frames to be considered \"agreeing\"\n",
    "    # Frames within this distance are merged; frames outside create separate trajectories\n",
    "    \"AGREEMENT_DISTANCE\": REFERENCE_BODY_SIZE * RESIZE_FACTOR * 0.25,\n",
    "    # MIN_OVERLAP_FRAMES: Minimum number of agreeing frames required to consider merging\n",
    "    \"MIN_OVERLAP_FRAMES\": 2,\n",
    "}\n",
    "\n",
    "# Interpolation settings\n",
    "INTERPOLATION_METHOD = \"linear\"  # Options: \"none\", \"linear\", \"cubic\", \"spline\"\n",
    "INTERPOLATION_MAX_GAP = 5  # Maximum gap size to interpolate (frames)\n",
    "\n",
    "print(\"Parameters configured:\")\n",
    "for k, v in params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nInterpolation: {INTERPOLATION_METHOD} (max_gap={INTERPOLATION_MAX_GAP})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db01bf19",
   "metadata": {},
   "source": [
    "## Validate Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a06a107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Forward CSV: emi_short_tracking_forward.csv\n",
      "✓ Backward CSV: emi_short_tracking_backward.csv\n",
      "✓ Video file: emi_short.mp4\n",
      "\n",
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "# Check that all required files exist\n",
    "files_to_check = [\n",
    "    (\"Forward CSV\", FORWARD_CSV_PATH),\n",
    "    (\"Backward CSV\", BACKWARD_CSV_PATH),\n",
    "    (\"Video file\", VIDEO_PATH),\n",
    "]\n",
    "\n",
    "all_ok = True\n",
    "for name, path in files_to_check:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"✓ {name}: {path}\")\n",
    "    else:\n",
    "        print(f\"✗ {name} NOT FOUND: {path}\")\n",
    "        all_ok = False\n",
    "\n",
    "if not all_ok:\n",
    "    raise FileNotFoundError(\n",
    "        \"One or more required files are missing. Please check the paths above.\"\n",
    "    )\n",
    "\n",
    "print(\"\\nAll files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b32aa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info:\n",
      "  Total frames: 750\n",
      "  FPS: 25.0\n",
      "  Resolution: 4512 x 4512\n",
      "  Duration: 30.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get total frame count from video\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Could not open video: {VIDEO_PATH}\")\n",
    "\n",
    "TOTAL_FRAMES = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "WIDTH = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "HEIGHT = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.release()\n",
    "\n",
    "print(f\"Video info:\")\n",
    "print(f\"  Total frames: {TOTAL_FRAMES}\")\n",
    "print(f\"  FPS: {FPS}\")\n",
    "print(f\"  Resolution: {WIDTH} x {HEIGHT}\")\n",
    "print(f\"  Duration: {TOTAL_FRAMES/FPS:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28826ca1",
   "metadata": {},
   "source": [
    "## Step 1: Load and Process Forward Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54bdc6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward raw trajectories:\n",
      "  Rows: 18750\n",
      "  Unique trajectories: 83\n",
      "  Columns: ['TrackID', 'TrajectoryID', 'Index', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "  Frame range: 1 - 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrackID</th>\n",
       "      <th>TrajectoryID</th>\n",
       "      <th>Index</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Theta</th>\n",
       "      <th>FrameID</th>\n",
       "      <th>State</th>\n",
       "      <th>DetectionConfidence</th>\n",
       "      <th>AssignmentConfidence</th>\n",
       "      <th>PositionUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrackID  TrajectoryID  Index   X   Y  Theta  FrameID     State  \\\n",
       "0        0             0      0 NaN NaN    NaN        1  occluded   \n",
       "1        1             1      0 NaN NaN    NaN        1  occluded   \n",
       "2        2             2      0 NaN NaN    NaN        1  occluded   \n",
       "3        3             3      0 NaN NaN    NaN        1  occluded   \n",
       "4        4             4      0 NaN NaN    NaN        1  occluded   \n",
       "\n",
       "   DetectionConfidence  AssignmentConfidence  PositionUncertainty  \n",
       "0                  0.0                   0.0            20.109999  \n",
       "1                  0.0                   0.0            20.109999  \n",
       "2                  0.0                   0.0            20.109999  \n",
       "3                  0.0                   0.0            20.109999  \n",
       "4                  0.0                   0.0            20.109999  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load forward CSV and preview\n",
    "forward_raw = pd.read_csv(FORWARD_CSV_PATH)\n",
    "print(f\"Forward raw trajectories:\")\n",
    "print(f\"  Rows: {len(forward_raw)}\")\n",
    "print(f\"  Unique trajectories: {forward_raw['TrajectoryID'].nunique()}\")\n",
    "print(f\"  Columns: {list(forward_raw.columns)}\")\n",
    "print(f\"  Frame range: {forward_raw['FrameID'].min()} - {forward_raw['FrameID'].max()}\")\n",
    "forward_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fabe1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 13:44:36,495 - multi_tracker.core.post_processing - INFO - Loaded 18750 rows from emi_short_tracking_forward.csv with columns: ['TrackID', 'TrajectoryID', 'Index', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 13:44:36,495 - multi_tracker.core.post_processing - INFO - Dropped columns: []\n",
      "2026-02-03 13:44:36,496 - multi_tracker.core.post_processing - INFO - Setting X, Y, Theta to NaN for 4802 occluded/lost detections\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forward trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 13:44:37,231 - multi_tracker.core.post_processing - INFO - Post-processing stats: {'original_count': 83, 'removed_short': 0, 'broken_velocity': 53, 'broken_occlusion': 153, 'broken_spatial_gap': 13, 'final_count': 131}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forward processing stats:\n",
      "  original_count: 83\n",
      "  removed_short: 0\n",
      "  broken_velocity: 53\n",
      "  broken_occlusion: 153\n",
      "  broken_spatial_gap: 13\n",
      "  final_count: 131\n",
      "\n",
      "Processed forward trajectories: 131\n"
     ]
    }
   ],
   "source": [
    "# Process forward trajectories\n",
    "print(\"Processing forward trajectories...\")\n",
    "forward_processed, forward_stats = process_trajectories_from_csv(\n",
    "    FORWARD_CSV_PATH, params\n",
    ")\n",
    "\n",
    "print(f\"\\nForward processing stats:\")\n",
    "for k, v in forward_stats.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "if forward_processed is not None and not forward_processed.empty:\n",
    "    print(\n",
    "        f\"\\nProcessed forward trajectories: {forward_processed['TrajectoryID'].nunique()}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"WARNING: No forward trajectories after processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08e38b",
   "metadata": {},
   "source": [
    "## Step 2: Load and Process Backward Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2915c1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward raw trajectories:\n",
      "  Rows: 18750\n",
      "  Unique trajectories: 102\n",
      "  Columns: ['TrackID', 'TrajectoryID', 'Index', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "  Frame range (before transform): 1 - 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrackID</th>\n",
       "      <th>TrajectoryID</th>\n",
       "      <th>Index</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Theta</th>\n",
       "      <th>FrameID</th>\n",
       "      <th>State</th>\n",
       "      <th>DetectionConfidence</th>\n",
       "      <th>AssignmentConfidence</th>\n",
       "      <th>PositionUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>occluded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.109999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrackID  TrajectoryID  Index   X   Y  Theta  FrameID     State  \\\n",
       "0        0             0      0 NaN NaN    NaN        1  occluded   \n",
       "1        1             1      0 NaN NaN    NaN        1  occluded   \n",
       "2        2             2      0 NaN NaN    NaN        1  occluded   \n",
       "3        3             3      0 NaN NaN    NaN        1  occluded   \n",
       "4        4             4      0 NaN NaN    NaN        1  occluded   \n",
       "\n",
       "   DetectionConfidence  AssignmentConfidence  PositionUncertainty  \n",
       "0                  0.0                   0.0            20.109999  \n",
       "1                  0.0                   0.0            20.109999  \n",
       "2                  0.0                   0.0            20.109999  \n",
       "3                  0.0                   0.0            20.109999  \n",
       "4                  0.0                   0.0            20.109999  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load backward CSV and preview\n",
    "backward_raw = pd.read_csv(BACKWARD_CSV_PATH)\n",
    "print(f\"Backward raw trajectories:\")\n",
    "print(f\"  Rows: {len(backward_raw)}\")\n",
    "print(f\"  Unique trajectories: {backward_raw['TrajectoryID'].nunique()}\")\n",
    "print(f\"  Columns: {list(backward_raw.columns)}\")\n",
    "print(\n",
    "    f\"  Frame range (before transform): {backward_raw['FrameID'].min()} - {backward_raw['FrameID'].max()}\"\n",
    ")\n",
    "backward_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4120bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 13:44:37,479 - multi_tracker.core.post_processing - INFO - Loaded 18750 rows from emi_short_tracking_backward.csv with columns: ['TrackID', 'TrajectoryID', 'Index', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "2026-02-03 13:44:37,480 - multi_tracker.core.post_processing - INFO - Dropped columns: []\n",
      "2026-02-03 13:44:37,480 - multi_tracker.core.post_processing - INFO - Setting X, Y, Theta to NaN for 4885 occluded/lost detections\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing backward trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 13:44:38,221 - multi_tracker.core.post_processing - INFO - Post-processing stats: {'original_count': 102, 'removed_short': 1, 'broken_velocity': 55, 'broken_occlusion': 144, 'broken_spatial_gap': 15, 'final_count': 134}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backward processing stats:\n",
      "  original_count: 102\n",
      "  removed_short: 1\n",
      "  broken_velocity: 55\n",
      "  broken_occlusion: 144\n",
      "  broken_spatial_gap: 15\n",
      "  final_count: 134\n",
      "\n",
      "Processed backward trajectories: 134\n"
     ]
    }
   ],
   "source": [
    "# Process backward trajectories\n",
    "print(\"Processing backward trajectories...\")\n",
    "backward_processed, backward_stats = process_trajectories_from_csv(\n",
    "    BACKWARD_CSV_PATH, params\n",
    ")\n",
    "\n",
    "print(f\"\\nBackward processing stats:\")\n",
    "for k, v in backward_stats.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "if backward_processed is not None and not backward_processed.empty:\n",
    "    print(\n",
    "        f\"\\nProcessed backward trajectories: {backward_processed['TrajectoryID'].nunique()}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"WARNING: No backward trajectories after processing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af43ccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "JUMP ANALYSIS IN RAW DATA (before any post-processing)\n",
      "============================================================\n",
      "\n",
      "Forward raw data: 95 large jumps (vel > 154.0 px/frame)\n",
      "Backward raw data: 100 large jumps (vel > 154.0 px/frame)\n",
      "\n",
      "Top 5 forward raw jumps:\n",
      "    TrajectoryID  FromFrame  ToFrame  FrameGap     Distance     Velocity\n",
      "91            78        708      709         1  4418.730700  4418.730700\n",
      "77            54        409      410         1  2650.672368  2650.672368\n",
      "81            60        493      494         1  2629.846573  2629.846573\n",
      "80            58        473      474         1  2626.634729  2626.634729\n",
      "79            57        447      448         1  2617.483715  2617.483715\n",
      "\n",
      "Top 5 backward raw jumps:\n",
      "    TrajectoryID  FromFrame  ToFrame  FrameGap     Distance     Velocity\n",
      "48            43         29       30         1  3825.281297  3825.281297\n",
      "46            42         26       27         1  3286.583180  3286.583180\n",
      "74            65        247      248         1  1291.410469  1291.410469\n",
      "79            67        273      274         1  1073.861257  1073.861257\n",
      "98            97        710      711         1   792.748384   792.748384\n",
      "\n",
      "If there are many jumps in raw data, the issue is in TRACKING, not post-processing!\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# DIAGNOSTIC: Check for jumps in RAW tracking data (before processing)\n",
    "# ===================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"JUMP ANALYSIS IN RAW DATA (before any post-processing)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "MAX_RAW_JUMP = REFERENCE_BODY_SIZE * RESIZE_FACTOR * 2  # 2x body size\n",
    "\n",
    "\n",
    "def analyze_raw_jumps(df, name, max_jump):\n",
    "    \"\"\"Analyze jumps in raw tracking data.\"\"\"\n",
    "    jumps = []\n",
    "    for traj_id in df[\"TrajectoryID\"].unique():\n",
    "        traj = df[df[\"TrajectoryID\"] == traj_id].sort_values(\"FrameID\")\n",
    "        if len(traj) < 2:\n",
    "            continue\n",
    "        for i in range(1, len(traj)):\n",
    "            prev = traj.iloc[i - 1]\n",
    "            curr = traj.iloc[i]\n",
    "            if pd.isna(prev[\"X\"]) or pd.isna(curr[\"X\"]):\n",
    "                continue\n",
    "            dist = np.sqrt((curr[\"X\"] - prev[\"X\"]) ** 2 + (curr[\"Y\"] - prev[\"Y\"]) ** 2)\n",
    "            frame_gap = curr[\"FrameID\"] - prev[\"FrameID\"]\n",
    "            velocity = dist / max(frame_gap, 1)\n",
    "            if velocity > max_jump:\n",
    "                jumps.append(\n",
    "                    {\n",
    "                        \"TrajectoryID\": traj_id,\n",
    "                        \"FromFrame\": int(prev[\"FrameID\"]),\n",
    "                        \"ToFrame\": int(curr[\"FrameID\"]),\n",
    "                        \"FrameGap\": frame_gap,\n",
    "                        \"Distance\": dist,\n",
    "                        \"Velocity\": velocity,\n",
    "                    }\n",
    "                )\n",
    "    return jumps\n",
    "\n",
    "\n",
    "forward_raw_jumps = analyze_raw_jumps(forward_raw, \"Forward\", MAX_RAW_JUMP)\n",
    "backward_raw_jumps = analyze_raw_jumps(backward_raw, \"Backward\", MAX_RAW_JUMP)\n",
    "\n",
    "print(\n",
    "    f\"\\nForward raw data: {len(forward_raw_jumps)} large jumps (vel > {MAX_RAW_JUMP:.1f} px/frame)\"\n",
    ")\n",
    "print(\n",
    "    f\"Backward raw data: {len(backward_raw_jumps)} large jumps (vel > {MAX_RAW_JUMP:.1f} px/frame)\"\n",
    ")\n",
    "\n",
    "if forward_raw_jumps:\n",
    "    print(f\"\\nTop 5 forward raw jumps:\")\n",
    "    fwd_jump_df = pd.DataFrame(forward_raw_jumps)\n",
    "    print(fwd_jump_df.nlargest(5, \"Velocity\").to_string())\n",
    "\n",
    "if backward_raw_jumps:\n",
    "    print(f\"\\nTop 5 backward raw jumps:\")\n",
    "    bwd_jump_df = pd.DataFrame(backward_raw_jumps)\n",
    "    print(bwd_jump_df.nlargest(5, \"Velocity\").to_string())\n",
    "\n",
    "print(\n",
    "    f\"\\nIf there are many jumps in raw data, the issue is in TRACKING, not post-processing!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7efb9",
   "metadata": {},
   "source": [
    "## Step 3: Merge Forward and Backward Trajectories (Conservative Strategy)\n",
    "\n",
    "This step resolves conflicts between forward and backward tracking using a **conservative consensus-based approach**:\n",
    "\n",
    "1. **Adjust backward data**: Frame numbers are flipped (they were stored in reverse), and theta is rotated by 180°\n",
    "2. **Find merge candidates**: Pairs must have at least `MIN_OVERLAP_FRAMES` frames where positions agree (within `AGREEMENT_DISTANCE`)\n",
    "3. **Conservative merge**: \n",
    "   - **Agreeing frames** (both exist within threshold): Merge into average position\n",
    "   - **Disagreeing frames** (both exist but too far apart): Split into separate trajectory segments\n",
    "   - **Unique frames** (only one direction has data): Keep as-is\n",
    "\n",
    "This prioritizes **identity confidence** over trajectory completeness - you may get more trajectory fragments, but each fragment has higher confidence in identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "566462de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward trajectories ready for merge: 131\n",
      "Backward trajectories ready for merge: 134\n"
     ]
    }
   ],
   "source": [
    "# Helper function to convert DataFrame to list of DataFrames (one per trajectory)\n",
    "\n",
    "\n",
    "def prepare_trajs_for_merge(trajs_df):\n",
    "    \"\"\"Convert a single DataFrame to a list of DataFrames (one per trajectory).\"\"\"\n",
    "    if trajs_df is None or trajs_df.empty:\n",
    "        return []\n",
    "    return [group.copy() for _, group in trajs_df.groupby(\"TrajectoryID\")]\n",
    "\n",
    "\n",
    "# Prepare trajectories for merging\n",
    "forward_prepared = prepare_trajs_for_merge(forward_processed)\n",
    "backward_prepared = prepare_trajs_for_merge(backward_processed)\n",
    "\n",
    "print(f\"Forward trajectories ready for merge: {len(forward_prepared)}\")\n",
    "print(f\"Backward trajectories ready for merge: {len(backward_prepared)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d65d19e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 13:44:58,607 - multi_tracker.core.post_processing - INFO - Starting conservative trajectory resolution with 131 forward and 134 backward trajectories\n",
      "2026-02-03 13:44:58,607 - multi_tracker.core.post_processing - INFO - Parameters: AGREEMENT_DISTANCE=19.25px, MIN_OVERLAP_FRAMES=2, MIN_LENGTH=10\n",
      "2026-02-03 13:44:58,720 - multi_tracker.core.post_processing - INFO - After cleaning: 131 forward, 134 backward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving forward and backward trajectories...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 13:44:58,966 - multi_tracker.core.post_processing - INFO - Found 333 merge candidates\n",
      "2026-02-03 13:45:00,379 - multi_tracker.core.post_processing - INFO - Removed 80 spatially redundant trajectories\n",
      "2026-02-03 13:45:12,211 - multi_tracker.core.post_processing - INFO - Processed overlapping trajectories in 5 iterations\n",
      "2026-02-03 13:45:12,236 - multi_tracker.core.post_processing - INFO - Final result: 191 trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Resolution complete! Got 191 merged trajectories.\n"
     ]
    }
   ],
   "source": [
    "# Resolve (merge) forward and backward trajectories\n",
    "print(\"Resolving forward and backward trajectories...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "resolved_trajectories = resolve_trajectories(\n",
    "    forward_prepared,\n",
    "    backward_prepared,\n",
    "    video_length=TOTAL_FRAMES,\n",
    "    params=params,\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nResolution complete! Got {len(resolved_trajectories)} merged trajectories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4928fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "  Rows: 13200\n",
      "  Unique trajectories: 191\n",
      "  Frame range: 1 - 750\n"
     ]
    }
   ],
   "source": [
    "# Convert list of DataFrames back to single DataFrame\n",
    "if resolved_trajectories and isinstance(resolved_trajectories, list):\n",
    "    if isinstance(resolved_trajectories[0], pd.DataFrame):\n",
    "        # Reassign TrajectoryID to ensure unique IDs\n",
    "        for new_id, traj_df in enumerate(resolved_trajectories):\n",
    "            traj_df[\"TrajectoryID\"] = new_id\n",
    "        merged_df = pd.concat(resolved_trajectories, ignore_index=True)\n",
    "    else:\n",
    "        # Fallback for old tuple format\n",
    "        all_data = []\n",
    "        for traj_id, traj in enumerate(resolved_trajectories):\n",
    "            for x, y, theta, frame in traj:\n",
    "                all_data.append(\n",
    "                    {\n",
    "                        \"TrajectoryID\": traj_id,\n",
    "                        \"X\": x,\n",
    "                        \"Y\": y,\n",
    "                        \"Theta\": theta,\n",
    "                        \"FrameID\": frame,\n",
    "                    }\n",
    "                )\n",
    "        merged_df = pd.DataFrame(all_data) if all_data else pd.DataFrame()\n",
    "else:\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "print(f\"Merged DataFrame:\")\n",
    "print(f\"  Rows: {len(merged_df)}\")\n",
    "print(\n",
    "    f\"  Unique trajectories: {merged_df['TrajectoryID'].nunique() if not merged_df.empty else 0}\"\n",
    ")\n",
    "if not merged_df.empty:\n",
    "    print(f\"  Frame range: {merged_df['FrameID'].min()} - {merged_df['FrameID'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01c9453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MERGED DATA JUMP ANALYSIS (threshold: 154.0 px/frame)\n",
      "======================================================================\n",
      "Total jumps exceeding threshold: 0\n",
      "✓ No significant jumps found in merged data!\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# DIAGNOSTIC: Check for jumps in merged data (after merge, before interpolation)\n",
    "# ===================================================================\n",
    "MAX_ALLOWED_JUMP = REFERENCE_BODY_SIZE * RESIZE_FACTOR * 2  # 2x body size threshold\n",
    "\n",
    "merged_jump_count = 0\n",
    "merged_jump_details = []\n",
    "\n",
    "for traj_id in sorted(merged_df[\"TrajectoryID\"].unique()):\n",
    "    traj_df = merged_df[merged_df[\"TrajectoryID\"] == traj_id].sort_values(\"FrameID\")\n",
    "\n",
    "    for i in range(1, len(traj_df)):\n",
    "        curr = traj_df.iloc[i]\n",
    "        prev = traj_df.iloc[i - 1]\n",
    "\n",
    "        # Skip if either position is NaN\n",
    "        if pd.isna(curr[\"X\"]) or pd.isna(prev[\"X\"]):\n",
    "            continue\n",
    "\n",
    "        frame_gap = curr[\"FrameID\"] - prev[\"FrameID\"]\n",
    "        distance = np.sqrt((curr[\"X\"] - prev[\"X\"]) ** 2 + (curr[\"Y\"] - prev[\"Y\"]) ** 2)\n",
    "\n",
    "        # Normalize distance by frame gap (distance per frame)\n",
    "        effective_jump = distance / frame_gap if frame_gap > 0 else distance\n",
    "\n",
    "        if effective_jump > MAX_ALLOWED_JUMP:\n",
    "            merged_jump_count += 1\n",
    "            merged_jump_details.append(\n",
    "                {\n",
    "                    \"TrajectoryID\": traj_id,\n",
    "                    \"FromFrame\": prev[\"FrameID\"],\n",
    "                    \"ToFrame\": curr[\"FrameID\"],\n",
    "                    \"FrameGap\": frame_gap,\n",
    "                    \"Distance\": distance,\n",
    "                    \"EffectiveJump\": effective_jump,\n",
    "                    \"FromPos\": (prev[\"X\"], prev[\"Y\"]),\n",
    "                    \"ToPos\": (curr[\"X\"], curr[\"Y\"]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"MERGED DATA JUMP ANALYSIS (threshold: {MAX_ALLOWED_JUMP:.1f} px/frame)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total jumps exceeding threshold: {merged_jump_count}\")\n",
    "\n",
    "if merged_jump_count > 0:\n",
    "    # Sort by effective jump distance\n",
    "    merged_jump_details.sort(key=lambda x: x[\"EffectiveJump\"], reverse=True)\n",
    "\n",
    "    print(f\"\\nTop 10 largest jumps:\")\n",
    "    for jump in merged_jump_details[:10]:\n",
    "        print(\n",
    "            f\"  Traj {jump['TrajectoryID']:3d}: Frame {jump['FromFrame']:5.0f}→{jump['ToFrame']:5.0f} \"\n",
    "            f\"(gap={jump['FrameGap']:2.0f}): {jump['EffectiveJump']:6.1f} px/frame \"\n",
    "            f\"({jump['Distance']:6.1f} px total)\"\n",
    "        )\n",
    "\n",
    "    # Count by trajectory\n",
    "    from collections import Counter\n",
    "\n",
    "    traj_counts = Counter([j[\"TrajectoryID\"] for j in merged_jump_details])\n",
    "    print(f\"\\nTrajectories with most jumps:\")\n",
    "    for traj_id, count in traj_counts.most_common(10):\n",
    "        print(f\"  Trajectory {traj_id}: {count} jumps\")\n",
    "else:\n",
    "    print(\"✓ No significant jumps found in merged data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee37014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HIDDEN JUMP ANALYSIS (spatial discontinuities across NaN gaps)\n",
      "======================================================================\n",
      "Threshold: 154.0 px/frame\n",
      "Hidden jumps found: 0\n",
      "✓ No hidden jumps found! Interpolation should not create new jumps.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# DIAGNOSTIC: Check for \"HIDDEN JUMPS\" - spatial discontinuities across NaN gaps\n",
    "# These will be revealed by interpolation!\n",
    "# ===================================================================\n",
    "MAX_ALLOWED_VELOCITY = REFERENCE_BODY_SIZE * RESIZE_FACTOR * 2  # 2x body size per frame\n",
    "\n",
    "hidden_jump_count = 0\n",
    "hidden_jump_details = []\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"HIDDEN JUMP ANALYSIS (spatial discontinuities across NaN gaps)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Threshold: {MAX_ALLOWED_VELOCITY:.1f} px/frame\")\n",
    "\n",
    "for traj_id in sorted(merged_df[\"TrajectoryID\"].unique()):\n",
    "    traj_df = (\n",
    "        merged_df[merged_df[\"TrajectoryID\"] == traj_id]\n",
    "        .sort_values(\"FrameID\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Find all valid (non-NaN) positions\n",
    "    valid_positions = traj_df[traj_df[\"X\"].notna()].copy()\n",
    "\n",
    "    if len(valid_positions) < 2:\n",
    "        continue\n",
    "\n",
    "    # Check jumps between consecutive valid positions (skipping NaN gaps)\n",
    "    for i in range(1, len(valid_positions)):\n",
    "        curr = valid_positions.iloc[i]\n",
    "        prev = valid_positions.iloc[i - 1]\n",
    "\n",
    "        frame_gap = curr[\"FrameID\"] - prev[\"FrameID\"]\n",
    "\n",
    "        # Only check if there's a gap (frame_gap > 1 means there were NaN frames between)\n",
    "        if frame_gap > 1:\n",
    "            distance = np.sqrt(\n",
    "                (curr[\"X\"] - prev[\"X\"]) ** 2 + (curr[\"Y\"] - prev[\"Y\"]) ** 2\n",
    "            )\n",
    "            velocity = distance / frame_gap  # Average velocity across gap\n",
    "\n",
    "            if velocity > MAX_ALLOWED_VELOCITY:\n",
    "                hidden_jump_count += 1\n",
    "                hidden_jump_details.append(\n",
    "                    {\n",
    "                        \"TrajectoryID\": traj_id,\n",
    "                        \"FromFrame\": prev[\"FrameID\"],\n",
    "                        \"ToFrame\": curr[\"FrameID\"],\n",
    "                        \"FrameGap\": frame_gap,\n",
    "                        \"Distance\": distance,\n",
    "                        \"Velocity\": velocity,\n",
    "                        \"FromPos\": (prev[\"X\"], prev[\"Y\"]),\n",
    "                        \"ToPos\": (curr[\"X\"], curr[\"Y\"]),\n",
    "                        \"NaNFrames\": frame_gap - 1,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "print(f\"Hidden jumps found: {hidden_jump_count}\")\n",
    "\n",
    "if hidden_jump_count > 0:\n",
    "    # Sort by velocity\n",
    "    hidden_jump_details.sort(key=lambda x: x[\"Velocity\"], reverse=True)\n",
    "\n",
    "    print(f\"\\nTop 10 largest hidden jumps:\")\n",
    "    for jump in hidden_jump_details[:10]:\n",
    "        print(\n",
    "            f\"  Traj {jump['TrajectoryID']:3d}: Frame {jump['FromFrame']:5.0f}→{jump['ToFrame']:5.0f} \"\n",
    "            f\"(gap={jump['FrameGap']:2.0f}, NaN={jump['NaNFrames']:2.0f}): \"\n",
    "            f\"{jump['Velocity']:6.1f} px/frame ({jump['Distance']:6.1f} px total)\"\n",
    "        )\n",
    "\n",
    "    # Count by trajectory\n",
    "    from collections import Counter\n",
    "\n",
    "    traj_counts_hidden = Counter([j[\"TrajectoryID\"] for j in hidden_jump_details])\n",
    "    print(f\"\\nTrajectories with most hidden jumps:\")\n",
    "    for traj_id, count in traj_counts_hidden.most_common(10):\n",
    "        print(f\"  Trajectory {traj_id}: {count} hidden jumps\")\n",
    "\n",
    "    print(f\"\\n⚠️  These hidden jumps will be REVEALED by interpolation!\")\n",
    "    print(\n",
    "        f\"    Interpolation will create {sum(j['NaNFrames'] for j in hidden_jump_details)} new frames\"\n",
    "    )\n",
    "    print(\n",
    "        f\"    across these gaps, making the jumps visible as consecutive-frame velocity.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"✓ No hidden jumps found! Interpolation should not create new jumps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc32d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "JUMP ANALYSIS (before interpolation)\n",
      "============================================================\n",
      "Max allowed jump threshold: 154.0 px\n",
      "\n",
      "Found 0 large jumps (velocity > 154.0 px/frame)\n",
      "No large jumps found!\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# DIAGNOSTIC: Analyze jumps in merged data BEFORE interpolation\n",
    "# ===================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"JUMP ANALYSIS (before interpolation)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate jumps for each trajectory\n",
    "MAX_ALLOWED_JUMP = REFERENCE_BODY_SIZE * RESIZE_FACTOR * 2  # 2x body size\n",
    "print(f\"Max allowed jump threshold: {MAX_ALLOWED_JUMP:.1f} px\")\n",
    "\n",
    "jump_analysis = []\n",
    "for traj_id in merged_df[\"TrajectoryID\"].unique():\n",
    "    traj = merged_df[merged_df[\"TrajectoryID\"] == traj_id].sort_values(\"FrameID\")\n",
    "\n",
    "    if len(traj) < 2:\n",
    "        continue\n",
    "\n",
    "    # Calculate frame-to-frame jumps\n",
    "    for i in range(1, len(traj)):\n",
    "        prev = traj.iloc[i - 1]\n",
    "        curr = traj.iloc[i]\n",
    "\n",
    "        # Skip if either position is NaN\n",
    "        if pd.isna(prev[\"X\"]) or pd.isna(curr[\"X\"]):\n",
    "            continue\n",
    "\n",
    "        dx = curr[\"X\"] - prev[\"X\"]\n",
    "        dy = curr[\"Y\"] - prev[\"Y\"]\n",
    "        dist = np.sqrt(dx**2 + dy**2)\n",
    "        frame_gap = curr[\"FrameID\"] - prev[\"FrameID\"]\n",
    "\n",
    "        # Normalize by frame gap (for multi-frame gaps)\n",
    "        velocity = dist / max(frame_gap, 1)\n",
    "\n",
    "        if velocity > MAX_ALLOWED_JUMP:\n",
    "            jump_analysis.append(\n",
    "                {\n",
    "                    \"TrajectoryID\": traj_id,\n",
    "                    \"FromFrame\": int(prev[\"FrameID\"]),\n",
    "                    \"ToFrame\": int(curr[\"FrameID\"]),\n",
    "                    \"FrameGap\": frame_gap,\n",
    "                    \"Distance\": dist,\n",
    "                    \"Velocity\": velocity,\n",
    "                    \"FromX\": prev[\"X\"],\n",
    "                    \"FromY\": prev[\"Y\"],\n",
    "                    \"ToX\": curr[\"X\"],\n",
    "                    \"ToY\": curr[\"Y\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "print(\n",
    "    f\"\\nFound {len(jump_analysis)} large jumps (velocity > {MAX_ALLOWED_JUMP:.1f} px/frame)\"\n",
    ")\n",
    "\n",
    "if jump_analysis:\n",
    "    jump_df = pd.DataFrame(jump_analysis)\n",
    "    print(f\"\\nTop 10 largest jumps:\")\n",
    "    print(\n",
    "        jump_df.nlargest(10, \"Velocity\")[\n",
    "            [\"TrajectoryID\", \"FromFrame\", \"ToFrame\", \"FrameGap\", \"Distance\", \"Velocity\"]\n",
    "        ].to_string()\n",
    "    )\n",
    "\n",
    "    # Which trajectories have the most jumps?\n",
    "    print(f\"\\nTrajectories with most jumps:\")\n",
    "    print(jump_df.groupby(\"TrajectoryID\").size().nlargest(10).to_string())\n",
    "else:\n",
    "    print(\"No large jumps found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c35a2",
   "metadata": {},
   "source": [
    "## Step 4: Apply Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eab9f7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 13:49:37,461 - multi_tracker.core.post_processing - INFO - Interpolating trajectories using linear method (max_gap=5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying linear interpolation (max_gap=5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 13:49:37,769 - multi_tracker.core.post_processing - INFO - Interpolation complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation complete!\n",
      "  NaN values before: 1368\n",
      "  NaN values after: 0\n",
      "  Filled: 1368 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Apply interpolation if enabled\n",
    "if INTERPOLATION_METHOD.lower() != \"none\" and not merged_df.empty:\n",
    "    print(\n",
    "        f\"Applying {INTERPOLATION_METHOD} interpolation (max_gap={INTERPOLATION_MAX_GAP})...\"\n",
    "    )\n",
    "\n",
    "    # Count NaN values before\n",
    "    nan_before = merged_df[[\"X\", \"Y\"]].isna().sum().sum()\n",
    "\n",
    "    merged_df = interpolate_trajectories(\n",
    "        merged_df,\n",
    "        method=INTERPOLATION_METHOD,\n",
    "        max_gap=INTERPOLATION_MAX_GAP,\n",
    "    )\n",
    "\n",
    "    # Count NaN values after\n",
    "    nan_after = merged_df[[\"X\", \"Y\"]].isna().sum().sum()\n",
    "\n",
    "    print(f\"Interpolation complete!\")\n",
    "    print(f\"  NaN values before: {nan_before}\")\n",
    "    print(f\"  NaN values after: {nan_after}\")\n",
    "    print(\n",
    "        f\"  Filled: {nan_before - nan_after} ({100*(nan_before-nan_after)/max(nan_before,1):.1f}%)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping interpolation (disabled or no data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479d9361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "POST-INTERPOLATION JUMP ANALYSIS (threshold: 154.0 px/frame)\n",
      "======================================================================\n",
      "Total jumps exceeding threshold: 0\n",
      "✓ No significant jumps found after interpolation!\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# DIAGNOSTIC: Check for jumps AFTER interpolation (before scaling)\n",
    "# ===================================================================\n",
    "MAX_ALLOWED_JUMP_POST_INTERP = (\n",
    "    REFERENCE_BODY_SIZE * RESIZE_FACTOR * 2\n",
    ")  # 2x body size threshold\n",
    "\n",
    "post_interp_jump_count = 0\n",
    "post_interp_jump_details = []\n",
    "\n",
    "for traj_id in sorted(merged_df[\"TrajectoryID\"].unique()):\n",
    "    traj_df = merged_df[merged_df[\"TrajectoryID\"] == traj_id].sort_values(\"FrameID\")\n",
    "\n",
    "    for i in range(1, len(traj_df)):\n",
    "        curr = traj_df.iloc[i]\n",
    "        prev = traj_df.iloc[i - 1]\n",
    "\n",
    "        # Skip if either position is NaN (though there should be fewer after interpolation)\n",
    "        if pd.isna(curr[\"X\"]) or pd.isna(prev[\"X\"]):\n",
    "            continue\n",
    "\n",
    "        frame_gap = curr[\"FrameID\"] - prev[\"FrameID\"]\n",
    "        distance = np.sqrt((curr[\"X\"] - prev[\"X\"]) ** 2 + (curr[\"Y\"] - prev[\"Y\"]) ** 2)\n",
    "\n",
    "        # For consecutive frames (frame_gap=1), check if distance exceeds threshold\n",
    "        # For non-consecutive frames, normalize by gap\n",
    "        if frame_gap == 1:\n",
    "            velocity = distance  # px/frame\n",
    "        else:\n",
    "            velocity = distance / frame_gap  # px/frame (normalized)\n",
    "\n",
    "        if velocity > MAX_ALLOWED_JUMP_POST_INTERP:\n",
    "            post_interp_jump_count += 1\n",
    "            post_interp_jump_details.append(\n",
    "                {\n",
    "                    \"TrajectoryID\": traj_id,\n",
    "                    \"FromFrame\": prev[\"FrameID\"],\n",
    "                    \"ToFrame\": curr[\"FrameID\"],\n",
    "                    \"FrameGap\": frame_gap,\n",
    "                    \"Distance\": distance,\n",
    "                    \"Velocity\": velocity,\n",
    "                    \"FromPos\": (prev[\"X\"], prev[\"Y\"]),\n",
    "                    \"ToPos\": (curr[\"X\"], curr[\"Y\"]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\n",
    "    f\"POST-INTERPOLATION JUMP ANALYSIS (threshold: {MAX_ALLOWED_JUMP_POST_INTERP:.1f} px/frame)\"\n",
    ")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total jumps exceeding threshold: {post_interp_jump_count}\")\n",
    "\n",
    "if post_interp_jump_count > 0:\n",
    "    # Sort by velocity\n",
    "    post_interp_jump_details.sort(key=lambda x: x[\"Velocity\"], reverse=True)\n",
    "\n",
    "    print(f\"\\nTop 10 largest jumps (after interpolation):\")\n",
    "    for jump in post_interp_jump_details[:10]:\n",
    "        print(\n",
    "            f\"  Traj {jump['TrajectoryID']:3d}: Frame {jump['FromFrame']:5.0f}→{jump['ToFrame']:5.0f} \"\n",
    "            f\"(gap={jump['FrameGap']:2.0f}): {jump['Velocity']:6.1f} px/frame \"\n",
    "            f\"({jump['Distance']:6.1f} px total)\"\n",
    "        )\n",
    "\n",
    "    # Count by trajectory\n",
    "    from collections import Counter\n",
    "\n",
    "    traj_counts_post = Counter([j[\"TrajectoryID\"] for j in post_interp_jump_details])\n",
    "    print(f\"\\nTrajectories with most jumps (after interpolation):\")\n",
    "    for traj_id, count in traj_counts_post.most_common(10):\n",
    "        print(f\"  Trajectory {traj_id}: {count} jumps\")\n",
    "\n",
    "    # Compare with pre-interpolation\n",
    "    if merged_jump_count > 0:\n",
    "        reduction = (\n",
    "            (merged_jump_count - post_interp_jump_count) / merged_jump_count\n",
    "        ) * 100\n",
    "        print(\n",
    "            f\"\\nJump reduction from interpolation: {merged_jump_count} → {post_interp_jump_count} \"\n",
    "            f\"({reduction:+.1f}% change)\"\n",
    "        )\n",
    "else:\n",
    "    print(\"✓ No significant jumps found after interpolation!\")\n",
    "    if merged_jump_count > 0:\n",
    "        print(f\"  Interpolation successfully eliminated all {merged_jump_count} jumps!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb83947",
   "metadata": {},
   "source": [
    "## Step 5: Scale to Original Video Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b19ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No scaling needed (resize_factor=1.0)\n"
     ]
    }
   ],
   "source": [
    "# Scale coordinates back to original video space\n",
    "if RESIZE_FACTOR != 1.0 and not merged_df.empty:\n",
    "    print(\n",
    "        f\"Scaling coordinates from resized space (factor={RESIZE_FACTOR}) to original space...\"\n",
    "    )\n",
    "\n",
    "    merged_df[[\"X\", \"Y\"]] = merged_df[[\"X\", \"Y\"]] / RESIZE_FACTOR\n",
    "\n",
    "    if \"Width\" in merged_df.columns:\n",
    "        merged_df[\"Width\"] /= RESIZE_FACTOR\n",
    "    if \"Height\" in merged_df.columns:\n",
    "        merged_df[\"Height\"] /= RESIZE_FACTOR\n",
    "\n",
    "    print(\"✓ Coordinates scaled to original video space\")\n",
    "else:\n",
    "    print(\"No scaling needed (resize_factor=1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eed287",
   "metadata": {},
   "source": [
    "## Step 6: Save Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a8758fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged trajectories:\n",
      "  Rows: 13734\n",
      "  Unique trajectories: 191\n",
      "  Columns: ['TrajectoryID', 'X', 'Y', 'Theta', 'FrameID', 'State', 'DetectionConfidence', 'AssignmentConfidence', 'PositionUncertainty']\n",
      "  Frame range: 1 - 750\n",
      "  X range: 456.0 - 4046.0\n",
      "  Y range: 328.0 - 3862.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrajectoryID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Theta</th>\n",
       "      <th>FrameID</th>\n",
       "      <th>State</th>\n",
       "      <th>DetectionConfidence</th>\n",
       "      <th>AssignmentConfidence</th>\n",
       "      <th>PositionUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>3.604497</td>\n",
       "      <td>19</td>\n",
       "      <td>active</td>\n",
       "      <td>0.960815</td>\n",
       "      <td>0.972963</td>\n",
       "      <td>0.558720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>3.305332</td>\n",
       "      <td>20</td>\n",
       "      <td>active</td>\n",
       "      <td>0.974500</td>\n",
       "      <td>0.853365</td>\n",
       "      <td>0.575555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>3.207548</td>\n",
       "      <td>21</td>\n",
       "      <td>active</td>\n",
       "      <td>0.977804</td>\n",
       "      <td>0.809330</td>\n",
       "      <td>0.588500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>2.936751</td>\n",
       "      <td>22</td>\n",
       "      <td>active</td>\n",
       "      <td>0.956972</td>\n",
       "      <td>0.749061</td>\n",
       "      <td>0.593665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>3.036397</td>\n",
       "      <td>23</td>\n",
       "      <td>active</td>\n",
       "      <td>0.956708</td>\n",
       "      <td>0.804415</td>\n",
       "      <td>0.567792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>3.090848</td>\n",
       "      <td>24</td>\n",
       "      <td>active</td>\n",
       "      <td>0.937172</td>\n",
       "      <td>0.817859</td>\n",
       "      <td>0.609486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>3.250555</td>\n",
       "      <td>25</td>\n",
       "      <td>active</td>\n",
       "      <td>0.950802</td>\n",
       "      <td>0.511432</td>\n",
       "      <td>1.533771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>646.5</td>\n",
       "      <td>393.5</td>\n",
       "      <td>3.121234</td>\n",
       "      <td>26</td>\n",
       "      <td>occluded</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>2.991913</td>\n",
       "      <td>27</td>\n",
       "      <td>active</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.828887</td>\n",
       "      <td>0.575455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>2.992872</td>\n",
       "      <td>28</td>\n",
       "      <td>active</td>\n",
       "      <td>0.916430</td>\n",
       "      <td>0.538257</td>\n",
       "      <td>0.577364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrajectoryID      X      Y     Theta  FrameID     State  \\\n",
       "0             0  732.0  398.0  3.604497       19    active   \n",
       "1             0  718.0  401.0  3.305332       20    active   \n",
       "2             0  712.0  405.0  3.207548       21    active   \n",
       "3             0  695.0  409.0  2.936751       22    active   \n",
       "4             0  676.0  412.0  3.036397       23    active   \n",
       "5             0  665.0  413.0  3.090848       24    active   \n",
       "6             0  657.0  413.0  3.250555       25    active   \n",
       "7             0  646.5  393.5  3.121234       26  occluded   \n",
       "8             0  636.0  374.0  2.991913       27    active   \n",
       "9             0  645.0  370.0  2.992872       28    active   \n",
       "\n",
       "   DetectionConfidence  AssignmentConfidence  PositionUncertainty  \n",
       "0             0.960815              0.972963             0.558720  \n",
       "1             0.974500              0.853365             0.575555  \n",
       "2             0.977804              0.809330             0.588500  \n",
       "3             0.956972              0.749061             0.593665  \n",
       "4             0.956708              0.804415             0.567792  \n",
       "5             0.937172              0.817859             0.609486  \n",
       "6             0.950802              0.511432             1.533771  \n",
       "7                  NaN                   NaN                  NaN  \n",
       "8             0.837836              0.828887             0.575455  \n",
       "9             0.916430              0.538257             0.577364  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview final data\n",
    "print(\"Final merged trajectories:\")\n",
    "print(f\"  Rows: {len(merged_df)}\")\n",
    "print(f\"  Unique trajectories: {merged_df['TrajectoryID'].nunique()}\")\n",
    "print(f\"  Columns: {list(merged_df.columns)}\")\n",
    "\n",
    "if not merged_df.empty:\n",
    "    print(f\"  Frame range: {merged_df['FrameID'].min()} - {merged_df['FrameID'].max()}\")\n",
    "    print(f\"  X range: {merged_df['X'].min():.1f} - {merged_df['X'].max():.1f}\")\n",
    "    print(f\"  Y range: {merged_df['Y'].min():.1f} - {merged_df['Y'].max():.1f}\")\n",
    "\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "937eb301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Final trajectories saved to: emi_short_tracking_final.csv\n",
      "  File size: 1226.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "if not merged_df.empty:\n",
    "    merged_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "    print(f\"✓ Final trajectories saved to: {OUTPUT_CSV_PATH}\")\n",
    "    print(f\"  File size: {os.path.getsize(OUTPUT_CSV_PATH) / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"WARNING: No data to save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc2f78",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beb612de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "POST-PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "📁 Input files:\n",
      "   Forward:  83 trajectories\n",
      "   Backward: 102 trajectories\n",
      "\n",
      "🔧 After individual post-processing:\n",
      "   Forward:  131 trajectories\n",
      "   Backward: 134 trajectories\n",
      "\n",
      "🔀 After merging:\n",
      "   Final: 191 trajectories\n",
      "\n",
      "💾 Output saved to:\n",
      "   emi_short_tracking_final.csv\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(\"=\" * 60)\n",
    "print(\"POST-PROCESSING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n📁 Input files:\")\n",
    "print(f\"   Forward:  {forward_raw['TrajectoryID'].nunique()} trajectories\")\n",
    "print(f\"   Backward: {backward_raw['TrajectoryID'].nunique()} trajectories\")\n",
    "\n",
    "print(f\"\\n🔧 After individual post-processing:\")\n",
    "print(f\"   Forward:  {forward_stats.get('final_count', 0)} trajectories\")\n",
    "print(f\"   Backward: {backward_stats.get('final_count', 0)} trajectories\")\n",
    "\n",
    "print(f\"\\n🔀 After merging:\")\n",
    "print(f\"   Final: {merged_df['TrajectoryID'].nunique()} trajectories\")\n",
    "\n",
    "print(f\"\\n💾 Output saved to:\")\n",
    "print(f\"   {OUTPUT_CSV_PATH}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4636ad",
   "metadata": {},
   "source": [
    "## Optional: Generate Annotated Video\n",
    "\n",
    "Generate a video with trajectory overlays similar to the main tracker output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "571d05b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video output: emi_short_annotated.mp4\n",
      "Options: labels=True, orientation=True, trails=True\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# VIDEO OUTPUT SETTINGS\n",
    "# ===================================================================\n",
    "\n",
    "# Generate video?\n",
    "GENERATE_VIDEO = True\n",
    "\n",
    "# Output video path (auto-generated if None)\n",
    "VIDEO_OUTPUT_PATH = None  # Will be *_annotated.mp4 if None\n",
    "\n",
    "# Visualization options\n",
    "SHOW_LABELS = True  # Show trajectory ID labels\n",
    "SHOW_ORIENTATION = True  # Show orientation arrows\n",
    "SHOW_TRAILS = True  # Show trajectory trails\n",
    "TRAIL_DURATION_SEC = 5.0  # Trail duration in seconds\n",
    "\n",
    "# Drawing parameters (relative to body size)\n",
    "MARKER_SIZE = 0.1  # Circle radius as fraction of body size\n",
    "ARROW_LENGTH = 0.25  # Arrow length as fraction of body size\n",
    "TEXT_SCALE = 3.0  # Text size scale factor\n",
    "\n",
    "# Auto-generate output path\n",
    "if VIDEO_OUTPUT_PATH is None:\n",
    "    base_video, ext_video = os.path.splitext(VIDEO_PATH)\n",
    "    VIDEO_OUTPUT_PATH = f\"{base_video}_annotated.mp4\"\n",
    "\n",
    "print(f\"Video output: {VIDEO_OUTPUT_PATH}\")\n",
    "print(\n",
    "    f\"Options: labels={SHOW_LABELS}, orientation={SHOW_ORIENTATION}, trails={SHOW_TRAILS}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09e4040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video generation function defined.\n"
     ]
    }
   ],
   "source": [
    "def generate_annotated_video(\n",
    "    video_path,\n",
    "    output_path,\n",
    "    trajectories_df,\n",
    "    reference_body_size=77.0,\n",
    "    show_labels=True,\n",
    "    show_orientation=True,\n",
    "    show_trails=True,\n",
    "    trail_duration_sec=2.0,\n",
    "    marker_size=0.1,\n",
    "    arrow_length=0.25,\n",
    "    text_scale=3.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate annotated video with trajectory overlays.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "        output_path: Path to output video\n",
    "        trajectories_df: DataFrame with columns TrajectoryID, FrameID, X, Y, Theta\n",
    "        reference_body_size: Reference body size in pixels for scaling\n",
    "        show_labels: Show trajectory ID labels\n",
    "        show_orientation: Show orientation arrows\n",
    "        show_trails: Show trajectory trails\n",
    "        trail_duration_sec: Duration of trails in seconds\n",
    "        marker_size: Circle radius as fraction of body size\n",
    "        arrow_length: Arrow length as fraction of body size\n",
    "        text_scale: Text size scale factor\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video: {video_path}\")\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(\n",
    "        f\"Input video: {frame_width}x{frame_height} @ {fps:.1f} FPS, {total_frames} frames\"\n",
    "    )\n",
    "\n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    if not out.isOpened():\n",
    "        cap.release()\n",
    "        raise ValueError(f\"Could not create output video: {output_path}\")\n",
    "\n",
    "    # Calculate trail duration in frames\n",
    "    trail_duration_frames = int(trail_duration_sec * fps)\n",
    "\n",
    "    # Scale drawing parameters by body size\n",
    "    marker_radius = int(marker_size * reference_body_size)\n",
    "    arrow_len = int(arrow_length * reference_body_size)\n",
    "    text_size = 0.5 * text_scale\n",
    "    marker_thickness = max(2, int(0.15 * reference_body_size))\n",
    "\n",
    "    # Default colors (BGR format for OpenCV)\n",
    "    default_colors = [\n",
    "        (0, 255, 0),  # Green\n",
    "        (255, 0, 0),  # Blue\n",
    "        (0, 0, 255),  # Red\n",
    "        (255, 255, 0),  # Cyan\n",
    "        (255, 0, 255),  # Magenta\n",
    "        (0, 255, 255),  # Yellow\n",
    "        (128, 0, 255),  # Orange\n",
    "        (255, 128, 0),  # Light blue\n",
    "        (0, 128, 255),  # Orange-red\n",
    "        (128, 255, 0),  # Lime\n",
    "    ]\n",
    "\n",
    "    # Build lookup for trajectories by frame\n",
    "    print(\"Building trajectory lookup...\")\n",
    "    traj_by_frame = {}\n",
    "    traj_by_track = {}\n",
    "\n",
    "    for _, row in trajectories_df.iterrows():\n",
    "        frame_num = int(row[\"FrameID\"])\n",
    "        track_id = int(row[\"TrajectoryID\"])\n",
    "\n",
    "        if frame_num not in traj_by_frame:\n",
    "            traj_by_frame[frame_num] = []\n",
    "        traj_by_frame[frame_num].append(row)\n",
    "\n",
    "        if track_id not in traj_by_track:\n",
    "            traj_by_track[track_id] = []\n",
    "        traj_by_track[track_id].append(row)\n",
    "\n",
    "    # Process video frame by frame\n",
    "    print(f\"Generating video: {output_path}\")\n",
    "\n",
    "    for frame_idx in tqdm(range(total_frames), desc=\"Processing frames\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Get trajectories for this frame\n",
    "        frame_trajs = traj_by_frame.get(frame_idx, [])\n",
    "\n",
    "        # Draw trails first (underneath current positions)\n",
    "        if show_trails:\n",
    "            for traj in frame_trajs:\n",
    "                track_id = int(traj[\"TrajectoryID\"])\n",
    "                color = default_colors[track_id % len(default_colors)]\n",
    "\n",
    "                # Get trail points (past N frames)\n",
    "                trail_points = []\n",
    "                if track_id in traj_by_track:\n",
    "                    for past_row in traj_by_track[track_id]:\n",
    "                        past_frame = int(past_row[\"FrameID\"])\n",
    "                        if frame_idx - trail_duration_frames <= past_frame < frame_idx:\n",
    "                            px, py = past_row[\"X\"], past_row[\"Y\"]\n",
    "                            if not pd.isna(px) and not pd.isna(py):\n",
    "                                trail_points.append((int(px), int(py), past_frame))\n",
    "\n",
    "                # Draw trail as fading line segments\n",
    "                if len(trail_points) > 1:\n",
    "                    trail_points.sort(key=lambda p: p[2])\n",
    "                    for i in range(len(trail_points) - 1):\n",
    "                        pt1 = (trail_points[i][0], trail_points[i][1])\n",
    "                        pt2 = (trail_points[i + 1][0], trail_points[i + 1][1])\n",
    "\n",
    "                        # Calculate opacity based on age\n",
    "                        age = frame_idx - trail_points[i][2]\n",
    "                        alpha = 1.0 - (age / trail_duration_frames)\n",
    "                        faded_color = tuple(int(c * alpha) for c in color)\n",
    "\n",
    "                        cv2.line(\n",
    "                            frame, pt1, pt2, faded_color, max(1, marker_thickness // 2)\n",
    "                        )\n",
    "\n",
    "        # Draw current positions\n",
    "        for traj in frame_trajs:\n",
    "            track_id = int(traj[\"TrajectoryID\"])\n",
    "            cx, cy = traj[\"X\"], traj[\"Y\"]\n",
    "\n",
    "            # Skip if NaN\n",
    "            if pd.isna(cx) or pd.isna(cy):\n",
    "                continue\n",
    "\n",
    "            cx, cy = int(cx), int(cy)\n",
    "            color = default_colors[track_id % len(default_colors)]\n",
    "\n",
    "            # Draw circle at position\n",
    "            cv2.circle(frame, (cx, cy), marker_radius, color, marker_thickness)\n",
    "\n",
    "            # Draw label\n",
    "            if show_labels:\n",
    "                label = f\"ID{track_id}\"\n",
    "                label_offset = int(marker_radius + 5)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    label,\n",
    "                    (cx + label_offset, cy - label_offset),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    text_size,\n",
    "                    color,\n",
    "                    max(1, int(text_scale * 2)),\n",
    "                )\n",
    "\n",
    "            # Draw orientation arrow\n",
    "            if (\n",
    "                show_orientation\n",
    "                and \"Theta\" in traj.index\n",
    "                and not pd.isna(traj[\"Theta\"])\n",
    "            ):\n",
    "                heading = traj[\"Theta\"]\n",
    "                end_x = int(cx + arrow_len * np.cos(heading))\n",
    "                end_y = int(cy + arrow_len * np.sin(heading))\n",
    "                cv2.arrowedLine(\n",
    "                    frame,\n",
    "                    (cx, cy),\n",
    "                    (end_x, end_y),\n",
    "                    color,\n",
    "                    marker_thickness,\n",
    "                    tipLength=0.3,\n",
    "                )\n",
    "\n",
    "        # Write frame\n",
    "        out.write(frame)\n",
    "\n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"✓ Video saved to: {output_path}\")\n",
    "    print(f\"  File size: {os.path.getsize(output_path) / (1024*1024):.1f} MB\")\n",
    "\n",
    "\n",
    "print(\"Video generation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d8254ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input video: 4512x4512 @ 25.0 FPS, 750 frames\n",
      "Building trajectory lookup...\n",
      "Generating video: emi_short_annotated.mp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6985ffb73044a1ea73ad14320d5395a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing frames:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Video saved to: emi_short_annotated.mp4\n",
      "  File size: 115.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Generate the annotated video\n",
    "if GENERATE_VIDEO and not merged_df.empty:\n",
    "    generate_annotated_video(\n",
    "        video_path=VIDEO_PATH,\n",
    "        output_path=VIDEO_OUTPUT_PATH,\n",
    "        trajectories_df=merged_df,\n",
    "        reference_body_size=REFERENCE_BODY_SIZE,  # Use original body size (coords already scaled)\n",
    "        show_labels=SHOW_LABELS,\n",
    "        show_orientation=SHOW_ORIENTATION,\n",
    "        show_trails=SHOW_TRAILS,\n",
    "        trail_duration_sec=TRAIL_DURATION_SEC,\n",
    "        marker_size=MARKER_SIZE,\n",
    "        arrow_length=ARROW_LENGTH,\n",
    "        text_scale=TEXT_SCALE,\n",
    "    )\n",
    "else:\n",
    "    if not GENERATE_VIDEO:\n",
    "        print(\"Video generation disabled (GENERATE_VIDEO=False)\")\n",
    "    else:\n",
    "        print(\"No trajectory data available for video generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac83204",
   "metadata": {},
   "source": [
    "## Optional: Quick Static Plots\n",
    "\n",
    "Generate static plots for quick overview (useful if video generation is slow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e99c85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Plot trajectory overview\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not merged_df.empty:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Plot 1: Spatial trajectories\n",
    "    ax1 = axes[0]\n",
    "    for traj_id in merged_df[\"TrajectoryID\"].unique():\n",
    "        traj = merged_df[merged_df[\"TrajectoryID\"] == traj_id]\n",
    "        ax1.plot(traj[\"X\"], traj[\"Y\"], alpha=0.7, linewidth=0.5)\n",
    "    ax1.set_xlabel(\"X (pixels)\")\n",
    "    ax1.set_ylabel(\"Y (pixels)\")\n",
    "    ax1.set_title(f'All Trajectories ({merged_df[\"TrajectoryID\"].nunique()} total)')\n",
    "    ax1.set_aspect(\"equal\")\n",
    "    ax1.invert_yaxis()  # Flip Y axis to match image coordinates\n",
    "\n",
    "    # Plot 2: Trajectory lengths\n",
    "    ax2 = axes[1]\n",
    "    traj_lengths = merged_df.groupby(\"TrajectoryID\").size()\n",
    "    ax2.hist(traj_lengths, bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "    ax2.set_xlabel(\"Trajectory Length (frames)\")\n",
    "    ax2.set_ylabel(\"Count\")\n",
    "    ax2.set_title(\n",
    "        f\"Trajectory Length Distribution\\nMean: {traj_lengths.mean():.1f}, Median: {traj_lengths.median():.1f}\"\n",
    "    )\n",
    "    ax2.axvline(\n",
    "        traj_lengths.mean(),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Mean ({traj_lengths.mean():.1f})\",\n",
    "    )\n",
    "    ax2.axvline(\n",
    "        traj_lengths.median(),\n",
    "        color=\"orange\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Median ({traj_lengths.median():.1f})\",\n",
    "    )\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to visualize!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c42396d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-trajectory statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Frame</th>\n",
       "      <th>End Frame</th>\n",
       "      <th>Length</th>\n",
       "      <th>X Mean</th>\n",
       "      <th>X Std</th>\n",
       "      <th>Y Mean</th>\n",
       "      <th>Y Std</th>\n",
       "      <th>Duration (s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrajectoryID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>674.95</td>\n",
       "      <td>34.08</td>\n",
       "      <td>399.95</td>\n",
       "      <td>15.27</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>927.44</td>\n",
       "      <td>146.10</td>\n",
       "      <td>481.78</td>\n",
       "      <td>142.06</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>750</td>\n",
       "      <td>697</td>\n",
       "      <td>848.59</td>\n",
       "      <td>223.69</td>\n",
       "      <td>740.06</td>\n",
       "      <td>280.11</td>\n",
       "      <td>27.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>601</td>\n",
       "      <td>554</td>\n",
       "      <td>2150.99</td>\n",
       "      <td>399.18</td>\n",
       "      <td>2505.56</td>\n",
       "      <td>670.96</td>\n",
       "      <td>22.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "      <td>1500.03</td>\n",
       "      <td>540.88</td>\n",
       "      <td>1575.47</td>\n",
       "      <td>936.63</td>\n",
       "      <td>27.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>124</td>\n",
       "      <td>153</td>\n",
       "      <td>30</td>\n",
       "      <td>856.55</td>\n",
       "      <td>43.96</td>\n",
       "      <td>1139.62</td>\n",
       "      <td>48.65</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>477</td>\n",
       "      <td>487</td>\n",
       "      <td>11</td>\n",
       "      <td>1165.05</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1141.23</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>197</td>\n",
       "      <td>207</td>\n",
       "      <td>11</td>\n",
       "      <td>1285.23</td>\n",
       "      <td>62.41</td>\n",
       "      <td>1247.36</td>\n",
       "      <td>32.60</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>824.22</td>\n",
       "      <td>88.90</td>\n",
       "      <td>978.10</td>\n",
       "      <td>62.32</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>111</td>\n",
       "      <td>122</td>\n",
       "      <td>12</td>\n",
       "      <td>905.25</td>\n",
       "      <td>54.43</td>\n",
       "      <td>678.33</td>\n",
       "      <td>134.77</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Start Frame  End Frame  Length   X Mean   X Std   Y Mean  \\\n",
       "TrajectoryID                                                             \n",
       "0                      19         29      11   674.95   34.08   399.95   \n",
       "1                       1         34      34   927.44  146.10   481.78   \n",
       "2                      54        750     697   848.59  223.69   740.06   \n",
       "3                      48        601     554  2150.99  399.18  2505.56   \n",
       "4                       1        685     685  1500.03  540.88  1575.47   \n",
       "...                   ...        ...     ...      ...     ...      ...   \n",
       "186                   124        153      30   856.55   43.96  1139.62   \n",
       "187                   477        487      11  1165.05    1.58  1141.23   \n",
       "188                   197        207      11  1285.23   62.41  1247.36   \n",
       "189                     3         64      62   824.22   88.90   978.10   \n",
       "190                   111        122      12   905.25   54.43   678.33   \n",
       "\n",
       "               Y Std  Duration (s)  \n",
       "TrajectoryID                        \n",
       "0              15.27          0.40  \n",
       "1             142.06          1.32  \n",
       "2             280.11         27.84  \n",
       "3             670.96         22.12  \n",
       "4             936.63         27.36  \n",
       "...              ...           ...  \n",
       "186            48.65          1.16  \n",
       "187             3.54          0.40  \n",
       "188            32.60          0.40  \n",
       "189            62.32          2.44  \n",
       "190           134.77          0.44  \n",
       "\n",
       "[191 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional: Per-trajectory statistics\n",
    "if not merged_df.empty:\n",
    "    traj_stats = (\n",
    "        merged_df.groupby(\"TrajectoryID\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"FrameID\": [\"min\", \"max\", \"count\"],\n",
    "                \"X\": [\"mean\", \"std\"],\n",
    "                \"Y\": [\"mean\", \"std\"],\n",
    "            }\n",
    "        )\n",
    "        .round(2)\n",
    "    )\n",
    "\n",
    "    traj_stats.columns = [\n",
    "        \"Start Frame\",\n",
    "        \"End Frame\",\n",
    "        \"Length\",\n",
    "        \"X Mean\",\n",
    "        \"X Std\",\n",
    "        \"Y Mean\",\n",
    "        \"Y Std\",\n",
    "    ]\n",
    "    traj_stats[\"Duration (s)\"] = (\n",
    "        traj_stats[\"End Frame\"] - traj_stats[\"Start Frame\"]\n",
    "    ) / FPS\n",
    "\n",
    "    print(\"Per-trajectory statistics:\")\n",
    "    display(traj_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-animal-tracker-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
